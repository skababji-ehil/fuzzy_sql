{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/samer/projects/fuzzy_sql/src') #This will enable reading the modules\n",
    "from fuzzy_sql.fuzzy_sql import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _assign_dtype(df, dict):\n",
    "    #Correct dtypes of real and syn dataframes before saving in the database \n",
    "    #map metaddata into dtype dict with pandas dtypes\n",
    "    #cols in df shall match keys in in_dict\n",
    "    assert bool(set(df.columns).intersection(set(dict.keys())))\n",
    "    out_dict={}\n",
    "    for key in dict:\n",
    "        if dict[key] in ['quantitative','continuous','interval','ratio']:\n",
    "            out_dict[key]='float64'\n",
    "        elif dict[key] in ['date','time','datetime']:\n",
    "            out_dict[key]='datetime64'\n",
    "        else:\n",
    "            out_dict[key]='category'\n",
    "    \n",
    "    for col in df.columns:\n",
    "        df[col]=df[col].astype(out_dict[col])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LONG_QUERY():\n",
    "    \"\"\" Generates random queries for baseline-longitudinal datasets. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, db_conn: object, parent_tbl_name: str, child_tbl_name: str, metadata: dict,params: dict , seed=False):\n",
    "        \"\"\" \n",
    "        Args:\n",
    "            db_conn: The connection object of the sqlite database where the data exists.\n",
    "            parent_tbl_name: The name of the parent table (i.e. baseline data) in the database.\n",
    "            child_tbl_name: The name of the child table (i.e. longitudinal data) in the database.\n",
    "            metadata: A dictionary that includes table's variable names (i.e. column names) as keys and types of variables as values. THey types shall be restricted to: 'continuous', 'data' and 'nominal'. Any table shall have at least one nominal variable.\n",
    "            params: A dictionary that includes the set of parameters that are necessary for generating the random queries. \n",
    "            seed: If set to True, generated random queries become deterministic. \n",
    "        \"\"\"\n",
    "        self.SEED=seed\n",
    "\n",
    "        self.CUR = db_conn.cursor()\n",
    "        self.RP_NAME = parent_tbl_name #RP = Real Parent\n",
    "        self.RC_NAME = child_tbl_name #RC = Real Child\n",
    "        self.metadata=copy.deepcopy(metadata)\n",
    "        \n",
    "        #Fetch Real data (both parent and child)\n",
    "        self.RP_DF=pd.read_sql_query(f'SELECT * FROM {self.RP_NAME}', db_conn) #Real Parent Dataframe\n",
    "        self.RC_DF=pd.read_sql_query(f'SELECT * FROM {self.RC_NAME}', db_conn) #Real Child Dataframe\n",
    "        #rename variables by concatenating table names\n",
    "        self.RP_DF.columns=[self.RP_NAME+'.'+x for x in self.RP_DF.columns]\n",
    "        self.RC_DF.columns=[self.RC_NAME+'.'+x for x in self.RC_DF.columns]\n",
    "\n",
    "\n",
    "        #Get foreign key name\n",
    "        self.FKEY_NAME=self.metadata['key']\n",
    "\n",
    "        #Delete foreign key from child variables to avoid repetition of variable in various expression\n",
    "        del self.metadata['child'][self.FKEY_NAME]\n",
    "\n",
    "\n",
    "        #Segregate variables into lists based on their types\n",
    "        self.CAT_VARS={} #Parent Categorical Variables\n",
    "        self.CNT_VARS={}\n",
    "        self.DT_VARS={}\n",
    "        self.CAT_VARS['parent']=[self.RP_NAME+'.'+key for key, value in self.metadata['parent'].items() if value in ['qualitative','categorical','nominal','discrete','ordinal','dichotomous']]\n",
    "        self.CAT_VARS['child']=[self.RC_NAME+'.'+key for key, value in self.metadata['child'].items() if value in ['qualitative','categorical','nominal','discrete','ordinal','dichotomous']]\n",
    "        self.CNT_VARS['parent']=[self.RP_NAME+'.'+key for key, value in self.metadata['parent'].items() if value in ['quantitative','continuous','interval','ratio']]\n",
    "        self.CNT_VARS['child']=[self.RC_NAME+'.'+key for key, value in self.metadata['child'].items() if value in ['quantitative','continuous','interval','ratio']]\n",
    "        self.DT_VARS['parent']=[self.RP_NAME+'.'+key for key, value in self.metadata['parent'].items() if value in ['date','time','datetime']]\n",
    "        self.DT_VARS['child']=[self.RC_NAME+'.'+key for key, value in self.metadata['child'].items() if value in ['date','time','datetime']]\n",
    "\n",
    "\n",
    "\n",
    "        # Aggregate function applies only when there is at least one continuous variable \n",
    "        self.AGG_FNCTN=True if len(self.CNT_VARS['parent'])!=0 or len(self.CNT_VARS['child'])!=0 else False\n",
    "\n",
    "        # Define random query attributes\n",
    "        self.ATTRS=params #General attributes that can be set by the user\n",
    "\n",
    "\n",
    "        # Generate dictionaries of bags for various variables\n",
    "        self.CAT_VAL_BAGS={}\n",
    "        self.CNT_VAL_BAGS={}\n",
    "        self.DT_VAL_BAGS={}\n",
    "        self.CAT_VAL_BAGS['parent']=self._make_bags(self.RP_DF[self.CAT_VARS['parent']])\n",
    "        self.CNT_VAL_BAGS['parent']=self._make_bags(self.RP_DF[self.CNT_VARS['parent']])\n",
    "        self.DT_VAL_BAGS['parent']=self._make_bags(self.RP_DF[self.DT_VARS['parent']])\n",
    "        self.CAT_VAL_BAGS['child']=self._make_bags(self.RC_DF[self.CAT_VARS['child']])\n",
    "        self.CNT_VAL_BAGS['child']=self._make_bags(self.RC_DF[self.CNT_VARS['child']])\n",
    "        self.DT_VAL_BAGS['child']=self._make_bags(self.RC_DF[self.DT_VARS['child']])\n",
    "        \n",
    "\n",
    "\n",
    "    def _make_bags(self,df:pd.DataFrame)-> dict:\n",
    "        val_bags={}\n",
    "        for var in df.columns:\n",
    "            vals=df[var].values\n",
    "            vals=[x for x in vals if x==x] #drop nan\n",
    "            vals=list(filter(None, vals)) #drop None\n",
    "            val_bags[var]=vals if len(vals)!=0 else ['N/A']\n",
    "        return val_bags\n",
    "\n",
    "    def _get_var_idx(self, var_name):\n",
    "        if var_name in self.RP_DF.columns: #search in parent\n",
    "            idx=self.RP_DF.columns.get_loc(var_name)\n",
    "            return 'parent',idx\n",
    "        elif var_name in self.RC_DF.columns: #search in child\n",
    "            idx=self.RC_DF.columns.get_loc(var_name)\n",
    "            return 'child', idx\n",
    "        else:\n",
    "            raise Exception(f\"{var_name} not found in parent or child tables!\")\n",
    "\n",
    "        \n",
    "    def _get_val_cmp_term(self) -> str:\n",
    "        pass\n",
    "\n",
    "    def _get_agg_fntn_term(self) -> str:\n",
    "        pass\n",
    "\n",
    "    def _get_groupby_term(self)-> str:\n",
    "        #You can group by CAT_VARS whether from parent or child or both\n",
    "        if self.SEED:\n",
    "            np.random.seed(141)\n",
    "        vars_select_bag=self.CAT_VARS['parent'] +self.CAT_VARS['child']\n",
    "        n_vars_bag=np.arange(1, 1+len(vars_select_bag)) \n",
    "        if self.ATTRS['LESS_GRP_VARS']:#define slope-down discrete distribution \n",
    "            n_var_probs=n_vars_bag[::-1]/n_vars_bag.sum()\n",
    "            # n_var_probs= np.zeros_like(n_vars_bag)\n",
    "            # n_var_probs[0]=1\n",
    "            n_vars=np.random.choice(n_vars_bag, p=n_var_probs)\n",
    "        else:\n",
    "            n_vars=np.random.choice(n_vars_bag)\n",
    "        picked_vars = random.sample(vars_select_bag, n_vars)\n",
    "        term=f\"{picked_vars}\"\n",
    "        term=term.replace(\"[\",\"\")\n",
    "        term=term.replace(\"]\",\"\")\n",
    "        term=term.replace(\"'\",\"\")\n",
    "\n",
    "        return term\n",
    "\n",
    "    \n",
    "    def _build_flter_expr(self, val_cmp_term: str) -> str:\n",
    "        pass\n",
    "\n",
    "    def _build_agg_expr(self,groupby_term: str) -> str:\n",
    "        pass\n",
    "\n",
    "    def _build_agg_w_fntn_expr(self, agg_fnt_term: str, groupby_term: str):\n",
    "        pass\n",
    "\n",
    "    def _build_aggfltr_expr(self, val_cmp_term: str, groupby_term: str):\n",
    "        pass\n",
    "\n",
    "    def _build_aggfltr_w_fntn_expr(self, agg_fnt_term: str, val_cmp_term, groupby_term: str):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_path=\"/home/samer/projects/fuzzy_sql/data/longitudinal/ready/real/b_sample.csv\" #real parent (baseline) path \n",
    "rc_path=\"/home/samer/projects/fuzzy_sql/data/longitudinal/ready/real/l_sample.csv\" #real child (longitudinal) path \n",
    "sp_path=\"/home/samer/projects/fuzzy_sql/data/longitudinal/ready/synthetic/b_sample_syn.csv\" #synthetic parent (baseline) path \n",
    "sc_path=\"/home/samer/projects/fuzzy_sql/data/longitudinal/ready/synthetic/l_sample_syn.csv\" #synthetic child (longitudinal) path \n",
    "meta_path=\"/home/samer/projects/fuzzy_sql/data/longitudinal/ready/metadata/sample.json\" #metdata path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data frames with all variables read as string and eliminate the apostrophe  '\n",
    "rp=load_csv(rp_path) \n",
    "rc=load_csv(rc_path) \n",
    "sp=load_csv(sp_path)  \n",
    "sc=load_csv(sc_path) \n",
    "import _json\n",
    "with open(meta_path) as f:\n",
    "    meta=json.load(f) #metadata for the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix datatypes in loaded csv \n",
    "rp=_assign_dtype(rp, meta['parent'])\n",
    "rc=_assign_dtype(rc, meta['child'])\n",
    "sp=_assign_dtype(sp, meta['parent'])\n",
    "sc=_assign_dtype(sc, meta['child'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define default parameters\n",
    "DFLT_PARAMS={\n",
    "    'AGG_OPS':{'AVG':0.5, 'SUM':0.3, 'MAX':0.1, 'MIN':0.1 },\n",
    "    'LOGIC_OPS':{'AND':0.5,'OR':0.5},\n",
    "    'NOT_STATE':{'0':1, '1':0},\n",
    "    'CAT_OPS':{'=':0.25, '<>':0.25, 'LIKE':0.25, 'IN':0.25},\n",
    "    'CNT_OPS':{'=':0.2, '>':0.1, '<':0.1, '>=':0.1, '<=':0.1, '<>':0.1, 'BETWEEN':0.3},\n",
    "    'DT_OPS':{'=':0.2, '>':0.1, '<':0.1, '>=':0, '<=':0, '<>':0.1, 'BETWEEN':0.3, 'IN':0.2},\n",
    "    'LESS_GRP_VARS': False, # enforce bias in random queries toward smaller number of groupby vars. Default is no bias (i.e. uniform sampling)\n",
    "    'LESS_CMP_VARS':False, # enforce bias in random queries toward small number of  comparison terms. Default is no bias (i.e. uniform sampling)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table sample_r_b already exists in the database\n",
      "Table sample_r_l already exists in the database\n",
      "Table sample_s_b already exists in the database\n",
      "Table sample_s_l already exists in the database\n"
     ]
    }
   ],
   "source": [
    "# import real data into database\n",
    "conn = sqlite3.connect('fuzzy_sql.db')\n",
    "make_table('sample_r_b', rp, conn)\n",
    "make_table('sample_r_l', rc, conn)\n",
    "make_table('sample_s_b', sp, conn)\n",
    "make_table('sample_s_l', sc, conn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "self=LONG_QUERY(conn,'sample_r_b','sample_r_l', meta,DFLT_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.ATTRS['LESS_GRP_VARS']=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "smk=self._get_groupby_term()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GROUP BY sample_r_b.PL_RUCC2, sample_r_b.PL_RUCA4, sample_r_b.PL_NCHS2, sample_r_b.RACE, sample_r_b.FEMALE, sample_r_b.PL_UR_CA'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'GROUP BY ' + smk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.env_dev': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cf594385e3e378fbba23be52d8fa8a1ff0f44816650af8bcee05fc5c8211531"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
