{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/samer/projects/fuzzy_sql/src') #This will enable reading the modules\n",
    "from fuzzy_sql.fuzzy_sql import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _assign_dtype(df, dict):\n",
    "    #Correct dtypes of real and syn dataframes before saving in the database \n",
    "    #map metaddata into dtype dict with pandas dtypes\n",
    "    #cols in df shall match keys in in_dict\n",
    "    assert bool(set(df.columns).intersection(set(dict.keys())))\n",
    "    out_dict={}\n",
    "    for key in dict:\n",
    "        if dict[key] in ['quantitative','continuous','interval','ratio']:\n",
    "            out_dict[key]='float64'\n",
    "        elif dict[key] in ['date','time','datetime']:\n",
    "            out_dict[key]='datetime64'\n",
    "        else:\n",
    "            out_dict[key]='category'\n",
    "    \n",
    "    for col in df.columns:\n",
    "        df[col]=df[col].astype(out_dict[col])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import exception\n",
    "\n",
    "\n",
    "class LONG_QUERY():\n",
    "    \"\"\" Generates random queries for baseline-longitudinal datasets. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, db_conn: object, parent_tbl_name: str, child_tbl_name: str, metadata: dict,params: dict , seed=False):\n",
    "        \"\"\" \n",
    "        Args:\n",
    "            db_conn: The connection object of the sqlite database where the data exists.\n",
    "            parent_tbl_name: The name of the parent table (i.e. baseline data) in the database.\n",
    "            child_tbl_name: The name of the child table (i.e. longitudinal data) in the database.\n",
    "            metadata: A dictionary that includes table's variable names (i.e. column names) as keys and types of variables as values. THey types shall be restricted to: 'continuous', 'data' and 'nominal'. Any table shall have at least one nominal variable.\n",
    "            params: A dictionary that includes the set of parameters that are necessary for generating the random queries. \n",
    "            seed: If set to True, generated random queries become deterministic. \n",
    "        \"\"\"\n",
    "        self.SEED=seed\n",
    "        self.seed_no=141\n",
    "\n",
    "        self.CUR = db_conn.cursor()\n",
    "        self.PARENT_NAME = parent_tbl_name #RP = Real Parent\n",
    "        self.CHILD_NAME = child_tbl_name #RC = Real Child\n",
    "        self.metadata=copy.deepcopy(metadata)\n",
    "        \n",
    "        #Fetch Real data (both parent and child)\n",
    "        self.PARENT_DF=pd.read_sql_query(f'SELECT * FROM {self.PARENT_NAME}', db_conn) #Real Parent Dataframe\n",
    "        self.CHILD_DF=pd.read_sql_query(f'SELECT * FROM {self.CHILD_NAME}', db_conn) #Real Child Dataframe\n",
    "\n",
    "\n",
    "        #Get foreign key name\n",
    "        self.FKEY_NAME=self.metadata['key']\n",
    "\n",
    "        #Delete foreign key from child variables to avoid repetition of variable in various expression\n",
    "        del self.metadata['child'][self.FKEY_NAME]\n",
    "\n",
    "\n",
    "        #Segregate variables into lists based on their types\n",
    "        self.CAT_VARS={} #Parent Categorical Variables\n",
    "        self.CNT_VARS={}\n",
    "        self.DT_VARS={}\n",
    "        self.CAT_VARS['parent']=[key for key, value in self.metadata['parent'].items() if value in ['qualitative','categorical','nominal','discrete','ordinal','dichotomous']]\n",
    "        self.CAT_VARS['child']=[key for key, value in self.metadata['child'].items() if value in ['qualitative','categorical','nominal','discrete','ordinal','dichotomous']]\n",
    "        self.CNT_VARS['parent']=[key for key, value in self.metadata['parent'].items() if value in ['quantitative','continuous','interval','ratio']]\n",
    "        self.CNT_VARS['child']=[key for key, value in self.metadata['child'].items() if value in ['quantitative','continuous','interval','ratio']]\n",
    "        self.DT_VARS['parent']=[key for key, value in self.metadata['parent'].items() if value in ['date','time','datetime']]\n",
    "        self.DT_VARS['child']=[key for key, value in self.metadata['child'].items() if value in ['date','time','datetime']]\n",
    "\n",
    "\n",
    "\n",
    "        # Aggregate function applies only when there is at least one continuous variable \n",
    "        self.AGG_FNCTN=True if len(self.CNT_VARS['parent'])!=0 or len(self.CNT_VARS['child'])!=0 else False\n",
    "\n",
    "        # Define random query attributes\n",
    "        self.ATTRS=params #General attributes that can be set by the user\n",
    "\n",
    "\n",
    "        # Generate dictionaries of bags for various variables\n",
    "        self.CAT_VAL_BAGS={}\n",
    "        self.CNT_VAL_BAGS={}\n",
    "        self.DT_VAL_BAGS={}\n",
    "        self.CAT_VAL_BAGS['parent']=self._make_bags(self.PARENT_DF[self.CAT_VARS['parent']])\n",
    "        self.CNT_VAL_BAGS['parent']=self._make_bags(self.PARENT_DF[self.CNT_VARS['parent']])\n",
    "        self.DT_VAL_BAGS['parent']=self._make_bags(self.PARENT_DF[self.DT_VARS['parent']])\n",
    "        self.CAT_VAL_BAGS['child']=self._make_bags(self.CHILD_DF[self.CAT_VARS['child']])\n",
    "        self.CNT_VAL_BAGS['child']=self._make_bags(self.CHILD_DF[self.CNT_VARS['child']])\n",
    "        self.DT_VAL_BAGS['child']=self._make_bags(self.CHILD_DF[self.DT_VARS['child']])\n",
    "        \n",
    "        self.max_no_in_terms=5 #Maximum number of n terms (set it to 0 if you do not want to impose any limit)\n",
    "\n",
    "    def _make_bags(self,df:pd.DataFrame)-> dict:\n",
    "        val_bags={}\n",
    "        for var in df.columns:\n",
    "            vals=df[var].values\n",
    "            vals=[x for x in vals if x==x] #drop nan\n",
    "            vals=list(filter(None, vals)) #drop None\n",
    "            val_bags[var]=vals if len(vals)!=0 else ['N/A']\n",
    "        return val_bags\n",
    "\n",
    "    def make_query(self,cur: object, query_exp: str)-> pd.DataFrame:\n",
    "        cur.execute(query_exp)\n",
    "        query = cur.fetchall()\n",
    "        query=pd.DataFrame(query, columns=[description[0] for description in cur.description])\n",
    "        return query\n",
    "\n",
    "    # def _get_var_idx(self, var_name):\n",
    "    #     if var_name in self.PARENT_DF.columns: #search in parent\n",
    "    #         idx=self.PARENT_DF.columns.get_loc(var_name)\n",
    "    #         return 'parent',idx\n",
    "    #     elif var_name in self.CHILD_DF.columns: #search in child\n",
    "    #         idx=self.CHILD_DF.columns.get_loc(var_name)\n",
    "    #         return 'child', idx\n",
    "    #     else:\n",
    "    #         raise Exception(f\"{var_name} not found in parent or child tables!\")\n",
    "\n",
    "    def _mix_vars(self,*args):\n",
    "        #accepts variable length of arguments as tuples where each tuple consists of the table name and some variables that belong to that table\n",
    "        # returns mixed variables in one list but each variable is concatenated with its respective table name\n",
    "        mixed_vars=[]\n",
    "        for arg in args:\n",
    "            vars=[arg[0]+'.'+x for x in arg[1]]\n",
    "            mixed_vars+=vars\n",
    "        return mixed_vars\n",
    "\n",
    "    def _get_twin_lst(self, in_lst: list,in_parent_name: str, out_parent_name: str, in_child_name: str, out_child_name: str)-> list:\n",
    "        # replaces the table names of teh real dataset by the table names of the synthetic datasets.\n",
    "        out_lst=[var.replace(in_parent_name,out_parent_name ) for var in in_lst] \n",
    "        out_lst=[var.replace(in_child_name,out_child_name ) for var in out_lst] \n",
    "        return out_lst\n",
    "\n",
    "    def _get_rnd_groupby_lst(self)-> list:\n",
    "        #returned randomly picked cat vars including the concatenated table name of the real data (ie that is defined in teh class)\n",
    "        #Note: You can group by CAT_VARS whether from parent or child or both\n",
    "        if self.SEED:\n",
    "            np.random.seed(self.seed_no)\n",
    "            random.seed(self.seed_no)\n",
    "        all_cat_vars=self._mix_vars((self.PARENT_NAME,self.CAT_VARS['parent']),(self.CHILD_NAME,self.CAT_VARS['child']))\n",
    "        # parent_cat_vars=[self.PARENT_NAME+'.'+x for x in self.CAT_VARS['parent']]\n",
    "        # child_cat_vars=[self.CHILD_NAME+'.'+x for x in self.CAT_VARS['child']]\n",
    "        # all_cat_vars=parent_cat_vars +child_cat_vars\n",
    "        n_vars_bag=np.arange(1, 1+len(all_cat_vars)) \n",
    "        if self.ATTRS['LESS_GRP_VARS']:#define slope-down discrete distribution \n",
    "            n_var_probs=n_vars_bag[::-1]/n_vars_bag.sum()\n",
    "            # n_var_probs= np.zeros_like(n_vars_bag)\n",
    "            # n_var_probs[0]=1\n",
    "            n_vars=np.random.choice(n_vars_bag, p=n_var_probs)\n",
    "        else:\n",
    "            n_vars=np.random.choice(n_vars_bag)\n",
    "        picked_vars = random.sample(all_cat_vars, n_vars)\n",
    "        return picked_vars\n",
    "\n",
    "\n",
    "    def _get_rnd_aggfntn_tpl(self) -> tuple:\n",
    "        #returns a random tuple of agg function and continuous OR date variable \n",
    "        # Note: continuous variable can be from either parent or child tables \n",
    "        if self.SEED:\n",
    "            np.random.seed(self.seed_no)\n",
    "            random.seed(self.seed_no)\n",
    "        all_possible_vars=self._mix_vars((self.PARENT_NAME,self.CNT_VARS['parent']),(self.PARENT_NAME,self.DT_VARS['parent']),(self.CHILD_NAME,self.CNT_VARS['child']),(self.CHILD_NAME,self.DT_VARS['child']))\n",
    "        picked_var=np.random.choice(all_possible_vars)\n",
    "        picked_op=np.random.choice(list(self.ATTRS['AGG_OPS'].keys()), p=list(self.ATTRS['AGG_OPS'].values()))\n",
    "        return (picked_op,picked_var)\n",
    "\n",
    "    \n",
    "    def _get_rnd_where_lst(self) -> tuple:\n",
    "        # use WHERE with mix of CAT, CNT, DT variables from both PARENT and CHILD\n",
    "        if self.SEED:\n",
    "            np.random.seed(self.seed_no)\n",
    "            random.seed(self.seed_no)\n",
    "        all_possible_vars=self._mix_vars((self.PARENT_NAME,self.CAT_VARS['parent']),(self.CHILD_NAME,self.CAT_VARS['child']),(self.PARENT_NAME,self.CNT_VARS['parent']),(self.CHILD_NAME,self.CNT_VARS['child']),(self.PARENT_NAME,self.DT_VARS['parent']),(self.CHILD_NAME,self.DT_VARS['child']))\n",
    "        n_vars_bag=np.arange(1, 1+len(all_possible_vars)) #this gives possible number of terms in the where clause\n",
    "        if self.ATTRS['LESS_CMP_VARS']:#define slope-down discrete distribution \n",
    "            n_var_probs=n_vars_bag[::-1]/n_vars_bag.sum()\n",
    "            # n_var_probs= np.zeros_like(n_vars_bag)\n",
    "            # n_var_probs[0]=1\n",
    "            n_vars=np.random.choice(n_vars_bag, p=n_var_probs)\n",
    "        else:\n",
    "            n_vars=np.random.choice(n_vars_bag)\n",
    "        picked_vars = random.sample(all_possible_vars, n_vars)\n",
    "\n",
    "        all_cat_vars=np.concatenate(list(self.CAT_VARS.values()))\n",
    "        all_cnt_vars=np.concatenate(list(self.CNT_VARS.values()))\n",
    "        all_dt_vars=np.concatenate(list(self.DT_VARS.values()))\n",
    "        terms=[]\n",
    "        log_ops=[]\n",
    "        for long_var_name in picked_vars: #This loop will find the a proper random value comparison operation and proper random value for all the picked variables\n",
    "            #var=long_var_name[long_var_name.find(\".\")+1:]\n",
    "            x=long_var_name.split(\".\") #Note is assumed that variable names do NOT include any \".\"\n",
    "            var_tbl=x[0]\n",
    "            var=x[1]\n",
    "            var_tbl_rank='parent' if var_tbl==self.PARENT_NAME else 'child'\n",
    "            \n",
    "            #adding not to long variable name \n",
    "            not_status=np.random.choice(list(self.ATTRS['NOT_STATE'].keys()), p=list(self.ATTRS['NOT_STATE'].values()) )\n",
    "            selected_long_var_name= 'NOT '+long_var_name if not_status=='1' else long_var_name\n",
    "            \n",
    "            if var in all_cat_vars:\n",
    "                picked_cmp_op=np.random.choice(list(self.ATTRS['CAT_OPS'].keys()),p=list(self.ATTRS['CAT_OPS'].values()))\n",
    "                if picked_cmp_op=='IN' or picked_cmp_op=='NOT IN' :\n",
    "                    possible_no_of_in_terms=np.arange(2,len(self.CAT_VAL_BAGS[var_tbl_rank][var]))\n",
    "                    no_of_in_terms=np.min([np.random.choice(possible_no_of_in_terms),self.max_no_in_terms]) if self.max_no_in_terms != 0 else np.random.choice(possible_no_of_in_terms)\n",
    "                    vals=np.random.choice(self.CAT_VAL_BAGS[var_tbl_rank][var], size=no_of_in_terms)\n",
    "                    if picked_cmp_op=='IN':\n",
    "                        term =f\" {selected_long_var_name} IN {tuple(vals)} \"\n",
    "                    else:\n",
    "                        term=f\" {selected_long_var_name} NOT IN {tuple(vals)} \"\n",
    "                else:\n",
    "                    val=np.random.choice(self.CAT_VAL_BAGS[var_tbl_rank][var])\n",
    "                    term=f\" {selected_long_var_name} {picked_cmp_op} {val} \"\n",
    "            \n",
    "            elif var in all_cnt_vars:\n",
    "                picked_cmp_op=np.random.choice(list(self.ATTRS['CNT_OPS'].keys()),p=list(self.ATTRS['CNT_OPS'].values()))\n",
    "                if picked_cmp_op=='BETWEEN' or picked_cmp_op=='NOT BETWEEN':\n",
    "                    lower_bound_bag=self.CNT_VAL_BAGS[var_tbl_rank][var]\n",
    "                    lower_bound=np.random.choice(lower_bound_bag)\n",
    "                    upper_bound_bag=[x for x in lower_bound_bag if x>=lower_bound]\n",
    "                    upper_bound=np.random.choice(upper_bound_bag)\n",
    "                    if picked_cmp_op=='BETWEEN':\n",
    "                        term=f\" {selected_long_var_name} BETWEEN {lower_bound} AND {upper_bound} \"\n",
    "                    else:\n",
    "                        term=f\" {selected_long_var_name} NOT BETWEEN {lower_bound} AND {upper_bound} \"\n",
    "                else:\n",
    "                    val=np.random.choice(self.CNT_VAL_BAGS[var_tbl_rank][var])\n",
    "                    term=f\" {selected_long_var_name} {picked_cmp_op} {val} \"\n",
    "            \n",
    "            elif var in all_dt_vars:\n",
    "                picked_cmp_op=np.random.choice(list(self.ATTRS['DT_OPS'].keys()),p=list(self.ATTRS['DT_OPS'].values()))\n",
    "                if picked_cmp_op=='BETWEEN':\n",
    "                    pass\n",
    "                elif picked_cmp_op=='IN':\n",
    "                    pass\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                raise Exception(f\"Can not find {var} in the lists of all variables!!\")\n",
    "            \n",
    "            terms.append(term)\n",
    "        \n",
    "        selected_logic_ops=np.random.choice(list(self.ATTRS['LOGIC_OPS'].keys()), size=len(terms)-1, p=list(self.ATTRS['LOGIC_OPS'].values()))\n",
    "        return terms, selected_logic_ops\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "    def _build_agg_expr(self,  pname: str, cname: str, fkey: str, groupby_lst: list) -> str:\n",
    "        expr1=f'SELECT *,COUNT(*) FROM {pname} JOIN {cname} ON {pname}.{fkey} = {cname}.{fkey}'\n",
    "        expr2_1=' GROUP BY '\n",
    "        expr2_2=f'{groupby_lst}'\n",
    "        expr2_2=expr2_2.replace(\"[\",\"\")\n",
    "        expr2_2=expr2_2.replace(\"]\",\"\")\n",
    "        expr2_2=expr2_2.replace(\"'\",\"\")\n",
    "        return expr1+expr2_1+expr2_2\n",
    "\n",
    "    \n",
    "    def make_single_agg_query(self) -> dict:\n",
    "        dic={}\n",
    "        single_grp_lst=self._get_rnd_groupby_lst()\n",
    "        single_expr=self._build_agg_expr(self.PARENT_NAME, self.CHILD_NAME,self.FKEY_NAME, single_grp_lst)\n",
    "        query=self.make_query(self.CUR, single_expr)\n",
    "        dic['query']=query\n",
    "        dic['query_desc']={\n",
    "            \"type\":\"single_agg\",\n",
    "            \"sql\":single_expr,\n",
    "            \"n_rows\":query.shape[0],\n",
    "            \"n_cols\":query.shape[1]\n",
    "        }\n",
    "        return dic\n",
    "\n",
    "    def make_twin_agg_query(self, twin_parent_name, twin_child_name):\n",
    "        dic={}\n",
    "        real_grp_lst =self._get_rnd_groupby_lst()\n",
    "        syn_grp_lst=self._get_twin_lst(real_grp_lst, self.PARENT_NAME,twin_parent_name, self.CHILD_NAME,twin_child_name)\n",
    "        real_expr=self._build_agg_expr(self.PARENT_NAME, self.CHILD_NAME,self.FKEY_NAME, real_grp_lst)\n",
    "        syn_expr=self._build_agg_expr(twin_parent_name, twin_child_name,self.FKEY_NAME, syn_grp_lst)\n",
    "        query_real=self.make_query(self.CUR, real_expr)\n",
    "        query_syn=self.make_query(self.CUR, syn_expr)\n",
    "        dic['query_real']=query_real\n",
    "        dic['query_syn']=query_syn\n",
    "        dic['query_desc']={\n",
    "            \"type\":\"twin_agg\",\n",
    "            \"sql_real\":real_expr,\n",
    "            \"n_cols_real\":query_real.shape[1],\n",
    "            \"n_rows_real\":query_real.shape[0],\n",
    "            \"sql_syn\":syn_expr,\n",
    "            \"n_cols_syn\":query_syn.shape[1],\n",
    "            \"n_rows_syn\":query_syn.shape[0],\n",
    "        }\n",
    "        return dic\n",
    "\n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "    def _build_agg_expr_w_aggfntn(self,pname: str, cname: str, fkey: str, agg_fntn_tpl: tuple, groupby_lst: list) -> str:\n",
    "        expr1=f'SELECT *,COUNT(*), {agg_fntn_tpl[0]}({agg_fntn_tpl[1]}) FROM {pname} JOIN {cname} ON {pname}.{fkey} = {cname}.{fkey}'\n",
    "        expr2_1=' GROUP BY '\n",
    "        expr2_2=f'{groupby_lst}'\n",
    "        expr2_2=expr2_2.replace(\"[\",\"\")\n",
    "        expr2_2=expr2_2.replace(\"]\",\"\")\n",
    "        expr2_2=expr2_2.replace(\"'\",\"\")\n",
    "        expr=expr1+expr2_1+expr2_2\n",
    "        return expr\n",
    "    \n",
    "\n",
    "    def make_single_agg_query_w_aggfntn(self):\n",
    "        dic={}\n",
    "        single_grp_lst=self._get_rnd_groupby_lst()\n",
    "        agg_fntn_tpl=self._get_rnd_aggfntn_tpl()\n",
    "        expr=self._build_agg_expr_w_aggfntn(self.PARENT_NAME,self.CHILD_NAME, self.FKEY_NAME,agg_fntn_tpl,single_grp_lst)\n",
    "        query=self.make_query(self.CUR, expr)\n",
    "        dic['query']=query\n",
    "        dic['query_desc']={\n",
    "            \"type\":\"single_agg\",\n",
    "            \"sql\":expr,\n",
    "            \"n_rows\":query.shape[0],\n",
    "            \"n_cols\":query.shape[1]\n",
    "        }\n",
    "        return dic\n",
    "\n",
    "    def make_twin_agg_query_w_aggfntn(self,twintbl_parent_name,twintbl_child_name):\n",
    "        dic={}\n",
    "        real_groupby_lst=self._get_rnd_groupby_lst()\n",
    "        syn_groupby_lst=self._get_twin_lst(real_groupby_lst, self.PARENT_NAME,twintbl_parent_name, self.CHILD_NAME, twintbl_child_name)\n",
    "        real_aggfntn_tpl=self._get_rnd_aggfntn_tpl()\n",
    "        syn_aggfntn_tpl=self._get_twin_lst(real_aggfntn_tpl, self.PARENT_NAME,twintbl_parent_name, self.CHILD_NAME, twintbl_child_name)\n",
    "        real_expr=self._build_agg_expr_w_aggfntn(self.PARENT_NAME,self.CHILD_NAME,self.FKEY_NAME,real_aggfntn_tpl, real_groupby_lst)\n",
    "        syn_expr=self._build_agg_expr_w_aggfntn(twintbl_parent_name,twintbl_child_name,self.FKEY_NAME,syn_aggfntn_tpl, syn_groupby_lst)\n",
    "        query_real=self.make_query(self.CUR, real_expr)\n",
    "        query_syn=self.make_query(self.CUR, syn_expr)\n",
    "        dic['query_real']=query_real\n",
    "        dic['query_syn']=query_syn\n",
    "        dic['query_desc']={\n",
    "            \"type\":\"twin_agg\",\n",
    "            \"sql_real\":real_expr,\n",
    "            \"n_cols_real\":query_real.shape[1],\n",
    "            \"n_rows_real\":query_real.shape[0],\n",
    "            \"sql_syn\":syn_expr,\n",
    "            \"n_cols_syn\":query_syn.shape[1],\n",
    "            \"n_rows_syn\":query_syn.shape[0],\n",
    "            }\n",
    "        return dic\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "    def _build_fltr_expr(self,  pname: str, cname: str, fkey: str, where_terms: list, log_ops:list ) -> str:\n",
    "        expr1=f'SELECT * FROM {pname} JOIN {cname} ON {pname}.{fkey} = {cname}.{fkey} WHERE '\n",
    "        where_expr=[None]*(len(where_terms)+len(log_ops))\n",
    "        where_expr[::2]=where_terms\n",
    "        where_expr[1::2]=log_ops\n",
    "        where_expr=' '.join(x for x in where_expr )\n",
    "        where_expr=where_expr + ' '\n",
    "        return expr1+where_expr\n",
    "\n",
    "\n",
    "    def make_single_fltr_query(self) -> dict:\n",
    "        dic={}\n",
    "        where_terms, log_ops=self._get_rnd_where_lst()\n",
    "        single_expr=self._build_fltr_expr(self.PARENT_NAME,self.CHILD_NAME, self.FKEY_NAME, where_terms, log_ops)\n",
    "        query=self.make_query(self.CUR, single_expr)\n",
    "        dic['query']=query\n",
    "        dic['query_desc']={\n",
    "            \"type\":\"single_fltr\",\n",
    "            \"sql\":single_expr,\n",
    "            \"n_rows\":query.shape[0],\n",
    "            \"n_cols\":query.shape[1]\n",
    "        }\n",
    "        return dic\n",
    "\n",
    "    def make_twin_fltr_query(self, twin_parent_name: str, twin_child_name:str) -> dict:\n",
    "        dic={}\n",
    "        real_where_terms, log_ops =self._get_rnd_where_lst()\n",
    "        syn_where_terms=self._get_twin_lst(real_where_terms, self.PARENT_NAME,twin_parent_name, self.CHILD_NAME,twin_child_name)\n",
    "        real_expr=self._build_fltr_expr(self.PARENT_NAME, self.CHILD_NAME,self.FKEY_NAME, real_where_terms, log_ops)\n",
    "        syn_expr=self._build_fltr_expr(twin_parent_name, twin_child_name,self.FKEY_NAME, syn_where_terms,log_ops)\n",
    "        query_real=self.make_query(self.CUR, real_expr)\n",
    "        query_syn=self.make_query(self.CUR, syn_expr)\n",
    "        dic['query_real']=query_real\n",
    "        dic['query_syn']=query_syn\n",
    "        dic['query_desc']={\n",
    "            \"type\":\"twin_fltr\",\n",
    "            \"sql_real\":real_expr,\n",
    "            \"n_cols_real\":query_real.shape[1],\n",
    "            \"n_rows_real\":query_real.shape[0],\n",
    "            \"sql_syn\":syn_expr,\n",
    "            \"n_cols_syn\":query_syn.shape[1],\n",
    "            \"n_rows_syn\":query_syn.shape[0],\n",
    "        }\n",
    "        return dic\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "    def _build_aggfltr_expr(self,  pname: str, cname: str, fkey: str, groupby_lst: list, where_terms: list, log_ops: list) -> str:\n",
    "        expr1=f'SELECT *,COUNT(*) FROM {pname} JOIN {cname} ON {pname}.{fkey} = {cname}.{fkey} '\n",
    "        expr2=np.random.choice(list(self.ATTRS['JOIN_CNDTN'].keys()), p=list(self.ATTRS['JOIN_CNDTN'].values()))+' '\n",
    "        expr2_1=[None]*(len(where_terms)+len(log_ops))\n",
    "        expr2_1[::2]=where_terms\n",
    "        expr2_1[1::2]=log_ops\n",
    "        expr2_1=' '.join(x for x in expr2_1)\n",
    "        expr2_1='('+expr2_1+')' \n",
    "        expr3_1=' GROUP BY '\n",
    "        expr3_2=f'{groupby_lst}'\n",
    "        expr3_2=expr3_2.replace(\"[\",\"\")\n",
    "        expr3_2=expr3_2.replace(\"]\",\"\")\n",
    "        expr3_2=expr3_2.replace(\"'\",\"\")\n",
    "        return expr1+expr2+expr2_1+expr3_1+expr3_2\n",
    "\n",
    "\n",
    "    def make_single_aggfltr_query(self) -> dict:\n",
    "        dic={}\n",
    "        grp_lst=self._get_rnd_groupby_lst()\n",
    "        where_terms, log_ops=self._get_rnd_where_lst()\n",
    "        single_expr=self._build_aggfltr_expr(self.PARENT_NAME, self.CHILD_NAME, self.FKEY_NAME,grp_lst, where_terms,log_ops )\n",
    "        query=self.make_query(self.CUR, single_expr)\n",
    "        dic['query']=query\n",
    "        dic['query_desc']={\n",
    "            \"type\":\"single_aggfltr\",\n",
    "            \"sql\":single_expr,\n",
    "            \"n_rows\":query.shape[0],\n",
    "            \"n_cols\":query.shape[1]\n",
    "        }\n",
    "        return dic\n",
    "\n",
    "\n",
    "    def make_twin_aggfltr_query(self, twin_parent_name: str, twin_child_name:str) -> dict:\n",
    "        dic={}\n",
    "        \n",
    "        real_grp_lst =self._get_rnd_groupby_lst()\n",
    "        syn_grp_lst=self._get_twin_lst(real_grp_lst, self.PARENT_NAME,twin_parent_name, self.CHILD_NAME,twin_child_name)\n",
    "\n",
    "        real_where_terms, log_ops =self._get_rnd_where_lst()\n",
    "        syn_where_terms=self._get_twin_lst(real_where_terms, self.PARENT_NAME,twin_parent_name, self.CHILD_NAME,twin_child_name)\n",
    "        \n",
    "        real_expr=self._build_aggfltr_expr(self.PARENT_NAME, self.CHILD_NAME, self.FKEY_NAME,real_grp_lst, real_where_terms,log_ops)\n",
    "        syn_expr=self._build_aggfltr_expr(twin_parent_name, twin_child_name, self.FKEY_NAME,syn_grp_lst, syn_where_terms,log_ops)\n",
    "\n",
    "        query_real=self.make_query(self.CUR, real_expr)\n",
    "        query_syn=self.make_query(self.CUR, syn_expr)\n",
    "        dic['query_real']=query_real\n",
    "        dic['query_syn']=query_syn\n",
    "        dic['query_desc']={\n",
    "            \"type\":\"twin_aggfltr\",\n",
    "            \"sql_real\":real_expr,\n",
    "            \"n_cols_real\":query_real.shape[1],\n",
    "            \"n_rows_real\":query_real.shape[0],\n",
    "            \"sql_syn\":syn_expr,\n",
    "            \"n_cols_syn\":query_syn.shape[1],\n",
    "            \"n_rows_syn\":query_syn.shape[0],\n",
    "        }\n",
    "        return dic\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "    def _build_aggfltr_expr_w_aggfntn(self,pname: str, cname: str, fkey: str, agg_fntn_tpl: tuple, groupby_lst: list, where_terms: list, log_ops: list) -> str:\n",
    "        expr1=f'SELECT *,COUNT(*), {agg_fntn_tpl[0]}({agg_fntn_tpl[1]}) FROM {pname} JOIN {cname} ON {pname}.{fkey} = {cname}.{fkey} '\n",
    "        expr2=np.random.choice(list(self.ATTRS['JOIN_CNDTN'].keys()), p=list(self.ATTRS['JOIN_CNDTN'].values()))+' '\n",
    "        expr2_1=[None]*(len(where_terms)+len(log_ops))\n",
    "        expr2_1[::2]=where_terms\n",
    "        expr2_1[1::2]=log_ops\n",
    "        expr2_1=' '.join(x for x in expr2_1)\n",
    "        expr2_1='('+expr2_1+')' \n",
    "        expr3_1=' GROUP BY '\n",
    "        expr3_2=f'{groupby_lst}'\n",
    "        expr3_2=expr3_2.replace(\"[\",\"\")\n",
    "        expr3_2=expr3_2.replace(\"]\",\"\")\n",
    "        expr3_2=expr3_2.replace(\"'\",\"\")\n",
    "        return expr1+expr2+expr2_1+expr3_1+expr3_2\n",
    "\n",
    "\n",
    "\n",
    "    def make_single_aggfltr_query_w_aggfntn(self) -> dict:\n",
    "        dic={}\n",
    "        agg_fntn_tpl=self._get_rnd_aggfntn_tpl()\n",
    "        grp_lst=self._get_rnd_groupby_lst()\n",
    "        where_terms, log_ops=self._get_rnd_where_lst()\n",
    "        single_expr=self._build_aggfltr_expr_w_aggfntn(self.PARENT_NAME, self.CHILD_NAME, self.FKEY_NAME,agg_fntn_tpl,grp_lst, where_terms,log_ops )\n",
    "        query=self.make_query(self.CUR, single_expr)\n",
    "        dic['query']=query\n",
    "        dic['query_desc']={\n",
    "            \"type\":\"single_aggfltr\",\n",
    "            \"sql\":single_expr,\n",
    "            \"n_rows\":query.shape[0],\n",
    "            \"n_cols\":query.shape[1]\n",
    "        }\n",
    "        return dic\n",
    "\n",
    "\n",
    "\n",
    "    def make_twin_aggfltr_query_w_aggfntn(self, twin_parent_name: str, twin_child_name:str) -> dict:\n",
    "        dic={}\n",
    "        real_agg_fntn_tpl=self._get_rnd_aggfntn_tpl()\n",
    "        syn_agg_fntn_tpl=tuple(self._get_twin_lst(real_agg_fntn_tpl, self.PARENT_NAME,twin_parent_name, self.CHILD_NAME,twin_child_name))\n",
    "\n",
    "        real_grp_lst =self._get_rnd_groupby_lst()\n",
    "        syn_grp_lst=self._get_twin_lst(real_grp_lst, self.PARENT_NAME,twin_parent_name, self.CHILD_NAME,twin_child_name)\n",
    "\n",
    "        real_where_terms, log_ops =self._get_rnd_where_lst()\n",
    "        syn_where_terms=self._get_twin_lst(real_where_terms, self.PARENT_NAME,twin_parent_name, self.CHILD_NAME,twin_child_name)\n",
    "\n",
    "        real_expr=self._build_aggfltr_expr_w_aggfntn(self.PARENT_NAME, self.CHILD_NAME, self.FKEY_NAME,real_agg_fntn_tpl,real_grp_lst, real_where_terms,log_ops )\n",
    "        syn_expr=self._build_aggfltr_expr_w_aggfntn(twin_parent_name, twin_child_name, self.FKEY_NAME,syn_agg_fntn_tpl,syn_grp_lst, syn_where_terms,log_ops )\n",
    "\n",
    "        query_real=self.make_query(self.CUR, real_expr)\n",
    "        query_syn=self.make_query(self.CUR, syn_expr)\n",
    "        dic['query_real']=query_real\n",
    "        dic['query_syn']=query_syn\n",
    "        dic['query_desc']={\n",
    "            \"type\":\"twin_aggfltr\",\n",
    "            \"sql_real\":real_expr,\n",
    "            \"n_cols_real\":query_real.shape[1],\n",
    "            \"n_rows_real\":query_real.shape[0],\n",
    "            \"sql_syn\":syn_expr,\n",
    "            \"n_cols_syn\":query_syn.shape[1],\n",
    "            \"n_rows_syn\":query_syn.shape[0],\n",
    "        }\n",
    "        return dic\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_path=\"/home/samer/projects/fuzzy_sql/data/longitudinal/ready/real/b_sample.csv\" #real parent (baseline) path \n",
    "rc_path=\"/home/samer/projects/fuzzy_sql/data/longitudinal/ready/real/l_sample.csv\" #real child (longitudinal) path \n",
    "sp_path=\"/home/samer/projects/fuzzy_sql/data/longitudinal/ready/synthetic/b_sample_syn.csv\" #synthetic parent (baseline) path \n",
    "sc_path=\"/home/samer/projects/fuzzy_sql/data/longitudinal/ready/synthetic/l_sample_syn.csv\" #synthetic child (longitudinal) path \n",
    "meta_path=\"/home/samer/projects/fuzzy_sql/data/longitudinal/ready/metadata/sample.json\" #metdata path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data frames with all variables read as string and eliminate the apostrophe  '\n",
    "rp=load_csv(rp_path) \n",
    "rc=load_csv(rc_path) \n",
    "sp=load_csv(sp_path)  \n",
    "sc=load_csv(sc_path) \n",
    "import _json\n",
    "with open(meta_path) as f:\n",
    "    meta=json.load(f) #metadata for the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix datatypes in loaded csv \n",
    "rp=_assign_dtype(rp, meta['parent'])\n",
    "rc=_assign_dtype(rc, meta['child'])\n",
    "sp=_assign_dtype(sp, meta['parent'])\n",
    "sc=_assign_dtype(sc, meta['child'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define default parameters\n",
    "DFLT_PARAMS={\n",
    "    'AGG_OPS':{'AVG':0.5, 'SUM':0.3, 'MAX':0.1, 'MIN':0.1 },\n",
    "    'LOGIC_OPS':{'AND':0.9,'OR':0.1},\n",
    "    'NOT_STATE':{'0':0.8, '1':0.2},\n",
    "    'CAT_OPS':{'=':0.25, '<>':0.25, 'LIKE':0.15, 'IN':0.15, 'NOT LIKE':0.1, 'NOT IN':0.1},\n",
    "    'CNT_OPS':{'=':0.2, '>':0.1, '<':0.1, '>=':0.1, '<=':0.1, '<>':0.1, 'BETWEEN':0.2, 'NOT BETWEEN':0.1},\n",
    "    'DT_OPS':{'=':0.2, '>':0.1, '<':0.1, '>=':0, '<=':0, '<>':0.1, 'BETWEEN':0.2, 'IN':0.1, 'NOT BETWEEN':0.1, 'NOT IN':0.1},\n",
    "    'LESS_GRP_VARS': False, # enforce bias in random queries toward smaller number of groupby vars. Default is no bias (i.e. uniform sampling)\n",
    "    'LESS_CMP_VARS':False, # enforce bias in random queries toward small number of  comparison terms. Default is no bias (i.e. uniform sampling)\n",
    "    'JOIN_CNDTN':{'WHERE':0.5, 'AND':0.5} #Use WHERE or AND with JOIN CLAUSE\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table sample_r_b already exists in the database\n",
      "Table sample_r_l already exists in the database\n",
      "Table sample_s_b already exists in the database\n",
      "Table sample_s_l already exists in the database\n"
     ]
    }
   ],
   "source": [
    "# import real data into database\n",
    "conn = sqlite3.connect('fuzzy_sql.db')\n",
    "make_table('sample_r_b', rp, conn)\n",
    "make_table('sample_r_l', rc, conn)\n",
    "make_table('sample_s_b', sp, conn)\n",
    "make_table('sample_s_l', sc, conn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "self=LONG_QUERY(conn,'sample_r_b','sample_r_l', meta,DFLT_PARAMS)\n",
    "smk1=self.make_single_agg_query()\n",
    "T_smk1=self.make_twin_agg_query('sample_s_b','sample_s_l')\n",
    "smk2=self.make_single_agg_query_w_aggfntn()\n",
    "T_smk2=self.make_twin_agg_query_w_aggfntn('sample_s_b','sample_s_l')\n",
    "smk3=self.make_single_fltr_query()\n",
    "T_smk3=self.make_twin_fltr_query('sample_s_b','sample_s_l')\n",
    "smk4=self.make_single_aggfltr_query()\n",
    "T_smk4=self.make_twin_aggfltr_query('sample_s_b', 'sample_s_l')\n",
    "smk5=self.make_single_aggfltr_query_w_aggfntn()\n",
    "T_smk5=self.make_twin_aggfltr_query_w_aggfntn('sample_s_b', 'sample_s_l')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.env_dev': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cf594385e3e378fbba23be52d8fa8a1ff0f44816650af8bcee05fc5c8211531"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
