{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/samer/projects/fuzzy_sql/src') #This will enable reading the modules\n",
    "from fuzzy_sql.fuzzy_sql import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _assign_dtype(df, dict):\n",
    "    #Correct dtypes of real and syn dataframes before saving in the database \n",
    "    #map metaddata into dtype dict with pandas dtypes\n",
    "    #cols in df shall match keys in in_dict\n",
    "    assert bool(set(df.columns).intersection(set(dict.keys())))\n",
    "    out_dict={}\n",
    "    for key in dict:\n",
    "        if dict[key] in ['quantitative','continuous','interval','ratio']:\n",
    "            out_dict[key]='float64'\n",
    "        elif dict[key] in ['date','time','datetime']:\n",
    "            out_dict[key]='datetime64'\n",
    "        else:\n",
    "            out_dict[key]='category'\n",
    "    \n",
    "    for col in df.columns:\n",
    "        df[col]=df[col].astype(out_dict[col])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import exception\n",
    "\n",
    "\n",
    "class LONG_QUERY():\n",
    "    \"\"\" Generates random queries for baseline-longitudinal datasets. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, db_conn: object, parent_tbl_name: str, child_tbl_name: str, metadata: dict,params: dict , seed=False):\n",
    "        \"\"\" \n",
    "        Args:\n",
    "            db_conn: The connection object of the sqlite database where the data exists.\n",
    "            parent_tbl_name: The name of the parent table (i.e. baseline data) in the database.\n",
    "            child_tbl_name: The name of the child table (i.e. longitudinal data) in the database.\n",
    "            metadata: A dictionary that includes table's variable names (i.e. column names) as keys and types of variables as values. THey types shall be restricted to: 'continuous', 'data' and 'nominal'. Any table shall have at least one nominal variable.\n",
    "            params: A dictionary that includes the set of parameters that are necessary for generating the random queries. \n",
    "            seed: If set to True, generated random queries become deterministic. \n",
    "        \"\"\"\n",
    "        self.SEED=seed\n",
    "        self.seed_no=141\n",
    "\n",
    "        self.CUR = db_conn.cursor()\n",
    "        self.PARENT_NAME = parent_tbl_name #RP = Real Parent\n",
    "        self.CHILD_NAME = child_tbl_name #RC = Real Child\n",
    "        self.metadata=copy.deepcopy(metadata)\n",
    "        \n",
    "        #Fetch Real data (both parent and child)\n",
    "        self.PARENT_DF=pd.read_sql_query(f'SELECT * FROM {self.PARENT_NAME}', db_conn) #Real Parent Dataframe\n",
    "        self.CHILD_DF=pd.read_sql_query(f'SELECT * FROM {self.CHILD_NAME}', db_conn) #Real Child Dataframe\n",
    "\n",
    "\n",
    "        #Get foreign key name\n",
    "        self.FKEY_NAME=self.metadata['key']\n",
    "\n",
    "        #Delete foreign key from child variables to avoid repetition of variable in various expression\n",
    "        del self.metadata['child'][self.FKEY_NAME]\n",
    "\n",
    "\n",
    "        #Segregate variables into lists based on their types\n",
    "        self.CAT_VARS={} #Parent Categorical Variables\n",
    "        self.CNT_VARS={}\n",
    "        self.DT_VARS={}\n",
    "        self.CAT_VARS['parent']=[key for key, value in self.metadata['parent'].items() if value in ['qualitative','categorical','nominal','discrete','ordinal','dichotomous']]\n",
    "        self.CAT_VARS['child']=[key for key, value in self.metadata['child'].items() if value in ['qualitative','categorical','nominal','discrete','ordinal','dichotomous']]\n",
    "        self.CNT_VARS['parent']=[key for key, value in self.metadata['parent'].items() if value in ['quantitative','continuous','interval','ratio']]\n",
    "        self.CNT_VARS['child']=[key for key, value in self.metadata['child'].items() if value in ['quantitative','continuous','interval','ratio']]\n",
    "        self.DT_VARS['parent']=[key for key, value in self.metadata['parent'].items() if value in ['date','time','datetime']]\n",
    "        self.DT_VARS['child']=[key for key, value in self.metadata['child'].items() if value in ['date','time','datetime']]\n",
    "\n",
    "\n",
    "\n",
    "        # Aggregate function applies only when there is at least one continuous variable \n",
    "        self.AGG_FNCTN=True if len(self.CNT_VARS['parent'])!=0 or len(self.CNT_VARS['child'])!=0 else False\n",
    "\n",
    "        # Define random query attributes\n",
    "        self.ATTRS=params #General attributes that can be set by the user\n",
    "\n",
    "\n",
    "        # Generate dictionaries of bags for various variables\n",
    "        self.CAT_VAL_BAGS={}\n",
    "        self.CNT_VAL_BAGS={}\n",
    "        self.DT_VAL_BAGS={}\n",
    "        self.CAT_VAL_BAGS['parent']=self._make_bags(self.PARENT_DF[self.CAT_VARS['parent']])\n",
    "        self.CNT_VAL_BAGS['parent']=self._make_bags(self.PARENT_DF[self.CNT_VARS['parent']])\n",
    "        self.DT_VAL_BAGS['parent']=self._make_bags(self.PARENT_DF[self.DT_VARS['parent']])\n",
    "        self.CAT_VAL_BAGS['child']=self._make_bags(self.CHILD_DF[self.CAT_VARS['child']])\n",
    "        self.CNT_VAL_BAGS['child']=self._make_bags(self.CHILD_DF[self.CNT_VARS['child']])\n",
    "        self.DT_VAL_BAGS['child']=self._make_bags(self.CHILD_DF[self.DT_VARS['child']])\n",
    "        \n",
    "        self.max_no_in_terms=5 #Maximum number of n terms (set it to 0 if you do not want to impose any limit)\n",
    "\n",
    "    def _make_bags(self,df:pd.DataFrame)-> dict:\n",
    "        val_bags={}\n",
    "        for var in df.columns:\n",
    "            vals=df[var].values\n",
    "            vals=[x for x in vals if x==x] #drop nan\n",
    "            vals=list(filter(None, vals)) #drop None\n",
    "            val_bags[var]=vals if len(vals)!=0 else ['N/A']\n",
    "        return val_bags\n",
    "\n",
    "    def make_query(self,cur: object, query_exp: str)-> pd.DataFrame:\n",
    "        cur.execute(query_exp)\n",
    "        query = cur.fetchall()\n",
    "        query=pd.DataFrame(query, columns=[description[0] for description in cur.description])\n",
    "        return query\n",
    "\n",
    "    # def _get_var_idx(self, var_name):\n",
    "    #     if var_name in self.PARENT_DF.columns: #search in parent\n",
    "    #         idx=self.PARENT_DF.columns.get_loc(var_name)\n",
    "    #         return 'parent',idx\n",
    "    #     elif var_name in self.CHILD_DF.columns: #search in child\n",
    "    #         idx=self.CHILD_DF.columns.get_loc(var_name)\n",
    "    #         return 'child', idx\n",
    "    #     else:\n",
    "    #         raise Exception(f\"{var_name} not found in parent or child tables!\")\n",
    "\n",
    "    def _mix_vars(self,*args):\n",
    "        #accepts variable length of arguments as tuples where each tuple consists of the table name and some variables that belong to that table\n",
    "        # returns mixed variables in one list but each variable is concatenated with its respective table name\n",
    "        mixed_vars=[]\n",
    "        for arg in args:\n",
    "            vars=[arg[0]+'.'+x for x in arg[1]]\n",
    "            mixed_vars+=vars\n",
    "        return mixed_vars\n",
    "\n",
    "    def _get_twin_lst(self, in_lst: list,in_parent_name: str, out_parent_name: str, in_child_name: str, out_child_name: str)-> list:\n",
    "        # replaces the table names of teh real dataset by the table names of the synthetic datasets.\n",
    "        out_lst=[var.replace(in_parent_name,out_parent_name ) for var in in_lst] \n",
    "        out_lst=[var.replace(in_child_name,out_child_name ) for var in out_lst] \n",
    "        return out_lst\n",
    "\n",
    "    def _get_rnd_groupby_lst(self)-> list:\n",
    "        #returned randomly picked cat vars including the concatenated table name of the real data (ie that is defined in teh class)\n",
    "        #Note: You can group by CAT_VARS whether from parent or child or both\n",
    "        if self.SEED:\n",
    "            np.random.seed(self.seed_no)\n",
    "            random.seed(self.seed_no)\n",
    "        all_cat_vars=self._mix_vars((self.PARENT_NAME,self.CAT_VARS['parent']),(self.CHILD_NAME,self.CAT_VARS['child']))\n",
    "        # parent_cat_vars=[self.PARENT_NAME+'.'+x for x in self.CAT_VARS['parent']]\n",
    "        # child_cat_vars=[self.CHILD_NAME+'.'+x for x in self.CAT_VARS['child']]\n",
    "        # all_cat_vars=parent_cat_vars +child_cat_vars\n",
    "        n_vars_bag=np.arange(1, 1+len(all_cat_vars)) \n",
    "        if self.ATTRS['LESS_GRP_VARS']:#define slope-down discrete distribution \n",
    "            n_var_probs=n_vars_bag[::-1]/n_vars_bag.sum()\n",
    "            # n_var_probs= np.zeros_like(n_vars_bag)\n",
    "            # n_var_probs[0]=1\n",
    "            n_vars=np.random.choice(n_vars_bag, p=n_var_probs)\n",
    "        else:\n",
    "            n_vars=np.random.choice(n_vars_bag)\n",
    "        picked_vars = random.sample(all_cat_vars, n_vars)\n",
    "        return picked_vars\n",
    "\n",
    "\n",
    "    def _get_rnd_aggfntn_tpl(self) -> tuple:\n",
    "        #returns a random tuple of agg function and continuous OR date variable \n",
    "        # Note: continuous variable can be from either parent or child tables \n",
    "        if self.SEED:\n",
    "            np.random.seed(self.seed_no)\n",
    "            random.seed(self.seed_no)\n",
    "        all_possible_vars=self._mix_vars((self.PARENT_NAME,self.CNT_VARS['parent']),(self.PARENT_NAME,self.DT_VARS['parent']),(self.CHILD_NAME,self.CNT_VARS['child']),(self.CHILD_NAME,self.DT_VARS['child']))\n",
    "        picked_var=np.random.choice(all_possible_vars)\n",
    "        picked_op=np.random.choice(list(self.ATTRS['AGG_OPS'].keys()), p=list(self.ATTRS['AGG_OPS'].values()))\n",
    "        return (picked_op,picked_var)\n",
    "\n",
    "    \n",
    "    def _get_rnd_where_lst(self) -> tuple:\n",
    "        # use WHERE with mix of CAT, CNT, DT variables from both PARENT and CHILD\n",
    "        if self.SEED:\n",
    "            np.random.seed(self.seed_no)\n",
    "            random.seed(self.seed_no)\n",
    "        all_possible_vars=self._mix_vars((self.PARENT_NAME,self.CAT_VARS['parent']),(self.CHILD_NAME,self.CAT_VARS['child']),(self.PARENT_NAME,self.CNT_VARS['parent']),(self.CHILD_NAME,self.CNT_VARS['child']),(self.PARENT_NAME,self.DT_VARS['parent']),(self.CHILD_NAME,self.DT_VARS['child']))\n",
    "        n_vars_bag=np.arange(1, 1+len(all_possible_vars)) #this gives possible number of terms in the where clause\n",
    "        if self.ATTRS['LESS_CMP_VARS']:#define slope-down discrete distribution \n",
    "            n_var_probs=n_vars_bag[::-1]/n_vars_bag.sum()\n",
    "            # n_var_probs= np.zeros_like(n_vars_bag)\n",
    "            # n_var_probs[0]=1\n",
    "            n_vars=np.random.choice(n_vars_bag, p=n_var_probs)\n",
    "        else:\n",
    "            n_vars=np.random.choice(n_vars_bag)\n",
    "        picked_vars = random.sample(all_possible_vars, n_vars)\n",
    "\n",
    "        all_cat_vars=np.concatenate(list(self.CAT_VARS.values()))\n",
    "        all_cnt_vars=np.concatenate(list(self.CNT_VARS.values()))\n",
    "        all_dt_vars=np.concatenate(list(self.DT_VARS.values()))\n",
    "        terms=[]\n",
    "        log_ops=[]\n",
    "        for long_var_name in picked_vars: #This loop will find the a proper random value comparison operation and proper random value for all the picked variables\n",
    "            #var=long_var_name[long_var_name.find(\".\")+1:]\n",
    "            x=long_var_name.split(\".\") #Note is assumed that variable names do NOT include any \".\"\n",
    "            var_tbl=x[0]\n",
    "            var=x[1]\n",
    "            var_tbl_rank='parent' if var_tbl==self.PARENT_NAME else 'child'\n",
    "            \n",
    "            #adding not to long variable name \n",
    "            not_status=np.random.choice(list(self.ATTRS['NOT_STATE'].keys()), p=list(self.ATTRS['NOT_STATE'].values()) )\n",
    "            selected_long_var_name= 'NOT '+long_var_name if not_status=='1' else long_var_name\n",
    "            \n",
    "            if var in all_cat_vars:\n",
    "                picked_cmp_op=np.random.choice(list(self.ATTRS['CAT_OPS'].keys()),p=list(self.ATTRS['CAT_OPS'].values()))\n",
    "                if picked_cmp_op=='IN' or picked_cmp_op=='NOT IN' :\n",
    "                    possible_no_of_in_terms=np.arange(2,len(self.CAT_VAL_BAGS[var_tbl_rank][var]))\n",
    "                    no_of_in_terms=np.min([np.random.choice(possible_no_of_in_terms),self.max_no_in_terms]) if self.max_no_in_terms != 0 else np.random.choice(possible_no_of_in_terms)\n",
    "                    vals=np.random.choice(self.CAT_VAL_BAGS[var_tbl_rank][var], size=no_of_in_terms)\n",
    "                    if picked_cmp_op=='IN':\n",
    "                        term =f\" {selected_long_var_name} IN {tuple(vals)} \"\n",
    "                    else:\n",
    "                        term=f\" {selected_long_var_name} NOT IN {tuple(vals)} \"\n",
    "                else:\n",
    "                    val=np.random.choice(self.CAT_VAL_BAGS[var_tbl_rank][var])\n",
    "                    term=f\" {selected_long_var_name} {picked_cmp_op} {val} \"\n",
    "            \n",
    "            elif var in all_cnt_vars:\n",
    "                picked_cmp_op=np.random.choice(list(self.ATTRS['CNT_OPS'].keys()),p=list(self.ATTRS['CNT_OPS'].values()))\n",
    "                if picked_cmp_op=='BETWEEN' or picked_cmp_op=='NOT BETWEEN':\n",
    "                    lower_bound_bag=self.CNT_VAL_BAGS[var_tbl_rank][var]\n",
    "                    lower_bound=np.random.choice(lower_bound_bag)\n",
    "                    upper_bound_bag=[x for x in lower_bound_bag if x>=lower_bound]\n",
    "                    upper_bound=np.random.choice(upper_bound_bag)\n",
    "                    if picked_cmp_op=='BETWEEN':\n",
    "                        term=f\" {selected_long_var_name} BETWEEN {lower_bound} AND {upper_bound} \"\n",
    "                    else:\n",
    "                        term=f\" {selected_long_var_name} NOT BETWEEN {lower_bound} AND {upper_bound} \"\n",
    "                else:\n",
    "                    val=np.random.choice(self.CNT_VAL_BAGS[var_tbl_rank][var])\n",
    "                    term=f\" {selected_long_var_name} {picked_cmp_op} {val} \"\n",
    "            \n",
    "            elif var in all_dt_vars:\n",
    "                picked_cmp_op=np.random.choice(list(self.ATTRS['DT_OPS'].keys()),p=list(self.ATTRS['DT_OPS'].values()))\n",
    "                if picked_cmp_op=='BETWEEN':\n",
    "                    pass\n",
    "                elif picked_cmp_op=='IN':\n",
    "                    pass\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                raise Exception(f\"Can not find {var} in the lists of all variables!!\")\n",
    "            \n",
    "            terms.append(term)\n",
    "        \n",
    "        selected_logic_ops=np.random.choice(list(self.ATTRS['LOGIC_OPS'].keys()), size=len(terms)-1, p=list(self.ATTRS['LOGIC_OPS'].values()))\n",
    "        return terms, selected_logic_ops\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "    def _build_agg_expr(self,  pname: str, cname: str, fkey: str, groupby_lst: list) -> str:\n",
    "        expr1=f'SELECT *,COUNT(*) FROM {pname} JOIN {cname} ON {pname}.{fkey} = {cname}.{fkey}'\n",
    "        expr2_1=' GROUP BY '\n",
    "        expr2_2=f'{groupby_lst}'\n",
    "        expr2_2=expr2_2.replace(\"[\",\"\")\n",
    "        expr2_2=expr2_2.replace(\"]\",\"\")\n",
    "        expr2_2=expr2_2.replace(\"'\",\"\")\n",
    "        return expr1+expr2_1+expr2_2\n",
    "\n",
    "    \n",
    "    def make_single_agg_query(self) -> dict:\n",
    "        dic={}\n",
    "        single_grp_lst=self._get_rnd_groupby_lst()\n",
    "        single_expr=self._build_agg_expr(self.PARENT_NAME, self.CHILD_NAME,self.FKEY_NAME, single_grp_lst)\n",
    "        query=self.make_query(self.CUR, single_expr)\n",
    "        dic['query']=query\n",
    "        dic['query_desc']={\n",
    "            \"type\":\"single_agg\",\n",
    "            \"sql\":single_expr,\n",
    "            \"n_rows\":query.shape[0],\n",
    "            \"n_cols\":query.shape[1]\n",
    "        }\n",
    "        return dic\n",
    "\n",
    "    def make_twin_agg_query(self, twin_parent_name, twin_child_name):\n",
    "        dic={}\n",
    "        real_grp_lst =self._get_rnd_groupby_lst()\n",
    "        syn_grp_lst=self._get_twin_lst(real_grp_lst, self.PARENT_NAME,twin_parent_name, self.CHILD_NAME,twin_child_name)\n",
    "        real_expr=self._build_agg_expr(self.PARENT_NAME, self.CHILD_NAME,self.FKEY_NAME, real_grp_lst)\n",
    "        syn_expr=self._build_agg_expr(twin_parent_name, twin_child_name,self.FKEY_NAME, syn_grp_lst)\n",
    "        query_real=self.make_query(self.CUR, real_expr)\n",
    "        query_syn=self.make_query(self.CUR, syn_expr)\n",
    "        dic['query_real']=query_real\n",
    "        dic['query_syn']=query_syn\n",
    "        dic['query_desc']={\n",
    "            \"type\":\"twin_agg\",\n",
    "            \"sql_real\":real_expr,\n",
    "            \"n_cols_real\":query_real.shape[1],\n",
    "            \"n_rows_real\":query_real.shape[0],\n",
    "            \"sql_syn\":syn_expr,\n",
    "            \"n_cols_syn\":query_syn.shape[1],\n",
    "            \"n_rows_syn\":query_syn.shape[0],\n",
    "        }\n",
    "        return dic\n",
    "\n",
    "#-------------------------------------------------------------------------------------------\n",
    "\n",
    "    def _build_agg_expr_w_aggfntn(self,pname: str, cname: str, fkey: str, agg_fntn_tpl: tuple, groupby_lst: list) -> str:\n",
    "        expr1=f'SELECT *,COUNT(*), {agg_fntn_tpl[0]}({agg_fntn_tpl[1]}) FROM {pname} JOIN {cname} ON {pname}.{fkey} = {cname}.{fkey}'\n",
    "        expr2_1=' GROUP BY '\n",
    "        expr2_2=f'{groupby_lst}'\n",
    "        expr2_2=expr2_2.replace(\"[\",\"\")\n",
    "        expr2_2=expr2_2.replace(\"]\",\"\")\n",
    "        expr2_2=expr2_2.replace(\"'\",\"\")\n",
    "        expr=expr1+expr2_1+expr2_2\n",
    "        return expr\n",
    "    \n",
    "\n",
    "    def make_single_agg_query_w_aggfntn(self):\n",
    "        dic={}\n",
    "        single_grp_lst=self._get_rnd_groupby_lst()\n",
    "        agg_fntn_tpl=self._get_rnd_aggfntn_tpl()\n",
    "        expr=self._build_agg_expr_w_aggfntn(self.PARENT_NAME,self.CHILD_NAME, self.FKEY_NAME,agg_fntn_tpl,single_grp_lst)\n",
    "        query=self.make_query(self.CUR, expr)\n",
    "        dic['query']=query\n",
    "        dic['query_desc']={\n",
    "            \"type\":\"single_agg\",\n",
    "            \"sql\":expr,\n",
    "            \"n_rows\":query.shape[0],\n",
    "            \"n_cols\":query.shape[1]\n",
    "        }\n",
    "        return dic\n",
    "\n",
    "    def make_twin_agg_query_w_aggfntn(self,twintbl_parent_name,twintbl_child_name):\n",
    "        dic={}\n",
    "        real_groupby_lst=self._get_rnd_groupby_lst()\n",
    "        syn_groupby_lst=self._get_twin_lst(real_groupby_lst, self.PARENT_NAME,twintbl_parent_name, self.CHILD_NAME, twintbl_child_name)\n",
    "        real_aggfntn_tpl=self._get_rnd_aggfntn_tpl()\n",
    "        syn_aggfntn_tpl=self._get_twin_lst(real_aggfntn_tpl, self.PARENT_NAME,twintbl_parent_name, self.CHILD_NAME, twintbl_child_name)\n",
    "        real_expr=self._build_agg_expr_w_aggfntn(self.PARENT_NAME,self.CHILD_NAME,self.FKEY_NAME,real_aggfntn_tpl, real_groupby_lst)\n",
    "        syn_expr=self._build_agg_expr_w_aggfntn(twintbl_parent_name,twintbl_child_name,self.FKEY_NAME,syn_aggfntn_tpl, syn_groupby_lst)\n",
    "        query_real=self.make_query(self.CUR, real_expr)\n",
    "        query_syn=self.make_query(self.CUR, syn_expr)\n",
    "        dic['query_real']=query_real\n",
    "        dic['query_syn']=query_syn\n",
    "        dic['query_desc']={\n",
    "            \"type\":\"twin_agg\",\n",
    "            \"sql_real\":real_expr,\n",
    "            \"n_cols_real\":query_real.shape[1],\n",
    "            \"n_rows_real\":query_real.shape[0],\n",
    "            \"sql_syn\":syn_expr,\n",
    "            \"n_cols_syn\":query_syn.shape[1],\n",
    "            \"n_rows_syn\":query_syn.shape[0],\n",
    "            }\n",
    "        return dic\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "    def _build_fltr_expr(self,  pname: str, cname: str, fkey: str, where_terms: list, log_ops:list ) -> str:\n",
    "        expr1=f'SELECT * FROM {pname} JOIN {cname} ON {pname}.{fkey} = {cname}.{fkey} WHERE '\n",
    "        where_expr=[None]*(len(where_terms)+len(log_ops))\n",
    "        where_expr[::2]=where_terms\n",
    "        where_expr[1::2]=log_ops\n",
    "        where_expr=' '.join(x for x in where_expr )\n",
    "        where_expr=where_expr + ' '\n",
    "        return expr1+where_expr\n",
    "\n",
    "\n",
    "    def make_single_fltr_query(self) -> dict:\n",
    "        dic={}\n",
    "        where_terms, log_ops=self._get_rnd_where_lst()\n",
    "        single_expr=self._build_fltr_expr(self.PARENT_NAME,self.CHILD_NAME, self.FKEY_NAME, where_terms, log_ops)\n",
    "        query=self.make_query(self.CUR, single_expr)\n",
    "        dic['query']=query\n",
    "        dic['query_desc']={\n",
    "            \"type\":\"single_fltr\",\n",
    "            \"sql\":single_expr,\n",
    "            \"n_rows\":query.shape[0],\n",
    "            \"n_cols\":query.shape[1]\n",
    "        }\n",
    "        return dic\n",
    "\n",
    "    def make_twin_fltr_query(self, twin_parent_name: str, twin_child_name:str) -> dict:\n",
    "        dic={}\n",
    "        real_where_terms, log_ops =self._get_rnd_where_lst()\n",
    "        syn_where_terms=self._get_twin_lst(real_where_terms, self.PARENT_NAME,twin_parent_name, self.CHILD_NAME,twin_child_name)\n",
    "        real_expr=self._build_fltr_expr(self.PARENT_NAME, self.CHILD_NAME,self.FKEY_NAME, real_where_terms, log_ops)\n",
    "        syn_expr=self._build_fltr_expr(twin_parent_name, twin_child_name,self.FKEY_NAME, syn_where_terms,log_ops)\n",
    "        query_real=self.make_query(self.CUR, real_expr)\n",
    "        query_syn=self.make_query(self.CUR, syn_expr)\n",
    "        dic['query_real']=query_real\n",
    "        dic['query_syn']=query_syn\n",
    "        dic['query_desc']={\n",
    "            \"type\":\"twin_fltr\",\n",
    "            \"sql_real\":real_expr,\n",
    "            \"n_cols_real\":query_real.shape[1],\n",
    "            \"n_rows_real\":query_real.shape[0],\n",
    "            \"sql_syn\":syn_expr,\n",
    "            \"n_cols_syn\":query_syn.shape[1],\n",
    "            \"n_rows_syn\":query_syn.shape[0],\n",
    "        }\n",
    "        return dic\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "    def _build_aggfltr_expr(self,  pname: str, cname: str, fkey: str, groupby_lst: list, where_terms: list, log_ops: list) -> str:\n",
    "        expr1=f'SELECT *,COUNT(*) FROM {pname} JOIN {cname} ON {pname}.{fkey} = {cname}.{fkey} '\n",
    "        expr2=np.random.choice(list(self.ATTRS['JOIN_CNDTN'].keys()), p=list(self.ATTRS['JOIN_CNDTN'].values()))+' '\n",
    "        expr2_1=[None]*(len(where_terms)+len(log_ops))\n",
    "        expr2_1[::2]=where_terms\n",
    "        expr2_1[1::2]=log_ops\n",
    "        expr2_1=' '.join(x for x in expr2_1)\n",
    "        expr2_1='('+expr2_1+')' \n",
    "        expr3_1=' GROUP BY '\n",
    "        expr3_2=f'{groupby_lst}'\n",
    "        expr3_2=expr3_2.replace(\"[\",\"\")\n",
    "        expr3_2=expr3_2.replace(\"]\",\"\")\n",
    "        expr3_2=expr3_2.replace(\"'\",\"\")\n",
    "        return expr1+expr2+expr2_1+expr3_1+expr3_2\n",
    "\n",
    "\n",
    "    def make_single_aggfltr_query(self) -> dict:\n",
    "        dic={}\n",
    "        grp_lst=self._get_rnd_groupby_lst()\n",
    "        where_terms, log_ops=self._get_rnd_where_lst()\n",
    "        single_expr=self._build_aggfltr_expr(self.PARENT_NAME, self.CHILD_NAME, self.FKEY_NAME,grp_lst, where_terms,log_ops )\n",
    "        query=self.make_query(self.CUR, single_expr)\n",
    "        dic['query']=query\n",
    "        dic['query_desc']={\n",
    "            \"type\":\"single_aggfltr\",\n",
    "            \"sql\":single_expr,\n",
    "            \"n_rows\":query.shape[0],\n",
    "            \"n_cols\":query.shape[1]\n",
    "        }\n",
    "        return dic\n",
    "\n",
    "\n",
    "    def make_twin_aggfltr_query(self, twin_parent_name: str, twin_child_name:str) -> dict:\n",
    "        dic={}\n",
    "        \n",
    "        real_grp_lst =self._get_rnd_groupby_lst()\n",
    "        syn_grp_lst=self._get_twin_lst(real_grp_lst, self.PARENT_NAME,twin_parent_name, self.CHILD_NAME,twin_child_name)\n",
    "\n",
    "        real_where_terms, log_ops =self._get_rnd_where_lst()\n",
    "        syn_where_terms=self._get_twin_lst(real_where_terms, self.PARENT_NAME,twin_parent_name, self.CHILD_NAME,twin_child_name)\n",
    "        \n",
    "        real_expr=self._build_aggfltr_expr(self.PARENT_NAME, self.CHILD_NAME, self.FKEY_NAME,real_grp_lst, real_where_terms,log_ops)\n",
    "        syn_expr=self._build_aggfltr_expr(twin_parent_name, twin_child_name, self.FKEY_NAME,syn_grp_lst, syn_where_terms,log_ops)\n",
    "\n",
    "        query_real=self.make_query(self.CUR, real_expr)\n",
    "        query_syn=self.make_query(self.CUR, syn_expr)\n",
    "        dic['query_real']=query_real\n",
    "        dic['query_syn']=query_syn\n",
    "        dic['query_desc']={\n",
    "            \"type\":\"twin_aggfltr\",\n",
    "            \"sql_real\":real_expr,\n",
    "            \"n_cols_real\":query_real.shape[1],\n",
    "            \"n_rows_real\":query_real.shape[0],\n",
    "            \"sql_syn\":syn_expr,\n",
    "            \"n_cols_syn\":query_syn.shape[1],\n",
    "            \"n_rows_syn\":query_syn.shape[0],\n",
    "        }\n",
    "        return dic\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------\n",
    "\n",
    "    def _build_aggfltr_expr_w_aggfntn(self,pname: str, cname: str, fkey: str, agg_fntn_tpl: tuple, groupby_lst: list, where_terms: list, log_ops: list) -> str:\n",
    "        expr1=f'SELECT *,COUNT(*), {agg_fntn_tpl[0]}({agg_fntn_tpl[1]}) FROM {pname} JOIN {cname} ON {pname}.{fkey} = {cname}.{fkey} '\n",
    "        expr2=np.random.choice(list(self.ATTRS['JOIN_CNDTN'].keys()), p=list(self.ATTRS['JOIN_CNDTN'].values()))+' '\n",
    "        expr2_1=[None]*(len(where_terms)+len(log_ops))\n",
    "        expr2_1[::2]=where_terms\n",
    "        expr2_1[1::2]=log_ops\n",
    "        expr2_1=' '.join(x for x in expr2_1)\n",
    "        expr2_1='('+expr2_1+')' \n",
    "        expr3_1=' GROUP BY '\n",
    "        expr3_2=f'{groupby_lst}'\n",
    "        expr3_2=expr3_2.replace(\"[\",\"\")\n",
    "        expr3_2=expr3_2.replace(\"]\",\"\")\n",
    "        expr3_2=expr3_2.replace(\"'\",\"\")\n",
    "        return expr1+expr2+expr2_1+expr3_1+expr3_2\n",
    "\n",
    "\n",
    "\n",
    "    def make_single_aggfltr_query_w_aggfntn(self) -> dict:\n",
    "        dic={}\n",
    "        agg_fntn_tpl=self._get_rnd_aggfntn_tpl()\n",
    "        grp_lst=self._get_rnd_groupby_lst()\n",
    "        where_terms, log_ops=self._get_rnd_where_lst()\n",
    "        single_expr=self._build_aggfltr_expr_w_aggfntn(self.PARENT_NAME, self.CHILD_NAME, self.FKEY_NAME,agg_fntn_tpl,grp_lst, where_terms,log_ops )\n",
    "        query=self.make_query(self.CUR, single_expr)\n",
    "        dic['query']=query\n",
    "        dic['query_desc']={\n",
    "            \"type\":\"single_aggfltr\",\n",
    "            \"sql\":single_expr,\n",
    "            \"n_rows\":query.shape[0],\n",
    "            \"n_cols\":query.shape[1]\n",
    "        }\n",
    "        return dic\n",
    "\n",
    "\n",
    "\n",
    "    def make_twin_aggfltr_query_w_aggfntn(self, twin_parent_name: str, twin_child_name:str) -> dict:\n",
    "        dic={}\n",
    "        real_agg_fntn_tpl=self._get_rnd_aggfntn_tpl()\n",
    "        syn_agg_fntn_tpl=tuple(self._get_twin_lst(real_agg_fntn_tpl, self.PARENT_NAME,twin_parent_name, self.CHILD_NAME,twin_child_name))\n",
    "\n",
    "        real_grp_lst =self._get_rnd_groupby_lst()\n",
    "        syn_grp_lst=self._get_twin_lst(real_grp_lst, self.PARENT_NAME,twin_parent_name, self.CHILD_NAME,twin_child_name)\n",
    "\n",
    "        real_where_terms, log_ops =self._get_rnd_where_lst()\n",
    "        syn_where_terms=self._get_twin_lst(real_where_terms, self.PARENT_NAME,twin_parent_name, self.CHILD_NAME,twin_child_name)\n",
    "\n",
    "        real_expr=self._build_aggfltr_expr_w_aggfntn(self.PARENT_NAME, self.CHILD_NAME, self.FKEY_NAME,real_agg_fntn_tpl,real_grp_lst, real_where_terms,log_ops )\n",
    "        syn_expr=self._build_aggfltr_expr_w_aggfntn(twin_parent_name, twin_child_name, self.FKEY_NAME,syn_agg_fntn_tpl,syn_grp_lst, syn_where_terms,log_ops )\n",
    "\n",
    "        query_real=self.make_query(self.CUR, real_expr)\n",
    "        query_syn=self.make_query(self.CUR, syn_expr)\n",
    "        dic['query_real']=query_real\n",
    "        dic['query_syn']=query_syn\n",
    "        dic['query_desc']={\n",
    "            \"type\":\"twin_aggfltr\",\n",
    "            \"sql_real\":real_expr,\n",
    "            \"n_cols_real\":query_real.shape[1],\n",
    "            \"n_rows_real\":query_real.shape[0],\n",
    "            \"sql_syn\":syn_expr,\n",
    "            \"n_cols_syn\":query_syn.shape[1],\n",
    "            \"n_rows_syn\":query_syn.shape[0],\n",
    "        }\n",
    "        return dic\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_path=\"/home/samer/projects/fuzzy_sql/data/longitudinal/ready/real/b_sample.csv\" #real parent (baseline) path \n",
    "rc_path=\"/home/samer/projects/fuzzy_sql/data/longitudinal/ready/real/l_sample.csv\" #real child (longitudinal) path \n",
    "sp_path=\"/home/samer/projects/fuzzy_sql/data/longitudinal/ready/synthetic/b_sample_syn.csv\" #synthetic parent (baseline) path \n",
    "sc_path=\"/home/samer/projects/fuzzy_sql/data/longitudinal/ready/synthetic/l_sample_syn.csv\" #synthetic child (longitudinal) path \n",
    "meta_path=\"/home/samer/projects/fuzzy_sql/data/longitudinal/ready/metadata/sample.json\" #metdata path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data frames with all variables read as string and eliminate the apostrophe  '\n",
    "rp=load_csv(rp_path) \n",
    "rp.columns=[col.replace(\".\",\"_\") for col in rp.columns] #replace dots in variable names by _ to avoid conflicts in sql naming \n",
    "rc=load_csv(rc_path) \n",
    "sp=load_csv(sp_path)  \n",
    "sc=load_csv(sc_path) \n",
    "\n",
    "rp.columns=[col.replace(\".\",\"_\") for col in rp.columns] #replace dots in variable names by _ to avoid conflicts in sql naming \n",
    "\n",
    "\n",
    "\n",
    "import _json\n",
    "with open(meta_path) as f:\n",
    "    meta=json.load(f) #metadata for the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix datatypes in loaded csv \n",
    "rp=_assign_dtype(rp, meta['parent'])\n",
    "rc=_assign_dtype(rc, meta['child'])\n",
    "sp=_assign_dtype(sp, meta['parent'])\n",
    "sc=_assign_dtype(sc, meta['child'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define default parameters\n",
    "DFLT_PARAMS={\n",
    "    'AGG_OPS':{'AVG':0.5, 'SUM':0.3, 'MAX':0.1, 'MIN':0.1 },\n",
    "    'LOGIC_OPS':{'AND':0.9,'OR':0.1},\n",
    "    'NOT_STATE':{'0':0.8, '1':0.2},\n",
    "    'CAT_OPS':{'=':0.25, '<>':0.25, 'LIKE':0.15, 'IN':0.15, 'NOT LIKE':0.1, 'NOT IN':0.1},\n",
    "    'CNT_OPS':{'=':0.2, '>':0.1, '<':0.1, '>=':0.1, '<=':0.1, '<>':0.1, 'BETWEEN':0.2, 'NOT BETWEEN':0.1},\n",
    "    'DT_OPS':{'=':0.2, '>':0.1, '<':0.1, '>=':0, '<=':0, '<>':0.1, 'BETWEEN':0.2, 'IN':0.1, 'NOT BETWEEN':0.1, 'NOT IN':0.1},\n",
    "    'LESS_GRP_VARS': False, # enforce bias in random queries toward smaller number of groupby vars. Default is no bias (i.e. uniform sampling)\n",
    "    'LESS_CMP_VARS':False, # enforce bias in random queries toward small number of  comparison terms. Default is no bias (i.e. uniform sampling)\n",
    "    'JOIN_CNDTN':{'WHERE':0.5, 'AND':0.5} #Use WHERE or AND with JOIN CLAUSE\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table sample_r_b already exists in the database\n",
      "Table sample_r_l already exists in the database\n",
      "Table sample_s_b already exists in the database\n",
      "Table sample_s_l already exists in the database\n"
     ]
    }
   ],
   "source": [
    "# import real data into database\n",
    "conn = sqlite3.connect('fuzzy_sql.db')\n",
    "make_table('sample_r_b', rp, conn)\n",
    "make_table('sample_r_l', rc, conn)\n",
    "make_table('sample_s_b', sp, conn)\n",
    "make_table('sample_s_l', sc, conn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "self=LONG_QUERY(conn,'sample_r_b','sample_r_l', meta,DFLT_PARAMS)\n",
    "smk1=self.make_single_agg_query()\n",
    "T_smk1=self.make_twin_agg_query('sample_s_b','sample_s_l')\n",
    "smk2=self.make_single_agg_query_w_aggfntn()\n",
    "T_smk2=self.make_twin_agg_query_w_aggfntn('sample_s_b','sample_s_l')\n",
    "smk3=self.make_single_fltr_query()\n",
    "T_smk3=self.make_twin_fltr_query('sample_s_b','sample_s_l')\n",
    "smk4=self.make_single_aggfltr_query()\n",
    "T_smk4=self.make_twin_aggfltr_query('sample_s_b', 'sample_s_l')\n",
    "smk5=self.make_single_aggfltr_query_w_aggfntn()\n",
    "T_smk5=self.make_twin_aggfltr_query_w_aggfntn('sample_s_b', 'sample_s_l')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'twin_aggfltr',\n",
       " 'sql_real': \"SELECT *,COUNT(*), AVG(sample_r_l.NECODE) FROM sample_r_b JOIN sample_r_l ON sample_r_b.PNUM_R = sample_r_l.PNUM_R AND ( sample_r_b.DNR <> 0  AND  sample_r_b.FEMALE <> 0  AND  sample_r_b.RACE = 3  AND  sample_r_b.PL_NCHS2 IN ('2', '1', '1', '1', '3')  AND  sample_r_b.PL_CBSA <> 2  AND  sample_r_l.TOTCHG BETWEEN 25324.0 AND 75821.0  AND  sample_r_b.NEOMAT LIKE 0  OR  sample_r_l.ASCHED <> 0  AND  NOT sample_r_l.DX1 <> 2761  AND  sample_r_b.PL_UR_CA <> 1  AND  sample_r_b.PNUM_R = 3865962  AND  NOT sample_r_l.PROCTYPE BETWEEN 1.0 AND 1.0  OR  sample_r_b.PL_RUCC2 <> 1  AND  sample_r_b.HOSPBRTH IN ('0', '0', '0', '0', '0')  AND  NOT sample_r_l.NECODE > 2.0  AND  NOT sample_r_b.PL_UIC20 NOT IN ('1', '2', '1', '1', '1')  AND  sample_r_b.AGE > 17.0  OR  sample_r_l.Date NOT BETWEEN 11.0 AND 12.0  AND  sample_r_l.MDC BETWEEN 23.0 AND 23.0  OR  sample_r_b.Homeless IN ('0', '0', '0', '0', '0')  AND  sample_r_l.LOS >= 9.0  AND  sample_r_b.DIED <> 0  OR  sample_r_l.NPR = 1.0  AND  sample_r_l.DRGVER < 24.0  AND  sample_r_b.MEDINCST IN ('2', '4', '3', '1', '1')  AND  NOT sample_r_b.HISPANIC IN ('2', '2', '2', '2', '1')  AND  sample_r_l.AWEEKEND > 1.0  OR  sample_r_l.HCUP_ED = 4.0  AND  sample_r_b.PL_RUCA4 = 1 ) GROUP BY sample_r_b.Homeless, sample_r_b.DIED, sample_r_b.HISPANIC, sample_r_b.PL_UIC20, sample_r_b.PL_CBSA, sample_r_b.PL_NCHS2, sample_r_b.PL_RUCC2, sample_r_b.MEDINCST, sample_r_b.HOSPBRTH, sample_r_b.PL_UR_CA, sample_r_b.NEOMAT\",\n",
       " 'n_cols_real': 33,\n",
       " 'n_rows_real': 293,\n",
       " 'sql_syn': \"SELECT *,COUNT(*), AVG(sample_s_l.NECODE) FROM sample_s_b JOIN sample_s_l ON sample_s_b.PNUM_R = sample_s_l.PNUM_R WHERE ( sample_s_b.DNR <> 0  AND  sample_s_b.FEMALE <> 0  AND  sample_s_b.RACE = 3  AND  sample_s_b.PL_NCHS2 IN ('2', '1', '1', '1', '3')  AND  sample_s_b.PL_CBSA <> 2  AND  sample_s_l.TOTCHG BETWEEN 25324.0 AND 75821.0  AND  sample_s_b.NEOMAT LIKE 0  OR  sample_s_l.ASCHED <> 0  AND  NOT sample_s_l.DX1 <> 2761  AND  sample_s_b.PL_UR_CA <> 1  AND  sample_s_b.PNUM_R = 3865962  AND  NOT sample_s_l.PROCTYPE BETWEEN 1.0 AND 1.0  OR  sample_s_b.PL_RUCC2 <> 1  AND  sample_s_b.HOSPBRTH IN ('0', '0', '0', '0', '0')  AND  NOT sample_s_l.NECODE > 2.0  AND  NOT sample_s_b.PL_UIC20 NOT IN ('1', '2', '1', '1', '1')  AND  sample_s_b.AGE > 17.0  OR  sample_s_l.Date NOT BETWEEN 11.0 AND 12.0  AND  sample_s_l.MDC BETWEEN 23.0 AND 23.0  OR  sample_s_b.Homeless IN ('0', '0', '0', '0', '0')  AND  sample_s_l.LOS >= 9.0  AND  sample_s_b.DIED <> 0  OR  sample_s_l.NPR = 1.0  AND  sample_s_l.DRGVER < 24.0  AND  sample_s_b.MEDINCST IN ('2', '4', '3', '1', '1')  AND  NOT sample_s_b.HISPANIC IN ('2', '2', '2', '2', '1')  AND  sample_s_l.AWEEKEND > 1.0  OR  sample_s_l.HCUP_ED = 4.0  AND  sample_s_b.PL_RUCA4 = 1 ) GROUP BY sample_s_b.Homeless, sample_s_b.DIED, sample_s_b.HISPANIC, sample_s_b.PL_UIC20, sample_s_b.PL_CBSA, sample_s_b.PL_NCHS2, sample_s_b.PL_RUCC2, sample_s_b.MEDINCST, sample_s_b.HOSPBRTH, sample_s_b.PL_UR_CA, sample_s_b.NEOMAT\",\n",
       " 'n_cols_syn': 33,\n",
       " 'n_rows_syn': 200}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_smk5['query_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "real=T_smk5['query_real']\n",
    "syn=T_smk5['query_syn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PNUM_R</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIED</th>\n",
       "      <th>DNR</th>\n",
       "      <th>FEMALE</th>\n",
       "      <th>HOSPBRTH</th>\n",
       "      <th>Homeless</th>\n",
       "      <th>HISPANIC</th>\n",
       "      <th>NEOMAT</th>\n",
       "      <th>PL_CBSA</th>\n",
       "      <th>...</th>\n",
       "      <th>NPR</th>\n",
       "      <th>TOTCHG</th>\n",
       "      <th>PROCTYPE</th>\n",
       "      <th>DX1</th>\n",
       "      <th>ASCHED</th>\n",
       "      <th>AWEEKEND</th>\n",
       "      <th>DRGVER</th>\n",
       "      <th>HCUP_ED</th>\n",
       "      <th>COUNT(*)</th>\n",
       "      <th>AVG(sample_r_l.NECODE)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12051248</td>\n",
       "      <td>62.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>882732.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85221</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13066132</td>\n",
       "      <td>52.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49071.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>V5789</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14088785</td>\n",
       "      <td>22.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8861.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9678</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1367754</td>\n",
       "      <td>58.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14183510</td>\n",
       "      <td>54.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>568188.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44101</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>2923783</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5770</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>10244187</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147870.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>V598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>13982134</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154384.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>V594</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>4244792</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>V598</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>13989988</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21624.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>430</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PNUM_R   AGE  DIED DNR FEMALE HOSPBRTH Homeless HISPANIC NEOMAT  \\\n",
       "0    12051248  62.0  None   0      0        0        0        1      0   \n",
       "1    13066132  52.0  None   0      1        0        0        1      0   \n",
       "2    14088785  22.0  None   0      1        0        0        1      0   \n",
       "3     1367754  58.0  None   0      1        0        0        2      0   \n",
       "4    14183510  54.0  None   0      0        0        0        2      0   \n",
       "..        ...   ...   ...  ..    ...      ...      ...      ...    ...   \n",
       "288   2923783  72.0     1   0      0        0        0        2      0   \n",
       "289  10244187  45.0     1   0      0        0        0        2      0   \n",
       "290  13982134  50.0     1   0      1        0        0        2      0   \n",
       "291   4244792  74.0     1   0      0        0        0        2      0   \n",
       "292  13989988  72.0     1   0      1        0        0        2      0   \n",
       "\n",
       "    PL_CBSA  ...   NPR    TOTCHG PROCTYPE    DX1 ASCHED AWEEKEND DRGVER  \\\n",
       "0         2  ...  21.0  882732.0      1.0  85221      0      1.0   24.0   \n",
       "1         2  ...   3.0   49071.0      1.0  V5789      0      0.0   24.0   \n",
       "2         2  ...   2.0    8861.0      1.0   9678      0      1.0   24.0   \n",
       "3         2  ...   0.0   19280.0      0.0  30001      0      0.0   24.0   \n",
       "4         2  ...  20.0  568188.0      1.0  44101      0      1.0   24.0   \n",
       "..      ...  ...   ...       ...      ...    ...    ...      ...    ...   \n",
       "288       2  ...   5.0       NaN      1.0   5770      0      0.0   24.0   \n",
       "289       2  ...   0.0  147870.0      0.0   V598      0      0.0   25.0   \n",
       "290       2  ...   0.0  154384.0      0.0   V594      1      0.0   25.0   \n",
       "291       2  ...   0.0       NaN      0.0   V598      1      1.0   24.0   \n",
       "292       2  ...   1.0   21624.0      1.0    430      0      0.0   25.0   \n",
       "\n",
       "    HCUP_ED  COUNT(*)  AVG(sample_r_l.NECODE)  \n",
       "0       4.0         4                2.000000  \n",
       "1       0.0         2                2.000000  \n",
       "2       4.0         1                3.000000  \n",
       "3       4.0         6                0.000000  \n",
       "4       4.0         3                0.666667  \n",
       "..      ...       ...                     ...  \n",
       "288     4.0         6                0.666667  \n",
       "289     0.0         2                1.000000  \n",
       "290     0.0         2                0.000000  \n",
       "291     0.0         6                0.333333  \n",
       "292     0.0         2                0.000000  \n",
       "\n",
       "[293 rows x 33 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    238\n",
       "1.0     55\n",
       "Name: AWEEKEND, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real['AWEEKEND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #match records\n",
    "        if len(real_idx)!=len(syn_idx):\n",
    "            missed_in_syn=real_idx.difference(syn_idx) # find missing classes in syn results\n",
    "            missed_in_real=syn_idx.difference(real_idx) # find missing classes in real results( very unlikely and it may indicate that a continuous varibale is mistakely defjned as nominal in the metadata)\n",
    "            for missed_idx in list(missed_in_syn):\n",
    "                syn_var[missed_idx]=0\n",
    "            for missed_idx in list(missed_in_real):\n",
    "                real_var[missed_idx]=0\n",
    "        # if len(real_idx)>len(syn_idx):\n",
    "        #     missing=real_idx.difference(syn_idx) #get missing index in syn\n",
    "        #     for idx in list(missing): #insert missing indices in syn \n",
    "        #         syn_var[idx]=0 #penalize it by adding zero count\n",
    "        # elif len(real_idx)<len(syn_idx):\n",
    "        #     missing=syn_idx.difference(real_idx) #do same thing with missing index in real\n",
    "        #     for idx in list(missing):  \n",
    "        #         real_var[idx]=0\n",
    "        assert len(real_var)==len(syn_var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.env_dev': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cf594385e3e378fbba23be52d8fa8a1ff0f44816650af8bcee05fc5c8211531"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
