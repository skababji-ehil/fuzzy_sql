from cmath import isnan, nan
from filecmp import cmp
from multiprocessing.sharedctypes import Synchronized
from queue import Empty
import random
import string
import pandas as pd
import numpy as np
import copy
from sklearn.preprocessing import StandardScaler


class TABULAR_QUERY():
    """This is a class used for generating random SELECT queries for a table residing  in sqlite database.
        
        Once called, various query parameters (listed below) are constructed typically in forms of dictionaries. The value entries of the dictionaries represent discrete probabilities for better model versatility. However, these probabilities can be modified only by accessing the constructor.  
        
        AGG_OPS: Aggregation functions

        LOGIC_OPS: Logic Operations

        NOT_OP_STATE: NOT operation state i.e. used or not used.

        CAT_OPS: Value comparison operations for nominal variables.

        CNT_OPS: Value comparison operations for continuous variables.

        CAT_VAL_BAG: A bag of possible values for nominal variables.

        CNT_VAL_BAG: A bag of possible values for continuous variables.

        DT_VAL_BAG: A bag of possible values for date variables.

    :param db_conn: A connection to the database that contains the table to be subjected to random queries. 
    :type db_conn: connection object created using sqlite3.connect()

    :param real_tbl_name: The name of the table to be randomly queried.
    :type real_tbl_name: String

    :param metadata: A dictionary that includes table's variable names (i.e. column names) as keys and types of variables as values. THey types shall be restricted to: 'continuous', 'data' and 'nominal'. Any table shall have at least one nominal variable.
    :type metadata: Dictionary

    """

    def __init__(self, db_conn, real_tbl_name: str, metadata: dict) -> None:

        """ Constructor method. 
        """
        self.CUR = db_conn.cursor()
        self.REAL_TBL_NAME = real_tbl_name
        self.VARS = list(metadata.keys())
        self.HLNGR_DROPNA=True #Drop non-matching records entries in the Hellinger pivot table. For Euclidean calac, we always drop non-matching records

        self.CAT_VARS = [key for key, value in metadata.items(
        ) if value == 'nominal']  # Get all categorical (nominal) var names
        self.CNT_VARS = [key for key, value in metadata.items(
        ) if value == 'continuous']  # Get all continuous var names
        self.DT_VARS = [key for key, value in metadata.items(
        ) if value == 'date']  # Get all dated var names
        
        self.AGG_FNCTN=True if self.CNT_VARS else False

        # COUNT is always included in queries
        self.AGG_OPS={'AVG':0.5, 'SUM':0.3, 'MAX':0.1, 'MIN':0.1 }
        self._agg_op_bag = list(self.AGG_OPS.keys())
        self._agg_op_wghts = list(self.AGG_OPS.values())

        self.LOGIC_OPS={'AND':0.5,'OR':0.5}
        self._logic_op_bag = list(self.LOGIC_OPS.keys())
        self._logic_op_wghts = list(self.LOGIC_OPS.values())

        # 1 means a NOT is added before the variable name
        self.NOT_OP_STATE={'0':1, '1':0}
        self._logic_not_states = [int(x) for x in list(self.NOT_OP_STATE.keys())]
        self._logic_not_wghts = list(self.NOT_OP_STATE.values())

        # Comparison operations for categorical variables; BETWEEN is excluded since it can be generated by other operations
        self.CAT_OPS={'=':0.25, '<>':0.25, 'LIKE':0.25, 'IN':0.25}
        self._cat_cmp_op_bag = list(self.CAT_OPS.keys())
        self._cat_cmp_op_wghts = list(self.CAT_OPS.values())

        # Comparison operations for continuous variables
        self.CNT_OPS={'=':0.2, '>':0.1, '<':0.1, '>=':0.1, '<=':0.1, '<>':0.1, 'BETWEEN':0.3}
        self._cnt_cmp_op_bag = list(self.CNT_OPS.keys())
        self._cnt_cmp_op_wghts = list(self.CNT_OPS.values())

        # A dictionary that holds all possible values for each categorical variable
        self.CAT_VAL_BAG = {}
        for CAT_VAR in self.CAT_VARS:
            this_var= pd.read_sql_query("SELECT `{}` FROM {}".format(CAT_VAR, self.REAL_TBL_NAME), db_conn).values.ravel()
            this_var=[x for x in this_var if x==x] #drop nan
            this_var = list(filter(None, this_var)) #drop None
            # this_var=this_var.astype(str) #make sure it is string
            # #this_var=np.unique(this_var) #drop duplicates
            self.CAT_VAL_BAG[CAT_VAR] =this_var if len(this_var)!=0  else ['N/A']


        # A dictionary that holds all possible values for each continuous variable
        self.CNT_VAL_BAG = {}
        for CNT_VAR in self.CNT_VARS:
            this_var = pd.read_sql_query("SELECT `{}` FROM {}".format(CNT_VAR, self.REAL_TBL_NAME), db_conn).values.ravel()
            this_var=[x for x in this_var if x==x] #drop nan
            this_var = list(filter(None, this_var)) #drop None
            # this_var=this_var.astype(str) #make sure it is string
            # #this_var=np.unique(this_var) #drop duplicates
            self.CNT_VAL_BAG[CNT_VAR] =this_var if len(this_var)!=0 else ['N/A']




        # A dictionary that holds all possible values for each date variable
        self.DT_VAL_BAG = {}
        for DT_VAR in self.DT_VARS:
            this_var=pd.read_sql_query("SELECT `{}` FROM {}".format(DT_VAR, self.REAL_TBL_NAME), db_conn).values.ravel()
            this_var=[x for x in this_var if x==x] #drop nan
            this_var = list(filter(None, this_var)) #drop None
            # this_var=this_var.astype(str) #make sure it is string
            # #this_var=np.unique(this_var) #drop duplicates
            self.DT_VAL_BAG[DT_VAR] =this_var if len(this_var)!=0 else ['N/A']




    def _make_agg_tmplts_c1(self, n: int) -> list:
        """ The function generates 'n' number of aggregate sql templates returning a list with length 'n'. 
        Typically, 'n' is the number of available categorical variables in a subject dataset. 
        This function needs at least one continuous variable to be present in the dataset"""
        tmplts = []
        for k in range(n):
            a = "SELECT `{}`"
            b = [",`{}`"*i for i in range(n)]
            c = ",{}(`{}`), COUNT(*) FROM {} "
            d = "GROUP BY `{}`"
            tmplts.append(a+b[k]+c+d+b[k])
        return tmplts

    def _make_agg_tmplts_c0(self, n: int) -> list:
        """ The function generates 'n' number of count sql templates returning a list with length 'n'. 
        Typically, 'n' is the number of available categorical variables in a subject dataset. 
        This function can be used if there is NO continuous variable in the dataset"""
        tmplts = []
        for k in range(n):
            a = "SELECT `{}`"
            b = [",`{}`"*i for i in range(n)]
            c = ", COUNT(*) FROM {} "
            d = "GROUP BY `{}`"
            tmplts.append(a+b[k]+c+d+b[k])
        return tmplts

    def _flatten(self, l):
        return [item for sublist in l for item in sublist]

    def _make_fltr_tmplt1_c1(self):  # where template1 case 1 with AGG function
        return "SELECT {}(`{}`), COUNT(*) FROM {} "

    def _make_fltr_tmplt1_c0(self):  # where template1 case 0 without AGG function
        return "SELECT * FROM {} "

    def _make_fltr_tmplt2(self, cmp_op_name):
        if cmp_op_name == 'BETWEEN':
            return "WHERE (`{}` {} {} AND {}) "
        else:
            return "WHERE (`{}` {} {}) "

    def _make_fltr_tmplt3(self, cmp_op_name):
        if cmp_op_name == 'BETWEEN':
            return " ((`{}` {} {} AND {}) {} "
        else:
            return "(`{}` {} {}  {}  "

    def _make_fltr_tmplt4(self, cmp_op_name):
        if cmp_op_name == 'BETWEEN':
            return " `{}` {} {} AND {})"
        else:
            return "`{}` {} {})  "

#########################################################################################

    def _make_aggfltr_tmplt_start_c1(self, n: int) -> list:
        tmplts = []
        for k in range(n):
            a = "SELECT `{}`"
            b = [",`{}`"*i for i in range(n)]
            c = ",{}(`{}`), COUNT(*) FROM {} "
            tmplts.append(a+b[k]+c)
        return tmplts

    def _make_aggfltr_tmplt_start_c0(self, n: int) -> list:
        tmplts = []
        for k in range(n):
            a = "SELECT `{}`"
            b = [",`{}`"*i for i in range(n)]
            c = ", COUNT(*) FROM {} "
            tmplts.append(a+b[k]+c)
        return tmplts


    def _make_aggfltr_tmplt_end(self, n: int) -> list:
        tmplts = []
        for k in range(n):
            b = [",`{}`"*i for i in range(n)]
            d = " GROUP BY `{}`"
            tmplts.append(d+b[k])
        return tmplts


    def _gen_single_aggfltr_expr(self, where_vars: list,  agg_fntn=True):

        n_vars = int(len(where_vars))
        if n_vars!=0: #if a WHERE clause is to be added to the aggregate query
            log_ops = random.choices(self._logic_op_bag, weights=self._logic_op_wghts, k=n_vars-1)         # sample logical operators allowing repetition
            exp_params,cmp_ops=self._sort_vars_ops(where_vars)
        real_tbl_name = self.REAL_TBL_NAME
        cat_vars = self.CAT_VARS
        cnt_vars = self.CNT_VARS
        #dt_vars=self.DT_VARS

        if agg_fntn:#case1
            tmplts_start = self._make_aggfltr_tmplt_start_c1(len(cat_vars))
        else: #case0
            tmplts_start = self._make_aggfltr_tmplt_start_c0(len(cat_vars))
        
        tmplts_end = self._make_aggfltr_tmplt_end(len(cat_vars))
        tmplts_idx = list(range(len(tmplts_start)))
        grp_rank = random.choice(tmplts_idx)

        start_tmplt = tmplts_start[grp_rank]
        end_tmplt=tmplts_end[grp_rank]

        select_cat_vars = random.sample(cat_vars, grp_rank+1) #cat variables  for the select and not for the where, you may include date in the future, just comment this line and uncomment the one below. Also uncomnent dt_var above
        #select_cat_vars = random.sample(cat_vars+dt_vars, grp_rank+1)

        if agg_fntn: #case1
            select_agg_op = random.choice(self._agg_op_bag)
            select_cnt_var = random.choice(cnt_vars)
            start_args_real = *select_cat_vars, select_agg_op, select_cnt_var, real_tbl_name
        else: #case0
            start_args_real = *select_cat_vars, real_tbl_name
        
        start_expr_real=start_tmplt.format(*start_args_real)
        end_expr_real=end_tmplt.format(*select_cat_vars)
        
        if n_vars!=0:
            mid_expr_real, query_params = self._gen_single_fltr_expr23(where_vars,log_ops, cmp_ops, exp_params)
            expr_real=start_expr_real+mid_expr_real+end_expr_real
        else:#No WHERE clause
            expr_real=start_expr_real+end_expr_real


        query_params['query_type']='aggfltr_{}'.format(int(agg_fntn))
        query_params['real_table_name']=real_tbl_name
        query_params['syn_table_name']=np.nan
        query_params['query_tmplt_idx']=grp_rank #The word 'query' refers to aggregate query arguments. The arguments of teh where clause  will start with where e.g. where_cnt_vars
        query_params['query_cat_vars']= select_cat_vars
        query_params['query_cnt_vars']=np.nan
        query_params['query_dt_vars']=np.nan
        query_params['query_cnt_var']=select_cnt_var if agg_fntn else np.nan
        query_params['query_agg_op']=select_agg_op if agg_fntn else np.nan
        query_params['query_match_vars']=select_cat_vars
        query_params['real_sql']=expr_real
        query_params['syn_sql']=np.nan

        return expr_real, query_params


    def gen_single_aggfltr_queries(self, n_rnd_queries,agg_fntn=True) -> dict:
        if agg_fntn:
            assert agg_fntn and self.CNT_VARS, "Data shall include at least one continuous variable, or set agg_fntn to False"
        cur = self.CUR
        queries = {'query_real': [],  'query_params': []}
        for k in range(n_rnd_queries):
            this_n_vars = random.randrange(1, len(self.VARS))
            this_vars = list(np.random.choice(self.VARS, size=this_n_vars, replace=False))  # Randomly pick a number of WHERE variables for the query

            real_expr, query_params = self._gen_single_aggfltr_expr(this_vars, agg_fntn=agg_fntn)

            cur.execute(real_expr)
            query_real = cur.fetchall()
            query_real_headers = [description[0] for description in cur.description]
            query_real_df = pd.DataFrame( query_real, columns=query_real_headers)

            query_params["real_n_rcrds"]= len(query_real_df),
            query_params["syn_n_rcrds"]= np.nan

            queries['query_real'].append(query_real_df)
            queries['query_params'].append(query_params)
            
            print('Generated Conditioned Aggregate Query {} '.format(str(k)))
        return queries


    def _gen_twin_aggfltr_expr(self, where_vars: list, syn_tbl_name, agg_fntn=True):

        n_vars = int(len(where_vars))
        if n_vars!=0: #if a WHERE clause is to be added to the aggregate query
            log_ops = random.choices(self._logic_op_bag, weights=self._logic_op_wghts, k=n_vars-1) # sample logical operators allowing repetition
            exp_params,cmp_ops=self._sort_vars_ops(where_vars)
        real_tbl_name = self.REAL_TBL_NAME
        cat_vars = self.CAT_VARS
        cnt_vars = self.CNT_VARS
        #dt_vars=self.DT_VARS

        if agg_fntn:#case1
            tmplts_start = self._make_aggfltr_tmplt_start_c1(len(cat_vars))
        else: #case0
            tmplts_start = self._make_aggfltr_tmplt_start_c0(len(cat_vars))
        
        tmplts_end = self._make_aggfltr_tmplt_end(len(cat_vars))
        tmplts_idx = list(range(len(tmplts_start)))
        grp_rank = random.choice(tmplts_idx)

        start_tmplt = tmplts_start[grp_rank]
        end_tmplt=tmplts_end[grp_rank]

        select_cat_vars = random.sample(cat_vars, grp_rank+1) #cat variables  for the select and not for the where, you may include date in the future, just comment this line and uncomment the one below. Also uncomnent dt_var above
        #select_cat_vars = random.sample(cat_vars+dt_vars, grp_rank+1)

        if agg_fntn: #case1
            select_agg_op = random.choice(self._agg_op_bag)
            select_cnt_var = random.choice(cnt_vars)
            start_args_real = *select_cat_vars, select_agg_op, select_cnt_var, real_tbl_name
            start_args_syn = *select_cat_vars, select_agg_op, select_cnt_var, syn_tbl_name

        else: #case0
            start_args_real = *select_cat_vars, real_tbl_name
            start_args_syn = *select_cat_vars, syn_tbl_name

        
        start_expr_real=start_tmplt.format(*start_args_real)
        start_expr_syn=start_tmplt.format(*start_args_syn)
        end_expr_real=end_tmplt.format(*select_cat_vars)
        
        if n_vars!=0:
            mid_expr_real, query_params = self._gen_single_fltr_expr23(where_vars,log_ops, cmp_ops, exp_params)
            expr_real=start_expr_real+mid_expr_real+end_expr_real
            expr_syn=start_expr_syn+mid_expr_real+end_expr_real
        else: #No WHERE clause
            expr_real=start_expr_real+end_expr_real
            expr_syn=start_expr_syn+end_expr_real


        query_params['query_type']='aggfltr_{}'.format(int(agg_fntn))
        query_params['real_table_name']=real_tbl_name
        query_params['syn_table_name']=syn_tbl_name
        query_params['query_tmplt_idx']=grp_rank #The word 'query' refers to aggregate query arguments. The arguments of teh where clause  will start with where e.g. where_cnt_vars
        query_params['query_cat_vars']= select_cat_vars
        query_params['query_cnt_vars']=np.nan
        query_params['query_dt_vars']=np.nan
        query_params['query_cnt_var']=select_cnt_var if agg_fntn else np.nan
        query_params['query_agg_op']=select_agg_op if agg_fntn else np.nan
        query_params['query_match_vars']=select_cat_vars
        query_params['real_sql']=expr_real
        query_params['syn_sql']=expr_syn

        return expr_real, expr_syn, query_params


    def gen_twin_aggfltr_queries(self, n_rnd_queries,syn_tbl_name,agg_fntn=True) -> dict:
        if agg_fntn:
            assert agg_fntn and self.CNT_VARS, "Data shall include at least one continuous variable, or set agg_fntn to False"
        cur = self.CUR
        queries = {'query_real': [], 'query_syn':[],'query_params': []}
        for k in range(n_rnd_queries):
            this_n_vars = random.randrange(1, len(self.VARS)) #Change starting bound to zero to allow omitting the where statement
            this_vars = list(np.random.choice(self.VARS, size=this_n_vars, replace=False))  # Randomly pick a number of WHERE variables for the query

            real_expr, syn_expr, query_params = self._gen_twin_aggfltr_expr(this_vars,syn_tbl_name,  agg_fntn=agg_fntn)

            cur.execute(real_expr)
            query_real = cur.fetchall()
            query_real_headers = [description[0] for description in cur.description]
            query_real_df = pd.DataFrame( query_real, columns=query_real_headers)

            cur.execute(syn_expr)
            query_syn = cur.fetchall()
            query_syn_headers = [description[0] for description in cur.description]
            query_syn_df = pd.DataFrame( query_syn, columns=query_syn_headers)

            query_params["real_n_rcrds"]= len(query_real_df)
            query_params["syn_n_rcrds"]= len(query_syn_df)

            queries['query_real'].append(query_real_df)
            queries['query_syn'].append(query_syn_df)
            queries['query_params'].append(query_params)
            
            print('Generated Conditioned Aggregate Query {} '.format(str(k)))
        return queries


        


##########################################################################################


    def _modify_vars(self, vars: list):
        """ The function allows to randomly add NOT before any variable"""
        n_vars = len(vars)
        add_not = np.random.choice(
            self._logic_not_states, size=(n_vars,), p=self._logic_not_wghts)
        new_vars = []
        for i, var in enumerate(vars):
            if add_not[i]:
                new_vars.append('NOT '+var)
            else:
                new_vars.append(var)
        return new_vars

    def _add_quotes(self, str_val):
        # if type(str_val) is not str:
        #     new_val=str(str_val)
        # else:
        new_val = "'"+str(str_val)+"'"
        return new_val

    def _sort_vars_ops(self, vars: list):
        """ The function randomly samples comparison operators and sorts them to be inline with input list of variables. It returns a list sorted comparison operators and a dictionary of of expression parameters that include the types of variable """
        exp_params = {}

        # separate continuous and categorical variable in the input variables
        cnt_vars = []
        cnt_idx = []
        cat_vars = []
        cat_idx = []
        dt_vars=[]
        dt_idx=[]
        for i, var in enumerate(vars):
            if var in self.CNT_VARS:
                cnt_vars.append(var)
                cnt_idx.append(i)
            elif var in self.CAT_VARS:
                cat_vars.append(var)
                cat_idx.append(i)
            elif var in self.DT_VARS:
                dt_vars.append(var)
                dt_idx.append(i)

        n_cnt_vars = len(cnt_vars)
        n_cat_vars = len(cat_vars)
        n_dt_vars=len(dt_vars)

        exp_params['where_cnt_vars'] = cnt_vars
        exp_params['where_cat_vars'] = cat_vars
        exp_params['where_dt_vars'] = dt_vars

        # sample comparison operators for continuous variables
        cnt_cmp_ops = list(np.random.choice(self._cnt_cmp_op_bag, size=n_cnt_vars,
                           replace=True, p=self._cnt_cmp_op_wghts))  # allow repetitions

        # sample comparison operators for categorical variables
        cat_cmp_ops = list(np.random.choice(
            self._cat_cmp_op_bag, size=n_cat_vars, replace=True, p=self._cat_cmp_op_wghts))

        # sample comparison operators for date variables ( use same ops as continuous variables)
        dt_cmp_ops = list(np.random.choice(
            self._cnt_cmp_op_bag, size=n_dt_vars, replace=True, p=self._cnt_cmp_op_wghts))

        idx = cnt_idx+cat_idx+dt_idx
        cmp_ops = cnt_cmp_ops+cat_cmp_ops+dt_cmp_ops
        # sort back ops to match input variable names
        cmp_ops = [x for _, x in sorted(zip(idx, cmp_ops))]

        return exp_params, cmp_ops

    def _append_val(self,args, var, cmp_op):
        """ The function randomly picks values corresponding to the input variable var and based on its subsequent operator cmp_op. The picked value is appended to the train of arguments that is necessary to construct the SQL statement."""
        if cmp_op == 'BETWEEN':
            if var in self.CNT_VARS:
                args.append(random.choice(self.CNT_VAL_BAG[var])) # upper bound of BETWEEN
                args.append(random.choice(self.CNT_VAL_BAG[var])) # lower bound of BETWEEN
            elif var in self.DT_VARS:
                args.append(self._add_quotes(random.choice(self.DT_VAL_BAG[var]))) # upper bound of BETWEEN
                args.append(self._add_quotes(random.choice(self.DT_VAL_BAG[var]))) # lower bound of BETWEEN
            else:  # this is actually redundant condition as 'BETWEEN' is not defined for categorical variables
                args.append(self._add_quotes(random.choice(self.CAT_VAL_BAG[var])))
                args.append(self._add_quotes(random.choice(self.CAT_VAL_BAG[var])))
        elif cmp_op == 'IN':
            # this is actually redundant condition as 'IN' is not defined for continuous variables
            if var in self.CNT_VARS:
                classes = list(set(self.CNT_VAL_BAG[var]))
                tpl_size = random.choice(list(range(1, 1+len(classes))))
                args.append(tuple(np.random.choice(
                    classes, size=tpl_size+1, replace=True)))
            elif var in self.DT_VARS:
                classes = list(set(self.DT_VAL_BAG[var]))
                tpl_size = random.choice(list(range(1, 1+len(classes))))
                args.append(tuple(np.random.choice(
                    classes, size=tpl_size+1, replace=True)))
            else:
                classes = list(set(self.CAT_VAL_BAG[var]))
                tpl_size = random.choice(list(range(1, 1+len(classes))))
                args.append(tuple(np.random.choice(classes, size=tpl_size+1, replace=True)))
        else:
            if var in self.CNT_VARS:
                args.append(random.choice(self.CNT_VAL_BAG[var]))
            elif var in self.DT_VARS:
                args.append(self._add_quotes(random.choice(self.DT_VAL_BAG[var])))
            else:
                args.append(self._add_quotes(random.choice(self.CAT_VAL_BAG[var])))
                    
        return args


    # def _gen_single_fltr_expr1(self, vars: list, agg_fntn=True) -> str:
    #     tbl = self.REAL_TBL_NAME

    #     n_vars = int(len(vars))

    #     # sample logical operators allowing repetition
    #     log_ops = random.choices(self._logic_op_bag, weights=self._logic_op_wghts, k=n_vars-1)
    #     exp_params,cmp_ops=self._sort_vars_ops(vars)

    #     # Construct SQL expression
    #     # Prepare expression pertaining to template 1
    #     if agg_fntn:
    #         tmplt = self._make_fltr_tmplt1_c1()
    #         args = []
    #         this_agg_op = random.choices(
    #             self._agg_op_bag, weights=self._agg_op_wghts, k=1)
    #         args.append(*this_agg_op)
    #         this_agg_var = random.choice(self.CNT_VARS)
    #         args.append(this_agg_var)
    #         exp_params['agg_cnt_var'] = this_agg_var
    #         args.append(tbl)
    #         expr1 = tmplt.format(*args)
    #         exp_params['query_agg_op'] = this_agg_op

    #     else:
    #         tmplt = self._make_fltr_tmplt1_c0()
    #         args = []
    #         args.append(tbl)
    #         expr1 = tmplt.format(*args)
    #         exp_params['agg_cnt_var'] = np.nan
    #         exp_params['query_agg_op'] = np.nan

    #     return expr1, log_ops,cmp_ops,exp_params

    def _gen_single_fltr_expr23(self, vars: list, log_ops, cmp_ops, exp_params) -> str:
        n_vars = int(len(vars))

        # Get randomly introduces NOT to vars by calling _modify_vars
        frmted_vars = self._modify_vars(vars)

        # Prepare expression pertaining to template 2 if the number of input vars is odd
        if n_vars % 2 != 0:
            args = []
            args.append(frmted_vars[0])
            args.append(cmp_ops[0])
            tmplt = self._make_fltr_tmplt2(cmp_ops[0])
            args=self._append_val(args, vars[0],cmp_ops[0])

            if log_ops:  # if list is not empty, ie. number of input variables > 1
                tmplt = tmplt+' {} '
                args.append(log_ops[0])
            expr2 = tmplt.format(*args)
            vars.remove(vars[0])
            cmp_ops.remove(cmp_ops[0])
            frmted_vars.remove(frmted_vars[0])
            if log_ops:
                log_ops.remove(log_ops[0])
            if not log_ops:  # return expression if number of input variables =1
                return expr2,  exp_params

        # Prepare expression pertaining to template 3 and template 4
        k = 0  # counter for logical operation
        if n_vars % 2 != 0:  # add expression 1 if the number of input variable is odd
            expr = expr2
        else:
            expr = ' WHERE '
        n_terms = int(len(vars)/2)

        j=0
        for i in range(n_terms):
            args = []
            args.append(frmted_vars[j])
            args.append(cmp_ops[j])
            tmplt = self._make_fltr_tmplt3(cmp_ops[j])
            args=self._append_val(args, vars[j],cmp_ops[j])
            j+=1
            
            args.append(log_ops[k])
            k += 1
            expr3 = tmplt.format(*args)
           
            args = []
            args.append(frmted_vars[j])
            args.append(cmp_ops[j])
            tmplt = self._make_fltr_tmplt4(cmp_ops[j])
            args=self._append_val(args, vars[j], cmp_ops[j])
            expr4 = tmplt.format(*args)
            j+=1

            if i < n_terms-1:
                expr = expr+expr3+expr4+' {} '.format(log_ops[k])
            else:
                expr = expr+expr3+expr4

        return expr,  exp_params

    def _gen_single_fltr_expr(self, vars: list, agg_fntn=True) -> str:
        """ The function returns sql where expression given the table name (tbl) and a list of variable names (vars). By default and a random aggregate function and random continuous variables are used. If agg_fntn is set to False, the query will return all records """
        tbl = self.REAL_TBL_NAME

        n_vars = int(len(vars))

        # sample logical operators allowing repetition
        log_ops = random.choices(self._logic_op_bag, weights=self._logic_op_wghts, k=n_vars-1)
        exp_params,cmp_ops=self._sort_vars_ops(vars)

        # Construct SQL expression
        # Prepare expression pertaining to template 1
        if agg_fntn:
            tmplt = self._make_fltr_tmplt1_c1()
            args = []
            this_agg_op = random.choices(
                self._agg_op_bag, weights=self._agg_op_wghts, k=1)
            args.append(*this_agg_op)
            this_agg_var = random.choice(self.CNT_VARS)
            args.append(this_agg_var)
            exp_params['agg_cnt_var'] = this_agg_var
            args.append(tbl)
            expr1 = tmplt.format(*args)
            exp_params['query_agg_op'] = this_agg_op

        else:
            tmplt = self._make_fltr_tmplt1_c0()
            args = []
            args.append(tbl)
            expr1 = tmplt.format(*args)
            exp_params['agg_cnt_var'] = np.nan
            exp_params['query_agg_op'] = np.nan

        # Get randomly introduces NOT to vars by calling _modify_vars
        frmted_vars = self._modify_vars(vars)

        # Prepare expression pertaining to template 2 if the number of input vars is odd
        if n_vars % 2 != 0:
            args = []
            args.append(frmted_vars[0])
            args.append(cmp_ops[0])
            tmplt = self._make_fltr_tmplt2(cmp_ops[0])
            args=self._append_val(args, vars[0],cmp_ops[0])

            if log_ops:  # if list is not empty, ie. number of input variables > 1
                tmplt = tmplt+' {} '
                args.append(log_ops[0])
            expr2 = tmplt.format(*args)
            vars.remove(vars[0])
            cmp_ops.remove(cmp_ops[0])
            frmted_vars.remove(frmted_vars[0])
            if log_ops:
                log_ops.remove(log_ops[0])
            if not log_ops:  # return expression if number of input variables =1
                return expr1+expr2,  exp_params

        # Prepare expression pertaining to template 3 and template 4
        k = 0  # counter for logical operation
        if n_vars % 2 != 0:  # add expression 1 if the number of input variable is odd
            expr = expr1+expr2
        else:
            expr = expr1 + ' WHERE '
        n_terms = int(len(vars)/2)

        j=0
        for i in range(n_terms):
            args = []
            args.append(frmted_vars[j])
            args.append(cmp_ops[j])
            tmplt = self._make_fltr_tmplt3(cmp_ops[j])
            args=self._append_val(args, vars[j],cmp_ops[j])
            j+=1
            
            args.append(log_ops[k])
            k += 1
            expr3 = tmplt.format(*args)
           
            args = []
            args.append(frmted_vars[j])
            args.append(cmp_ops[j])
            tmplt = self._make_fltr_tmplt4(cmp_ops[j])
            args=self._append_val(args, vars[j], cmp_ops[j])
            expr4 = tmplt.format(*args)
            j+=1

            if i < n_terms-1:
                expr = expr+expr3+expr4+' {} '.format(log_ops[k])
            else:
                expr = expr+expr3+expr4

        return expr,  exp_params


    def _gen_twin_fltr_expr(self, vars: list,tbl_syn, agg_fntn=True) -> str:
        """ The function returns an sql expression with WHERE clause for the input table name (tbl) and a list of variable names (vars). By default, a random aggregate function with a random continuous variables are used. If agg_fntn is set to False, the query will return all records """
        tbl = self.REAL_TBL_NAME
        n_vars = int(len(vars))
        exp_params = {}
        # sample logical operators allowing repetition
        log_ops = random.choices(
            self._logic_op_bag, weights=self._logic_op_wghts, k=n_vars-1)
        # separate continuous and categorical variable in t
        exp_params,cmp_ops=self._sort_vars_ops(vars)
        # Construct SQL expression
        # Prepare expression pertaining to template 1
        if agg_fntn:
            tmplt = self._make_fltr_tmplt1_c1()
            args = []
            this_agg_op = random.choices(
                self._agg_op_bag, weights=self._agg_op_wghts, k=1)
            args.append(*this_agg_op)
            this_agg_var = random.choice(self.CNT_VARS)
            args.append(this_agg_var)
            exp_params['agg_cnt_var'] = this_agg_var
            args_syn = copy.deepcopy(args)
            args.append(tbl)
            args_syn.append(tbl_syn)
            expr1 = tmplt.format(*args)
            expr1_syn = tmplt.format(*args_syn)
            exp_params['query_agg_op'] = this_agg_op
        else:
            tmplt = self._make_fltr_tmplt1_c0()
            args = []
            args_syn = []
            args.append(tbl)
            args_syn.append(tbl_syn)
            expr1 = tmplt.format(*args)
            expr1_syn = tmplt.format(*args_syn)
            exp_params['agg_cnt_var'] = np.nan
            exp_params['query_agg_op'] = np.nan

        # Get randomly introduce NOT to nars by calling _modify_vars
        frmted_vars = self._modify_vars(vars)

        # Prepare expression pertaining to template 2 if the number of input vars is odd
        if n_vars % 2 != 0:
            args = []
            args.append(frmted_vars[0])
            args.append(cmp_ops[0])
            tmplt = self._make_fltr_tmplt2(cmp_ops[0])
            args=self._append_val(args, vars[0],cmp_ops[0])           
            if log_ops:  # if list is not empty, ie. number of input variables > 1
                tmplt = tmplt+' {} '
                args.append(log_ops[0])
            expr2 = tmplt.format(*args)
            vars.remove(vars[0])
            cmp_ops.remove(cmp_ops[0])
            frmted_vars.remove(frmted_vars[0])
            if log_ops:
                log_ops.remove(log_ops[0])
            if not log_ops:  # return expression if number of input variables =1
                return expr1+expr2, expr1_syn+expr2, exp_params

        # Prepare expression pertaining to template 3 and template 4
        k = 0  # counter for logical operation
        if n_vars % 2 != 0:  # add expression 1 if the number of input variable is odd
            expr = expr1+expr2
            expr_syn = expr1_syn+expr2
        else:
            expr = expr1 + ' WHERE '
            expr_syn = expr1_syn + ' WHERE '
        n_terms = int(len(vars)/2)

        j=0
        for i in range(n_terms):
            args = []
            args.append(frmted_vars[j])
            args.append(cmp_ops[j])
            tmplt = self._make_fltr_tmplt3(cmp_ops[j])
            args=self._append_val(args, vars[j],cmp_ops[j])
            j+=1
            args.append(log_ops[k])
            k += 1
            expr3 = tmplt.format(*args)
            args = []
            args.append(frmted_vars[j])
            args.append(cmp_ops[j])
            tmplt = self._make_fltr_tmplt4(cmp_ops[j])
            args=self._append_val(args, vars[j],cmp_ops[j])
            expr4 = tmplt.format(*args)
            j+=1
            if i < n_terms-1:
                expr = expr+expr3+expr4+' {} '.format(log_ops[k])
                expr_syn = expr_syn+expr3+expr4+' {} '.format(log_ops[k])
            else:
                expr = expr+expr3+expr4
                expr_syn = expr_syn+expr3+expr4

        return expr, expr_syn, exp_params

    def _match_class_records(self, query_params: dict, query_real: pd.DataFrame, query_syn: pd.DataFrame) -> pd.DataFrame:
        """ The function matches records of real and syn queries and return same length dataframes """

        new_real_idx = []  # use grouping classes as indices for query_real
        for idx, row in query_real.iterrows():
            lookup_vars = row[0:len(query_params['query_match_vars'])].values
            new_idx = " ".join([str(item) for item in list(lookup_vars)])
            new_real_idx.append(new_idx)
        query_real.index = new_real_idx

        new_syn_idx = []  # use grouping classes as indices for query_syn
        for idx, row in query_syn.iterrows():
            lookup_vars = row[0:len(query_params['query_match_vars'])].values
            new_idx = " ".join([str(item) for item in list(lookup_vars)])
            new_syn_idx.append(new_idx)
        query_syn.index = new_syn_idx

        if len(query_real) >= len(query_syn):
            # loop thru query_real and find matching recorreal in query_syn. Add the record with no match but with
            # count and aggregate fielreal set to nan. You should end up with same length of query_real and query_syn
            # (equal to the longer table ie query_real)
            new_query_syn = copy.deepcopy(query_real)
            count_col_name = new_query_syn.columns[-1]
            agg_col_name = new_query_syn.columns[-2]
            new_query_syn.iloc[:, (-1, -2)] = np.nan
            for idx, row in new_query_syn.iterrows():
                if idx in query_syn.index:
                    new_query_syn.at[idx,
                                     count_col_name] = query_syn.loc[idx][-1]
                    new_query_syn.at[idx,
                                     agg_col_name] = query_syn.loc[idx][-2]
                else:
                    pass
            query_real.reset_index(drop=True, inplace=True)
            new_query_syn.reset_index(drop=True, inplace=True)
            return query_real, new_query_syn
        else:
            # Do exactly the opposite of the above (ie extend the real with nan entries instead of the syn)
            new_query_real = copy.deepcopy(query_syn)
            count_col_name = new_query_real.columns[-1]
            agg_col_name = new_query_real.columns[-2]
            new_query_real.iloc[:, (-1, -2)] = np.nan
            for idx, row in new_query_real.iterrows():
                if idx in query_real.index:
                    new_query_real.at[idx,
                                      count_col_name] = query_real.loc[idx][-1]
                    new_query_real.at[idx,
                                      agg_col_name] = query_real.loc[idx][-2]
                else:
                    pass
            new_query_real.reset_index(drop=True, inplace=True)
            query_syn.reset_index(drop=True, inplace=True)
            return new_query_real, query_syn


    def _gen_single_agg_query_c1(self) -> pd.DataFrame:
        cur = self.CUR
        real_tbl_name = self.REAL_TBL_NAME
        cat_vars = self.CAT_VARS
        CNT_VARSs = self.CNT_VARS
        tmplts = self._make_agg_tmplts_c1(len(cat_vars))
        # Form random combination
        # you can substitute len(tmplts) by you number of choice if you want to limit the number of grouped categories by that number
        tmplts_idx = list(range(len(tmplts)))
        # grouping rank is the number of variables used in the select statement less 1
        grp_rank = random.choice(tmplts_idx)
        this_tmplt = tmplts[grp_rank]
        this_cat_vars = random.sample(cat_vars, grp_rank+1)
        this_op = random.choice(self._agg_op_bag)
        this_CNT_VARS = random.choice(CNT_VARSs)
        this_expr_real = *this_cat_vars, this_op, this_CNT_VARS, real_tbl_name, *this_cat_vars
        cur.execute(this_tmplt.format(*this_expr_real))
        query_real = cur.fetchall()

        #SMK CHECK
        query_real_header = [description[0] for description in cur.description]
        query_real_df = pd.DataFrame(query_real, columns=query_real_header)
        #query_real_df = pd.DataFrame(query_real, columns=[*this_cat_vars, this_CNT_VARS, "count"])

        query_params = {
            "query_type":"agg_1",
            "real_table_name": real_tbl_name,
            "syn_table_name": np.nan,
            "query_tmplt_idx": grp_rank,
            "query_tmplt": this_tmplt,
            "query_cat_vars": this_cat_vars,
            "query_cnt_vars": np.nan,
            "query_cnt_var": this_CNT_VARS,
            "query_agg_op": this_op,
            "real_n_rcrds": len(query_real_df),
            "syn_n_rcrds": np.nan,
            "query_match_vars": this_cat_vars, 
            "real_sql":this_tmplt.format(*this_expr_real),
            "syn_sql":np.nan
        }

        return query_real_df, query_params



    def _gen_twin_agg_query_c1(self, syn_tbl_name) -> pd.DataFrame:
        """ The function generates a random aggregate query for both the real and its corresponding 
        synthetic data with the table names given in real_tbl_name and syn_tbl_name respectively. The tables are assumed to be available 
        in the database with given cursor 'cur'. The function returns both queries for real and syn tables. It also returns the applied aggregate 
        operation name. Do not use this function if there are no continuous variables in the dataset"""
        self.SYN_TBL_NAME=syn_tbl_name
        cur = self.CUR
        real_tbl_name = self.REAL_TBL_NAME
        cat_vars = self.CAT_VARS
        CNT_VARSs = self.CNT_VARS
        tmplts = self._make_agg_tmplts_c1(len(cat_vars))
        # Form random combination
        # you can substitute len(tmplts) by you number of choice if you want to limit the number of grouped categories by that number
        tmplts_idx = list(range(len(tmplts)))
        # grouping rank is the number of variables used in the select statement less 1
        grp_rank = random.choice(tmplts_idx)
        this_tmplt = tmplts[grp_rank]
        this_cat_vars = random.sample(cat_vars, grp_rank+1)
        this_op = random.choice(self._agg_op_bag)
        this_CNT_VARS = random.choice(CNT_VARSs)
        this_expr_real = *this_cat_vars, this_op, this_CNT_VARS, real_tbl_name, *this_cat_vars
        cur.execute(this_tmplt.format(*this_expr_real))
        query_real = cur.fetchall()
        
        #SMK CHECK
        query_real_header = [description[0] for description in cur.description]
        query_real_df = pd.DataFrame(query_real, columns=query_real_header)

        
        
        this_expr_syn = *this_cat_vars, this_op, this_CNT_VARS, syn_tbl_name, *this_cat_vars
        cur.execute(this_tmplt.format(*this_expr_syn))
        query_syn = cur.fetchall()

        #SMK CHECK
        query_syn_header = [description[0] for description in cur.description]
        query_syn_df = pd.DataFrame(query_syn, columns=query_syn_header)

        

        #SMK CHECK
        # query_real_df = pd.DataFrame(query_real, columns=[*this_cat_vars, this_CNT_VARS, "count"])
        # query_syn_df = pd.DataFrame(query_syn, columns=[*this_cat_vars, this_CNT_VARS, "count"])
        
        
        
        query_params = {
            "query_type":"agg_1",
            "real_table_name": real_tbl_name,
            "syn_table_name": syn_tbl_name,
            "query_tmplt_idx": grp_rank,
            "query_tmplt": this_tmplt,
            "query_cat_vars": this_cat_vars,
            "query_cnt_vars": np.nan,
            "query_cnt_var": this_CNT_VARS,
            "query_agg_op": this_op,
            "real_n_rcrds": len(query_real_df),
            "syn_n_rcrds": len(query_syn_df),
            "query_match_vars": this_cat_vars, 
            "real_sql":this_tmplt.format(*this_expr_real),
            "syn_sql":this_tmplt.format(*this_expr_syn)
        }

        return query_real_df, query_syn_df, query_params

    def _gen_det_twin_agg_query_c0(self, def_cat_vars: list,syn_tbl_name) -> pd.DataFrame:
        """ The function generates a specific query defined by the input list of categorical variables for both the real and its corresponding 
        synthetic data with the table names given in real_tbl_name and syn_tbl_name respectively. The tables are assumed to be available 
        in the database with given cursor 'cur'. The function returns both queries for real and syn tables. 
        The generated query do not include any aggregation of continuous variables."""
        self.SYN_TBL_NAME=syn_tbl_name
        cur = self.CUR
        real_tbl_name = self.REAL_TBL_NAME
        tmplts = self._make_agg_tmplts_c0(len(def_cat_vars))
        # Form random combination
        # you can substitute len(tmplts) by you number of choice if you want to limit the number of grouped categories by that number
        tmplts_idx = list(range(len(def_cat_vars)))
        grp_rank = len(tmplts_idx)
        this_tmplt = tmplts[grp_rank-1]
        this_expr_real = *def_cat_vars, real_tbl_name, *def_cat_vars
        cur.execute(this_tmplt.format(*this_expr_real))
        query_real = cur.fetchall()
        this_expr_syn = *def_cat_vars, syn_tbl_name, *def_cat_vars
        cur.execute(this_tmplt.format(*this_expr_syn))
        query_syn = cur.fetchall()

        query_real_df = pd.DataFrame(
            query_real, columns=[*def_cat_vars, "count"])
        query_syn_df = pd.DataFrame(
            query_syn, columns=[*def_cat_vars, "count"])
        query_params = {
            "query_type":"agg_2",
            "real_table_name": real_tbl_name,
            "syn_table_name": syn_tbl_name,
            "query_tmplt_idx": grp_rank,
            "query_tmplt": this_tmplt,
            "query_cat_vars": def_cat_vars,
            "query_cnt_vars": np.nana,
            "query_cnt_var": np.nan,
            "query_agg_op": np.nan,
            "real_n_rcrds": len(query_real_df),
            "syn_n_rcrds": len(query_syn_df),
            "query_match_vars": def_cat_vars,
            "real_sql":this_tmplt.format(*this_expr_real),
            "syn_sql":this_tmplt.format(*this_expr_syn)
        }
        return query_real_df, query_syn_df, query_params


    def _gen_single_agg_query_c0(self) -> pd.DataFrame:
        cur = self.CUR
        real_tbl_name = self.REAL_TBL_NAME
        cat_vars = self.CAT_VARS
        tmplts = self._make_agg_tmplts_c0(len(cat_vars))
        # Form random combination
        # you can substitute len(tmplts) by you number of choice if you want to limit the number of grouped categories by that number
        tmplts_idx = list(range(len(tmplts)))
        # grouping rank is teh number of variables used in teh select statement less 1
        grp_rank = random.choice(tmplts_idx)
        this_tmplt = tmplts[grp_rank]
        this_cat_vars = random.sample(cat_vars, grp_rank+1)
        this_expr_real = *this_cat_vars, real_tbl_name, *this_cat_vars
        cur.execute(this_tmplt.format(*this_expr_real))
        query_real = cur.fetchall()

        query_real_df = pd.DataFrame(
            query_real, columns=[*this_cat_vars, "count"])

        query_params = {
            "query_type":"agg_2",
            "real_table_name": real_tbl_name,
            "syn_table_name": np.nan,
            "query_tmplt_idx": grp_rank,
            "query_tmplt": this_tmplt,
            "query_cat_vars": this_cat_vars,
            "query_cnt_vars": np.nan,
            "query_cnt_var": np.nan,
            "query_agg_op": np.nan,
            "real_n_rcrds": len(query_real_df),
            "syn_n_rcrds": np.nan,
            "query_match_vars": this_cat_vars,
            "real_sql":this_tmplt.format(*this_expr_real),
            "syn_sql":np.nan
        }

        return query_real_df, query_params


    def _gen_twin_agg_query_c0(self,syn_tbl_name) -> pd.DataFrame:
        """ The function generates a random aggregate query for both the real and its corresponding 
        synthetic data with the table names given in real_tbl_name and syn_tbl_name respectively. The tables are assumed to be available 
        in the database with given cursor 'cur'. The function returns both queries for real and syn tables. 
        The generated query do not include any aggregation of continuous variables."""
        cur = self.CUR
        real_tbl_name = self.REAL_TBL_NAME
        cat_vars = self.CAT_VARS
        tmplts = self._make_agg_tmplts_c0(len(cat_vars))
        # Form random combination
        # you can substitute len(tmplts) by you number of choice if you want to limit the number of grouped categories by that number
        tmplts_idx = list(range(len(tmplts)))
        # grouping rank is teh number of variables used in teh select statement less 1
        grp_rank = random.choice(tmplts_idx)
        this_tmplt = tmplts[grp_rank]
        this_cat_vars = random.sample(cat_vars, grp_rank+1)
        this_expr_real = *this_cat_vars, real_tbl_name, *this_cat_vars
        cur.execute(this_tmplt.format(*this_expr_real))
        query_real = cur.fetchall()
        this_expr_syn = *this_cat_vars, syn_tbl_name, *this_cat_vars
        cur.execute(this_tmplt.format(*this_expr_syn))
        query_syn = cur.fetchall()

        query_real_df = pd.DataFrame(
            query_real, columns=[*this_cat_vars, "count"])
        query_syn_df = pd.DataFrame(
            query_syn, columns=[*this_cat_vars, "count"])
        query_params = {
            "query_type":"agg_2",
            "real_table_name": real_tbl_name,
            "syn_table_name": syn_tbl_name,
            "query_tmplt_idx": grp_rank,
            "query_tmplt": this_tmplt,
            "query_cat_vars": this_cat_vars,
            "query_cnt_vars": np.nan,
            "query_cnt_var": np.nan,
            "query_agg_op": np.nan,
            "real_n_rcrds": len(query_real_df),
            "syn_n_rcrds": len(query_syn_df),
            "query_match_vars": this_cat_vars,
            "real_sql":this_tmplt.format(*this_expr_real),
            "syn_sql":this_tmplt.format(*this_expr_syn)
        }

        return query_real_df, query_syn_df, query_params

    def gen_twin_agg_queries(self, n_rnd_queries,syn_tbl_name, agg_fntn=True) -> dict:
        if agg_fntn:
            assert agg_fntn and self.CNT_VARS, "Data shall include at least one continuous variable, or set agg_fntn to False"
        queries = {'query_real': [], 'query_syn': [], 'query_params': []}
        for k in range(n_rnd_queries):
            if agg_fntn:
                query_real, query_syn, query_params = self._gen_twin_agg_query_c1(syn_tbl_name)
            else:
                query_real, query_syn, query_params = self._gen_twin_agg_query_c0(syn_tbl_name)
            queries['query_real'].append(query_real)
            queries['query_syn'].append(query_syn)
            queries['query_params'].append(query_params)
            print('Generated Aggregate Query {} '.format(str(k)))
        print('\n')
        return queries


    def gen_single_agg_queries(self, n_rnd_queries, agg_fntn=True) -> dict:
        if agg_fntn:
            assert agg_fntn and self.CNT_VARS, "Data shall include at least one continuous variable, or set agg_fntn to False"
        queries = {'query_real': [], 'query_params': []}
        for k in range(n_rnd_queries):
            if agg_fntn:
                query_real, query_params = self._gen_single_agg_query_c1()
            else:
                query_real, query_params = self._gen_single_agg_query_c0()
            queries['query_real'].append(query_real)
            queries['query_params'].append(query_params)
            print('Generated Aggregate Query {} '.format(str(k)))
        print('\n')
        return queries

    def gen_single_fltr_queries(self, n_rnd_queries,agg_fntn=True) -> dict:
        if agg_fntn:
            assert agg_fntn and self.CNT_VARS, "Data shall include at least one continuous variable, or set agg_fntn to False"
        cur = self.CUR
        queries = {'query_real': [],  'query_params': []}
        for k in range(n_rnd_queries):
            this_n_vars = random.randrange(1, len(self.VARS))
            # SMK - Randomly pick a number of WHERE variables for the query
            this_vars = list(np.random.choice(
                self.VARS, size=this_n_vars, replace=False))
            real_expr, expr_params = self._gen_single_fltr_expr(
                this_vars, agg_fntn=agg_fntn)

            cur.execute(real_expr)
            query_real = cur.fetchall()
            query_real_headers = [description[0]
                                  for description in cur.description]
            query_real_df = pd.DataFrame(
                query_real, columns=query_real_headers)


            query_params = {
                "query_type":'fltr_{}'.format(str(int(agg_fntn))),
                "real_table_name": self.REAL_TBL_NAME,
                "syn_table_name": np.nan,
                "query_tmplt_idx": np.nan,
                "real_query_tmplt": real_expr,
                "syn_query_tmplt": np.nan,
                "query_cat_vars": expr_params['where_cat_vars'],
                "query_cnt_vars": expr_params['where_cnt_vars'],
                "query_cnt_var": expr_params['agg_cnt_var'],
                "query_agg_op": expr_params['query_agg_op'],
                "real_n_rcrds": len(query_real_df),
                "syn_n_rcrds": np.nan,
                "query_match_vars": expr_params['where_cat_vars']+expr_params['where_cnt_vars'],
                "real_sql":real_expr,
                "syn_sql":np.nan
            }

            queries['query_real'].append(query_real_df)
            queries['query_params'].append(query_params)
            
            print('Generated Filter Query {} '.format(str(k)))
        return queries


    def gen_twin_fltr_queries(self, n_rnd_queries, tbl_syn,agg_fntn=True) -> dict:
        if agg_fntn:
            assert agg_fntn and self.CNT_VARS, "Data shall include at least one continuous variable, or set agg_fntn to False"
        cur = self.CUR
        queries = {'query_real': [], 'query_syn': [], 'query_params': []}
        for k in range(n_rnd_queries):
            this_n_vars = random.randrange(1, len(self.VARS))
            # SMK - Randomly pick a number of WHERE variables for the query
            this_vars = list(np.random.choice(
                self.VARS, size=this_n_vars, replace=False))
            real_expr, syn_expr, expr_params = self._gen_twin_fltr_expr(
                this_vars,tbl_syn, agg_fntn=agg_fntn)

            cur.execute(real_expr)
            query_real = cur.fetchall()
            query_real_headers = [description[0]
                                  for description in cur.description]
            query_real_df = pd.DataFrame(
                query_real, columns=query_real_headers)

            cur.execute(syn_expr)
            query_syn = cur.fetchall()
            query_syn_headers = [description[0]
                                 for description in cur.description]
            query_syn_df = pd.DataFrame(query_syn, columns=query_syn_headers)
            query_params = {
                "query_type":'fltr_{}'.format(str(int(agg_fntn))),
                "real_table_name": self.REAL_TBL_NAME,
                "syn_table_name": tbl_syn,
                "query_tmplt_idx": np.nan,
                "real_query_tmplt": real_expr,
                "syn_query_tmplt": syn_expr,
                "query_cat_vars": expr_params['where_cat_vars'],
                "query_cnt_vars": expr_params['where_cnt_vars'],
                "query_cnt_var": expr_params['agg_cnt_var'],
                "query_agg_op": expr_params['query_agg_op'],
                "real_n_rcrds": len(query_real_df),
                "syn_n_rcrds": len(query_syn_df),
                "query_match_vars": expr_params['where_cat_vars']+expr_params['where_cnt_vars'],
                "real_sql":real_expr,
                "syn_sql":syn_expr
            }

            queries['query_real'].append(query_real_df)
            queries['query_syn'].append(query_syn_df)
            queries['query_params'].append(query_params)
            
            print('Generated Filter Query {} '.format(str(k)))
        return queries

    def _match_agg_queries(self, queries: dict) -> dict:
        " The function matches the records of both real and synthetic input queries and returns the the both queries being matched record-by-record"
        real_queries = queries['query_real']
        syn_queries = queries['query_syn']
        query_params = queries['query_params']
        matched_queries = {'query_real': [],
                           'query_syn': [], 'query_params': []}
        for query_real, query_syn, query_params in zip(real_queries, syn_queries, query_params):
            matched_real, matched_syn = self._match_class_records(
                query_params, query_real, query_syn)
            matched_queries['query_real'].append(matched_real)
            matched_queries['query_syn'].append(matched_syn)
            matched_queries['query_params'].append(query_params)
        return matched_queries

    def _make_hlngr_pivot(self, real_df: pd.DataFrame, syn_df: pd.DataFrame) -> pd.DataFrame:
        # real_counts = real_df['count'].values
        # syn_counts = syn_df['count'].values
        real_counts = real_df['COUNT(*)'].values
        syn_counts = syn_df['COUNT(*)'].values
        pivot = np.concatenate([real_counts.reshape(
            1, -1), syn_counts.reshape(1, -1)], axis=0)
        pivot = pd.DataFrame(pivot, index=['real', 'syn'])
        return pivot.T

    def _make_ecldn_pivot(self, real_df: pd.DataFrame, syn_df: pd.DataFrame, agg_var_name) -> pd.DataFrame:
        real_vals = real_df[agg_var_name].values
        syn_vals = syn_df[agg_var_name].values
        pivot = np.concatenate(
            [real_vals.reshape(1, -1), syn_vals.reshape(1, -1)], axis=0)
        pivot = pd.DataFrame(pivot, index=['real', 'syn'])
        return pivot.T

    def _calc_hlngr_dist(self, pivot: pd.DataFrame) -> float:
        if self.HLNGR_DROPNA:
            pivot = pivot.dropna()  # drop nan (ie drop non-matching records)
        else:
            pivot = pivot.fillna(0)  # replace nan with 0 (the default)

        p = pivot['real'].values
        p = p/np.sum(p)
        q = pivot['syn'].values
        q = q/np.sum(q)
        z = np.sqrt(p) - np.sqrt(q)
        if len(z)!=0:
            res=np.sqrt(z @ z / 2)
        else:
            res=np.nan
        return res

    def _calc_ecldn_dist(self, pivot: pd.DataFrame) -> float:
        # I am dropping nan since we can not penalize (ie replacing nan with zero) the generator in
        # terms of distance if it fails to produce a specific class
        pivot = pivot.dropna()
        p = pivot['real'].values
        q = pivot['syn'].values
        scaler = StandardScaler()
        p_q=(p-q).reshape(-1, 1)
        if len(p_q) !=0:
            pq_s = scaler.fit_transform((p-q).reshape(-1, 1))
            res=np.linalg.norm(pq_s, 2)/len(pq_s)
        else:
            res=np.nan
        return res

    def get_agg_metrics(self, queries: dict) -> dict:
        """ The function returns Hillinger distance and Euclidean distance (whenever applicable) for each real-syn query tuple in the input dictionary"""
        matched_queries = self._match_agg_queries(queries)
        matched_queries["hlngr_dist"] = []
        matched_queries["ecldn_dist"] = []
        real_queries = matched_queries['query_real']
        syn_queries = matched_queries['query_syn']
        params = matched_queries['query_params']
        for query_real, query_syn, query_params in zip(real_queries, syn_queries, params):
            hlngr_pivot = self._make_hlngr_pivot(query_real, query_syn)
            hlngr_dist = self._calc_hlngr_dist(hlngr_pivot)
            matched_queries["hlngr_dist"].append(hlngr_dist)
            # For case1, both hlngr and ecldn pivots and distances will be produced
            if not pd.isnull(query_params['query_agg_op']):
                # SMK CHECK
                ecldn_pivot = self._make_ecldn_pivot(query_real, query_syn, query_real.columns[-1])
                #ecldn_pivot = self._make_ecldn_pivot(query_real, query_syn, query_params['query_cnt_var'])
                ecldn_dist = self._calc_ecldn_dist(ecldn_pivot)
                matched_queries["ecldn_dist"].append(ecldn_dist)
            else:  # For case 0, only hlngr pivots wil be produced
                matched_queries["ecldn_dist"].append(np.nan)

        return matched_queries

    def get_fltr_metrics(self, queries: dict)-> dict:
        hits=[]
        misses=[]
        diffs=[]
        for real, syn, params in zip(queries['query_real'], queries['query_syn'], queries['query_params']):
            if params['query_type']=='fltr_0':
                # unify types of real and syn dataframes
                types_dict=dict(real.dtypes)
                syn=syn.astype(types_dict)         
                #find hits and misses
                in_both=df = real.merge(syn, how = 'inner' ,indicator=False)
                #only_in_real= real.merge(syn, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='left_only']
                #only_in_syn=real.merge(syn, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='right_only']
                hits.append(len(in_both))
                misses.append(len(real)-len(in_both))
            else:
                real=real.astype(float)
                syn=syn.astype(float)
                diffs.append(np.nan_to_num(np.abs(real-syn).values.ravel()))
                
        if params['query_type']=='fltr_0':
            queries['hits']=hits
            queries['misses']=misses
        else:
            queries['agg_fnctn_diffs']=[diffs[i][0] for i in range(len(diffs))]
            queries['count_diffs']=[diffs[i][1] for i in range(len(diffs))]

        return queries



# To deal with categorical values, you may need to do something like this: print("my name is {}".format('"'+(smk[0]+'"')))
