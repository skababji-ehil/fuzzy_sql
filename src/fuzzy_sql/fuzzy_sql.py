import string
import pandas as pd
import numpy as np
import copy
from sklearn.preprocessing import StandardScaler, KBinsDiscretizer
from array import array
from pathlib import Path
import os
import datetime
import sqlite3
import json
import copy
import pdfkit as pdf
import random
import matplotlib.pylab as plt
import seaborn as sns
sns.set_style("ticks",{'axes.grid' : True})



class TABULAR_QUERY():
    def __init__(self, db_conn, real_tbl_name: str, metadata: dict) -> None:
        self.CUR = db_conn.cursor()
        self.REAL_TBL_NAME = real_tbl_name
        self.VARS = list(metadata.keys())

        self.CAT_VARS = [key for key, value in metadata.items(
        ) if value == 'nominal']  # Get all categorical (nominal) var names
        self.CNT_VARS = [key for key, value in metadata.items(
        ) if value == 'continuous']  # Get all continuous var names
        self.DT_VARS = [key for key, value in metadata.items(
        ) if value == 'date']  # Get all dated var names

        # COUNT is always included in queries
        self.AGG_OPS={'AVG':0.5, 'SUM':0.3, 'MAX':0.1, 'MIN':0.1 }
        self._agg_op_bag = list(self.AGG_OPS.keys())
        self._agg_op_wghts = list(self.AGG_OPS.values())

        self.LOGIC_OPS={'AND':0.5,'OR':0.5}
        self._logic_op_bag = list(self.LOGIC_OPS.keys())
        self._logic_op_wghts = list(self.LOGIC_OPS.values())

        # 1 means a NOT is added before the variable name
        self.NOT_OP_STATE={'0':1, '1':0}
        self._logic_not_states = [int(x) for x in list(self.NOT_OP_STATE.keys())]
        self._logic_not_wghts = list(self.NOT_OP_STATE.values())

        # Comparison operations for categorical variables; BETWEEN is excluded since it can be generated by other operations
        self.CAT_OPS={'=':0.25, '<>':0.25, 'LIKE':0.25, 'IN':0.25}
        self._cat_cmp_op_bag = list(self.CAT_OPS.keys())
        self._cat_cmp_op_wghts = list(self.CAT_OPS.values())

        # Comparison operations for continuous variables
        self.CNT_OPS={'=':0.2, '>':0.1, '<':0.1, '>=':0.1, '<=':0.1, '<>':0.1, 'BETWEEN':0.3}
        self._cnt_cmp_op_bag = list(self.CNT_OPS.keys())
        self._cnt_cmp_op_wghts = list(self.CNT_OPS.values())

        # A dictionary that holds all possible values for each categorical variable
        self.CAT_VAL_BAG = {}
        for CAT_VAR in self.CAT_VARS:
            self.CAT_VAL_BAG[CAT_VAR] = pd.read_sql_query("SELECT {} FROM {}".format(
                CAT_VAR, self.REAL_TBL_NAME), db_conn).values.ravel()

        # A dictionary that holds all possible values for each continuous variable
        self.CNT_VAL_BAG = {}
        for CNT_VAR in self.CNT_VARS:
            self.CNT_VAL_BAG[CNT_VAR] = pd.read_sql_query("SELECT {} FROM {}".format(
                CNT_VAR, self.REAL_TBL_NAME), db_conn).values.ravel()


        # A dictionary that holds all possible values for each date variable
        self.DT_VAL_BAG = {}
        for DT_VAR in self.DT_VARS:
            self.DT_VAL_BAG[DT_VAR] = pd.read_sql_query("SELECT {} FROM {}".format(
                DT_VAR, self.REAL_TBL_NAME), db_conn).values.ravel()


    def _make_agg_tmplts_c1(self, n: int) -> list:
        """ The function generates 'n' number of aggregate sql templates returning a list with length 'n'. 
        Typically, 'n' is the number of available categorical variables in a subject dataset. 
        This function needs at least one continuous variable to be present in the dataset"""
        tmplts = []
        for k in range(n):
            a = "SELECT {}"
            b = [",{}"*i for i in range(n)]
            c = ",{}({}), COUNT(*) FROM {} "
            d = "GROUP BY {}"
            tmplts.append(a+b[k]+c+d+b[k])
        return tmplts

    def _make_agg_tmplts_c0(self, n: int) -> list:
        """ The function generates 'n' number of count sql templates returning a list with length 'n'. 
        Typically, 'n' is the number of available categorical variables in a subject dataset. 
        This function can be used if there is NO continuous variable in the dataset"""
        tmplts = []
        for k in range(n):
            a = "SELECT {}"
            b = [",{}"*i for i in range(n)]
            c = ", COUNT(*) FROM {} "
            d = "GROUP BY {}"
            tmplts.append(a+b[k]+c+d+b[k])
        return tmplts

    def _flatten(self, l):
        return [item for sublist in l for item in sublist]

    def _make_fltr_tmplt1_c1(self):  # where template1 case 1 with AGG function
        return "SELECT {}({}), COUNT(*) FROM {} "

    def _make_fltr_tmplt1_c0(self):  # where template1 case 0 without AGG function
        return "SELECT * FROM {} "

    def _make_fltr_tmplt2(self, cmp_op_name):
        if cmp_op_name == 'BETWEEN':
            return "WHERE ({} {} {} AND {}) "
        else:
            return "WHERE ({} {} {}) "

    def _make_fltr_tmplt3(self, cmp_op_name):
        if cmp_op_name == 'BETWEEN':
            return " (({} {} {} AND {}) {} "
        else:
            return "({} {} {}  {}  "

    def _make_fltr_tmplt4(self, cmp_op_name):
        if cmp_op_name == 'BETWEEN':
            return " {} {} {} AND {})"
        else:
            return "{} {} {})  "

    def _modify_vars(self, vars):
        n_vars = len(vars)
        add_not = np.random.choice(
            self._logic_not_states, size=(n_vars,), p=self._logic_not_wghts)
        new_vars = []
        for i, var in enumerate(vars):
            if add_not[i]:
                new_vars.append('NOT '+var)
            else:
                new_vars.append(var)
        return new_vars

    def _add_quotes(self, str_val):
        new_val = "'"+str_val+"'"
        return new_val

    def _sort_vars_ops(self, vars):
        exp_params = {}

        # separate continuous and categorical variable in the input variables
        cnt_vars = []
        cnt_idx = []
        cat_vars = []
        cat_idx = []
        dt_vars=[]
        dt_idx=[]
        for i, var in enumerate(vars):
            if var in self.CNT_VARS:
                cnt_vars.append(var)
                cnt_idx.append(i)
            elif var in self.CAT_VARS:
                cat_vars.append(var)
                cat_idx.append(i)
            elif var in self.DT_VARS:
                dt_vars.append(var)
                dt_idx.append(i)

        n_cnt_vars = len(cnt_vars)
        n_cat_vars = len(cat_vars)
        n_dt_vars=len(dt_vars)

        exp_params['where_cnt_vars'] = cnt_vars
        exp_params['where_cat_vars'] = cat_vars
        exp_params['where_dt_vars'] = dt_vars

        # sample comparison operators for continuous variables
        cnt_cmp_ops = list(np.random.choice(self._cnt_cmp_op_bag, size=n_cnt_vars,
                           replace=True, p=self._cnt_cmp_op_wghts))  # allow repetitions

        # sample comparison operators for categorical variables
        cat_cmp_ops = list(np.random.choice(
            self._cat_cmp_op_bag, size=n_cat_vars, replace=True, p=self._cat_cmp_op_wghts))

        # sample comparison operators for date variables ( use same ops as continuous variables)
        dt_cmp_ops = list(np.random.choice(
            self._cnt_cmp_op_bag, size=n_dt_vars, replace=True, p=self._cnt_cmp_op_wghts))

        idx = cnt_idx+cat_idx+dt_idx
        cmp_ops = cnt_cmp_ops+cat_cmp_ops+dt_cmp_ops
        # sort back ops to match input variable names
        cmp_ops = [x for _, x in sorted(zip(idx, cmp_ops))]

        return exp_params, cmp_ops

    def _append_var(self,args, var, cmp_op):
        """ The function randomly picks values corresponding to the input variable var and based on its subsequent operator cmp_op. The picked value is appended to the train of argeuments that is necessary to construct the SQL statement."""
        if cmp_op == 'BETWEEN':
            if var in self.CNT_VARS:
                args.append(random.choice(self.CNT_VAL_BAG[var])) # upper bound of BETWEEN
                args.append(random.choice(self.CNT_VAL_BAG[var])) # lower bound of BETWEEN
            elif var in self.DT_VARS:
                args.append(self._add_quotes(random.choice(self.DT_VAL_BAG[var]))) # upper bound of BETWEEN
                args.append(self._add_quotes(random.choice(self.DT_VAL_BAG[var]))) # lower bound of BETWEEN
            else:  # this is actually redundant condition as 'BETWEEN' is not defined for categorical variables
                args.append(self._add_quotes(random.choice(self.CAT_VAL_BAG[var])))
                args.append(self._add_quotes(random.choice(self.CAT_VAL_BAG[var])))
        elif cmp_op == 'IN':
            # this is actually redundant condition as 'IN' is not defined for continuous variables
            if var in self.CNT_VARS:
                classes = list(set(self.CNT_VAL_BAG[var]))
                tpl_size = random.choice(list(range(1, len(classes))))
                args.append(tuple(np.random.choice(
                    classes, size=tpl_size+1, replace=False)))
            elif var in self.DT_VARS:
                classes = list(set(self.DT_VAL_BAG[var]))
                tpl_size = random.choice(list(range(1, len(classes))))
                args.append(tuple(np.random.choice(
                    classes, size=tpl_size+1, replace=False)))
            else:
                classes = list(set(self.CAT_VAL_BAG[var]))
                tpl_size = random.choice(list(range(1, len(classes))))
                args.append(tuple(np.random.choice(
                    classes, size=tpl_size+1, replace=False)))
        else:
            if var in self.CNT_VARS:
                args.append(random.choice(self.CNT_VAL_BAG[var]))
            elif var in self.DT_VARS:
                args.append(self._add_quotes(random.choice(self.DT_VAL_BAG[var])))
            else:
                args.append(self._add_quotes(
                    random.choice(self.CAT_VAL_BAG[var])))
                    
        return args

    def _gen_fltr_expr(self, vars: list, agg_fntn=True) -> str:
        """ The function returns sql where expression given the table name (tbl) and a list of variable names (vars). By default and a random aggregate function and random continuous variables are used. If agg_fntn is set to False, the query will return all records """
        tbl = self.REAL_TBL_NAME

        n_vars = int(len(vars))

        # sample logical operators allowing repetition
        log_ops = random.choices(self._logic_op_bag, weights=self._logic_op_wghts, k=n_vars-1)
        exp_params,cmp_ops=self._sort_vars_ops(vars)

        # Construct SQL expression
        # Prepare expression pertaining to template 1
        if agg_fntn:
            tmplt = self._make_fltr_tmplt1_c1()
            args = []
            this_agg_op = random.choices(
                self._agg_op_bag, weights=self._agg_op_wghts, k=1)
            args.append(*this_agg_op)
            this_agg_var = random.choice(self.CNT_VARS)
            args.append(this_agg_var)
            exp_params['agg_cnt_var'] = this_agg_var
            args.append(tbl)
            expr1 = tmplt.format(*args)
            exp_params['query_agg_op'] = this_agg_op

        else:
            tmplt = self._make_fltr_tmplt1_c0()
            args = []
            args.append(tbl)
            expr1 = tmplt.format(*args)
            exp_params['agg_cnt_var'] = np.nan
            exp_params['query_agg_op'] = np.nan

        # Get randomly introduce NOT to nars by calling _modify_vars
        frmted_vars = self._modify_vars(vars)

        # Prepare expression pertaining to template 2 if the number of input vars is odd
        if n_vars % 2 != 0:
            args = []
            args.append(frmted_vars[0])
            args.append(cmp_ops[0])
            tmplt = self._make_fltr_tmplt2(cmp_ops[0])
            args=self._append_var(args, vars[0],cmp_ops[0])

            if log_ops:  # if list is not empty, ie. number of input variables > 1
                tmplt = tmplt+' {} '
                args.append(log_ops[0])
            expr2 = tmplt.format(*args)
            vars.remove(vars[0])
            cmp_ops.remove(cmp_ops[0])
            frmted_vars.remove(frmted_vars[0])
            if log_ops:
                log_ops.remove(log_ops[0])
            if not log_ops:  # return expression if number of input variables =1
                return expr1+expr2,  exp_params

        # Prepare expression pertaining to template 3 and template 4
        k = 0  # counter for logical operation
        if n_vars % 2 != 0:  # add expression 1 if the number of input variable is odd
            expr = expr1+expr2
        else:
            expr = expr1 + ' WHERE '
        n_terms = int(len(vars)/2)

        j=0
        for i in range(n_terms):
            args = []
            args.append(frmted_vars[j])
            args.append(cmp_ops[j])
            tmplt = self._make_fltr_tmplt3(cmp_ops[j])
            args=self._append_var(args, vars[j],cmp_ops[j])
            j+=1
            
            args.append(log_ops[k])
            k += 1
            expr3 = tmplt.format(*args)
           
            args = []
            args.append(frmted_vars[j])
            args.append(cmp_ops[j])
            tmplt = self._make_fltr_tmplt4(cmp_ops[j])
            args=self._append_var(args, vars[j], cmp_ops[j])
            expr4 = tmplt.format(*args)
            j+=1

            if i < n_terms-1:
                expr = expr+expr3+expr4+' {} '.format(log_ops[k])
            else:
                expr = expr+expr3+expr4

        return expr,  exp_params


    def _gen_twin_fltr_expr(self, vars: list,tbl_syn, agg_fntn=True) -> str:
        """ The function returns an sql expression with WHERE clause for the input table name (tbl) and a list of variable names (vars). By default, a random aggregate function with a random continuous variables are used. If agg_fntn is set to False, the query will return all records """
        tbl = self.REAL_TBL_NAME
        n_vars = int(len(vars))
        exp_params = {}
        # sample logical operators allowing repetition
        log_ops = random.choices(
            self._logic_op_bag, weights=self._logic_op_wghts, k=n_vars-1)
        # separate continuous and categorical variable in t
        exp_params,cmp_ops=self._sort_vars_ops(vars)
        # Construct SQL expression
        # Prepare expression pertaining to template 1
        if agg_fntn:
            tmplt = self._make_fltr_tmplt1_c1()
            args = []
            this_agg_op = random.choices(
                self._agg_op_bag, weights=self._agg_op_wghts, k=1)
            args.append(*this_agg_op)
            this_agg_var = random.choice(self.CNT_VARS)
            args.append(this_agg_var)
            exp_params['agg_cnt_var'] = this_agg_var
            args_syn = copy.deepcopy(args)
            args.append(tbl)
            args_syn.append(tbl_syn)
            expr1 = tmplt.format(*args)
            expr1_syn = tmplt.format(*args_syn)
            exp_params['query_agg_op'] = this_agg_op
        else:
            tmplt = self._make_fltr_tmplt1_c0()
            args = []
            args_syn = []
            args.append(tbl)
            args_syn.append(tbl_syn)
            expr1 = tmplt.format(*args)
            expr1_syn = tmplt.format(*args_syn)
            exp_params['agg_cnt_var'] = np.nan
            exp_params['query_agg_op'] = np.nan

        # Get randomly introduce NOT to nars by calling _modify_vars
        frmted_vars = self._modify_vars(vars)

        # Prepare expression pertaining to template 2 if the number of input vars is odd
        if n_vars % 2 != 0:
            args = []
            args.append(frmted_vars[0])
            args.append(cmp_ops[0])
            tmplt = self._make_fltr_tmplt2(cmp_ops[0])
            args=self._append_var(args, vars[0],cmp_ops[0])           
            if log_ops:  # if list is not empty, ie. number of input variables > 1
                tmplt = tmplt+' {} '
                args.append(log_ops[0])
            expr2 = tmplt.format(*args)
            vars.remove(vars[0])
            cmp_ops.remove(cmp_ops[0])
            frmted_vars.remove(frmted_vars[0])
            if log_ops:
                log_ops.remove(log_ops[0])
            if not log_ops:  # return expression if number of input variables =1
                return expr1+expr2, expr1_syn+expr2, exp_params

        # Prepare expression pertaining to template 3 and template 4
        k = 0  # counter for logical operation
        if n_vars % 2 != 0:  # add expression 1 if the number of input variable is odd
            expr = expr1+expr2
            expr_syn = expr1_syn+expr2
        else:
            expr = expr1 + ' WHERE '
            expr_syn = expr1_syn + ' WHERE '
        n_terms = int(len(vars)/2)

        j=0
        for i in range(n_terms):
            args = []
            args.append(frmted_vars[j])
            args.append(cmp_ops[j])
            tmplt = self._make_fltr_tmplt3(cmp_ops[j])
            args=self._append_var(args, vars[j],cmp_ops[j])
            j+=1
            args.append(log_ops[k])
            k += 1
            expr3 = tmplt.format(*args)
            args = []
            args.append(frmted_vars[j])
            args.append(cmp_ops[j])
            tmplt = self._make_fltr_tmplt4(cmp_ops[j])
            args=self._append_var(args, vars[j],cmp_ops[j])
            expr4 = tmplt.format(*args)
            j+=1
            if i < n_terms-1:
                expr = expr+expr3+expr4+' {} '.format(log_ops[k])
                expr_syn = expr_syn+expr3+expr4+' {} '.format(log_ops[k])
            else:
                expr = expr+expr3+expr4
                expr_syn = expr_syn+expr3+expr4

        return expr, expr_syn, exp_params

    def _match_class_records(self, query_params: dict, query_real: pd.DataFrame, query_syn: pd.DataFrame) -> pd.DataFrame:
        """ The function matches records of real and syn queries and return same length dataframes """

        new_real_idx = []  # use grouping classes as indices for query_real
        for idx, row in query_real.iterrows():
            lookup_vars = row[0:len(query_params['query_match_vars'])].values
            new_idx = " ".join([str(item) for item in list(lookup_vars)])
            new_real_idx.append(new_idx)
        query_real.index = new_real_idx

        new_syn_idx = []  # use grouping classes as indices for query_syn
        for idx, row in query_syn.iterrows():
            lookup_vars = row[0:len(query_params['query_match_vars'])].values
            new_idx = " ".join([str(item) for item in list(lookup_vars)])
            new_syn_idx.append(new_idx)
        query_syn.index = new_syn_idx

        if len(query_real) >= len(query_syn):
            # loop thru query_real and find matching recorreal in query_syn. Add the record with no match but with
            # count and aggregate fielreal set to nan. You should end up with same length of query_real and query_syn
            # (equal to the longer table ie query_real)
            new_query_syn = copy.deepcopy(query_real)
            count_col_name = new_query_syn.columns[-1]
            agg_col_name = new_query_syn.columns[-2]
            new_query_syn.iloc[:, (-1, -2)] = np.nan
            for idx, row in new_query_syn.iterrows():
                if idx in query_syn.index:
                    new_query_syn.at[idx,
                                     count_col_name] = query_syn.loc[idx][-1]
                    new_query_syn.at[idx,
                                     agg_col_name] = query_syn.loc[idx][-2]
                else:
                    pass
            query_real.reset_index(drop=True, inplace=True)
            new_query_syn.reset_index(drop=True, inplace=True)
            return query_real, new_query_syn
        else:
            # Do exactly the opposite of the above (ie extend the real with nan entries instead of the syn)
            new_query_real = copy.deepcopy(query_syn)
            count_col_name = new_query_real.columns[-1]
            agg_col_name = new_query_real.columns[-2]
            new_query_real.iloc[:, (-1, -2)] = np.nan
            for idx, row in new_query_real.iterrows():
                if idx in query_real.index:
                    new_query_real.at[idx,
                                      count_col_name] = query_real.loc[idx][-1]
                    new_query_real.at[idx,
                                      agg_col_name] = query_real.loc[idx][-2]
                else:
                    pass
            new_query_real.reset_index(drop=True, inplace=True)
            query_syn.reset_index(drop=True, inplace=True)
            return new_query_real, query_syn


    def _gen_single_agg_query_c1(self) -> pd.DataFrame:
        cur = self.CUR
        real_tbl_name = self.REAL_TBL_NAME
        cat_vars = self.CAT_VARS
        CNT_VARSs = self.CNT_VARS
        tmplts = self._make_agg_tmplts_c1(len(cat_vars))
        # Form random combination
        # you can substitute len(tmplts) by you number of choice if you want to limit the number of grouped categories by that number
        tmplts_idx = list(range(len(tmplts)))
        # grouping rank is the number of variables used in the select statement less 1
        grp_rank = random.choice(tmplts_idx)
        this_tmplt = tmplts[grp_rank]
        this_cat_vars = random.sample(cat_vars, grp_rank+1)
        this_op = random.choice(self._agg_op_bag)
        this_CNT_VARS = random.choice(CNT_VARSs)
        this_expr_real = *this_cat_vars, this_op, this_CNT_VARS, real_tbl_name, *this_cat_vars
        cur.execute(this_tmplt.format(*this_expr_real))
        query_real = cur.fetchall()

        query_real_df = pd.DataFrame(
            query_real, columns=[*this_cat_vars, this_CNT_VARS, "count"])

        query_params = {
            "query_type":"agg_1",
            "real_table_name": real_tbl_name,
            "syn_table_name": np.nan,
            "query_tmplt_idx": grp_rank,
            "query_tmplt": this_tmplt,
            "query_cat_vars": this_cat_vars,
            "query_cnt_vars": np.nan,
            "query_cnt_var": this_CNT_VARS,
            "query_agg_op": this_op,
            "real_n_rcrds": len(query_real_df),
            "syn_n_rcrds": np.nan,
            "query_match_vars": this_cat_vars, 
            "real_sql":this_tmplt.format(*this_expr_real),
            "syn_sql":np.nan
        }

        return query_real_df, query_params



    def _gen_twin_agg_query_c1(self, syn_tbl_name) -> pd.DataFrame:
        """ The function generates a random aggregate query for both the real and its corresponding 
        synthetic data with the table names given in real_tbl_name and syn_tbl_name respectively. The tables are assumed to be available 
        in the database with given cursor 'cur'. The function returns both queries for real and syn tables. It also returns the applied aggregate 
        operation name. Do not use this function if there are no continuous variables in the dataset"""
        self.SYN_TBL_NAME=syn_tbl_name
        cur = self.CUR
        real_tbl_name = self.REAL_TBL_NAME
        cat_vars = self.CAT_VARS
        CNT_VARSs = self.CNT_VARS
        tmplts = self._make_agg_tmplts_c1(len(cat_vars))
        # Form random combination
        # you can substitute len(tmplts) by you number of choice if you want to limit the number of grouped categories by that number
        tmplts_idx = list(range(len(tmplts)))
        # grouping rank is the number of variables used in the select statement less 1
        grp_rank = random.choice(tmplts_idx)
        this_tmplt = tmplts[grp_rank]
        this_cat_vars = random.sample(cat_vars, grp_rank+1)
        this_op = random.choice(self._agg_op_bag)
        this_CNT_VARS = random.choice(CNT_VARSs)
        this_expr_real = *this_cat_vars, this_op, this_CNT_VARS, real_tbl_name, *this_cat_vars
        cur.execute(this_tmplt.format(*this_expr_real))
        query_real = cur.fetchall()
        this_expr_syn = *this_cat_vars, this_op, this_CNT_VARS, syn_tbl_name, *this_cat_vars
        cur.execute(this_tmplt.format(*this_expr_syn))
        query_syn = cur.fetchall()

        query_real_df = pd.DataFrame(
            query_real, columns=[*this_cat_vars, this_CNT_VARS, "count"])
        query_syn_df = pd.DataFrame(
            query_syn, columns=[*this_cat_vars, this_CNT_VARS, "count"])
        query_params = {
            "query_type":"agg_1",
            "real_table_name": real_tbl_name,
            "syn_table_name": syn_tbl_name,
            "query_tmplt_idx": grp_rank,
            "query_tmplt": this_tmplt,
            "query_cat_vars": this_cat_vars,
            "query_cnt_vars": np.nan,
            "query_cnt_var": this_CNT_VARS,
            "query_agg_op": this_op,
            "real_n_rcrds": len(query_real_df),
            "syn_n_rcrds": len(query_syn_df),
            "query_match_vars": this_cat_vars, 
            "real_sql":this_tmplt.format(*this_expr_real),
            "syn_sql":this_tmplt.format(*this_expr_syn)
        }

        return query_real_df, query_syn_df, query_params

    def _gen_det_twin_agg_query_c0(self, def_cat_vars: list,syn_tbl_name) -> pd.DataFrame:
        """ The function generates a specific query defined by the input list of categorical variables for both the real and its corresponding 
        synthetic data with the table names given in real_tbl_name and syn_tbl_name respectively. The tables are assumed to be available 
        in the database with given cursor 'cur'. The function returns both queries for real and syn tables. 
        The generated query do not include any aggregation of continuous variables."""
        self.SYN_TBL_NAME=syn_tbl_name
        cur = self.CUR
        real_tbl_name = self.REAL_TBL_NAME
        tmplts = self._make_agg_tmplts_c0(len(def_cat_vars))
        # Form random combination
        # you can substitute len(tmplts) by you number of choice if you want to limit the number of grouped categories by that number
        tmplts_idx = list(range(len(def_cat_vars)))
        grp_rank = len(tmplts_idx)
        this_tmplt = tmplts[grp_rank-1]
        this_expr_real = *def_cat_vars, real_tbl_name, *def_cat_vars
        cur.execute(this_tmplt.format(*this_expr_real))
        query_real = cur.fetchall()
        this_expr_syn = *def_cat_vars, syn_tbl_name, *def_cat_vars
        cur.execute(this_tmplt.format(*this_expr_syn))
        query_syn = cur.fetchall()

        query_real_df = pd.DataFrame(
            query_real, columns=[*def_cat_vars, "count"])
        query_syn_df = pd.DataFrame(
            query_syn, columns=[*def_cat_vars, "count"])
        query_params = {
            "query_type":"agg_2",
            "real_table_name": real_tbl_name,
            "syn_table_name": syn_tbl_name,
            "query_tmplt_idx": grp_rank,
            "query_tmplt": this_tmplt,
            "query_cat_vars": def_cat_vars,
            "query_cnt_vars": np.nana,
            "query_cnt_var": np.nan,
            "query_agg_op": np.nan,
            "real_n_rcrds": len(query_real_df),
            "syn_n_rcrds": len(query_syn_df),
            "query_match_vars": def_cat_vars,
            "real_sql":this_tmplt.format(*this_expr_real),
            "syn_sql":this_tmplt.format(*this_expr_syn)
        }
        return query_real_df, query_syn_df, query_params


    def _gen_single_agg_query_c0(self) -> pd.DataFrame:
        cur = self.CUR
        real_tbl_name = self.REAL_TBL_NAME
        cat_vars = self.CAT_VARS
        tmplts = self._make_agg_tmplts_c0(len(cat_vars))
        # Form random combination
        # you can substitute len(tmplts) by you number of choice if you want to limit the number of grouped categories by that number
        tmplts_idx = list(range(len(tmplts)))
        # grouping rank is teh number of variables used in teh select statement less 1
        grp_rank = random.choice(tmplts_idx)
        this_tmplt = tmplts[grp_rank]
        this_cat_vars = random.sample(cat_vars, grp_rank+1)
        this_expr_real = *this_cat_vars, real_tbl_name, *this_cat_vars
        cur.execute(this_tmplt.format(*this_expr_real))
        query_real = cur.fetchall()

        query_real_df = pd.DataFrame(
            query_real, columns=[*this_cat_vars, "count"])

        query_params = {
            "query_type":"agg_2",
            "real_table_name": real_tbl_name,
            "syn_table_name": np.nan,
            "query_tmplt_idx": grp_rank,
            "query_tmplt": this_tmplt,
            "query_cat_vars": this_cat_vars,
            "query_cnt_vars": np.nan,
            "query_cnt_var": np.nan,
            "query_agg_op": np.nan,
            "real_n_rcrds": len(query_real_df),
            "syn_n_rcrds": np.nan,
            "query_match_vars": this_cat_vars,
            "real_sql":this_tmplt.format(*this_expr_real),
            "syn_sql":np.nan
        }

        return query_real_df, query_params


    def _gen_twin_agg_query_c0(self,syn_tbl_name) -> pd.DataFrame:
        """ The function generates a random aggregate query for both the real and its corresponding 
        synthetic data with the table names given in real_tbl_name and syn_tbl_name respectively. The tables are assumed to be available 
        in the database with given cursor 'cur'. The function returns both queries for real and syn tables. 
        The generated query do not include any aggregation of continuous variables."""
        cur = self.CUR
        real_tbl_name = self.REAL_TBL_NAME
        cat_vars = self.CAT_VARS
        tmplts = self._make_agg_tmplts_c0(len(cat_vars))
        # Form random combination
        # you can substitute len(tmplts) by you number of choice if you want to limit the number of grouped categories by that number
        tmplts_idx = list(range(len(tmplts)))
        # grouping rank is teh number of variables used in teh select statement less 1
        grp_rank = random.choice(tmplts_idx)
        this_tmplt = tmplts[grp_rank]
        this_cat_vars = random.sample(cat_vars, grp_rank+1)
        this_expr_real = *this_cat_vars, real_tbl_name, *this_cat_vars
        cur.execute(this_tmplt.format(*this_expr_real))
        query_real = cur.fetchall()
        this_expr_syn = *this_cat_vars, syn_tbl_name, *this_cat_vars
        cur.execute(this_tmplt.format(*this_expr_syn))
        query_syn = cur.fetchall()

        query_real_df = pd.DataFrame(
            query_real, columns=[*this_cat_vars, "count"])
        query_syn_df = pd.DataFrame(
            query_syn, columns=[*this_cat_vars, "count"])
        query_params = {
            "query_type":"agg_2",
            "real_table_name": real_tbl_name,
            "syn_table_name": syn_tbl_name,
            "query_tmplt_idx": grp_rank,
            "query_tmplt": this_tmplt,
            "query_cat_vars": this_cat_vars,
            "query_cnt_vars": np.nan,
            "query_cnt_var": np.nan,
            "query_agg_op": np.nan,
            "real_n_rcrds": len(query_real_df),
            "syn_n_rcrds": len(query_syn_df),
            "query_match_vars": this_cat_vars,
            "real_sql":this_tmplt.format(*this_expr_real),
            "syn_sql":this_tmplt.format(*this_expr_syn)
        }

        return query_real_df, query_syn_df, query_params

    def gen_twin_agg_queries(self, n_rnd_queries,syn_tbl_name, agg_fntn=True) -> dict:
        if agg_fntn:
            assert agg_fntn and self.CNT_VARS, "Data shall include at least one continuous variable, or set agg_fntn to False"
        queries = {'query_real': [], 'query_syn': [], 'query_params': []}
        for k in range(n_rnd_queries):
            if agg_fntn:
                query_real, query_syn, query_params = self._gen_twin_agg_query_c1(syn_tbl_name)
            else:
                query_real, query_syn, query_params = self._gen_twin_agg_query_c0(syn_tbl_name)
            queries['query_real'].append(query_real)
            queries['query_syn'].append(query_syn)
            queries['query_params'].append(query_params)
            print('Generated Aggregate Query {} '.format(str(k)))
        print('\n')
        return queries


    def gen_single_agg_queries(self, n_rnd_queries, agg_fntn=True) -> dict:
        if agg_fntn:
            assert agg_fntn and self.CNT_VARS, "Data shall include at least one continuous variable, or set agg_fntn to False"
        queries = {'query_real': [], 'query_params': []}
        for k in range(n_rnd_queries):
            if agg_fntn:
                query_real, query_params = self._gen_single_agg_query_c1()
            else:
                query_real, query_params = self._gen_single_agg_query_c0()
            queries['query_real'].append(query_real)
            queries['query_params'].append(query_params)
            print('Generated Aggregate Query {} '.format(str(k)))
        print('\n')
        return queries

    def gen_single_fltr_queries(self, n_rnd_queries,agg_fntn=True) -> dict:
        if agg_fntn:
            assert agg_fntn and self.CNT_VARS, "Data shall include at least one continuous variable, or set agg_fntn to False"
        cur = self.CUR
        queries = {'query_real': [],  'query_params': []}
        for k in range(n_rnd_queries):
            this_n_vars = random.randrange(1, len(self.VARS))
            # SMK - Randomly pick a number of WHERE variables for the query
            this_vars = list(np.random.choice(
                self.VARS, size=this_n_vars, replace=False))
            real_expr, expr_params = self._gen_fltr_expr(
                this_vars, agg_fntn=agg_fntn)

            cur.execute(real_expr)
            query_real = cur.fetchall()
            query_real_headers = [description[0]
                                  for description in cur.description]
            query_real_df = pd.DataFrame(
                query_real, columns=query_real_headers)


            query_params = {
                "query_type":'fltr_{}'.format(str(int(agg_fntn))),
                "real_table_name": self.REAL_TBL_NAME,
                "syn_table_name": np.nan,
                "query_tmplt_idx": np.nan,
                "real_query_tmplt": real_expr,
                "syn_query_tmplt": np.nan,
                "query_cat_vars": expr_params['where_cat_vars'],
                "query_cnt_vars": expr_params['where_cnt_vars'],
                "query_cnt_var": expr_params['agg_cnt_var'],
                "query_agg_op": expr_params['query_agg_op'],
                "real_n_rcrds": len(query_real_df),
                "syn_n_rcrds": np.nan,
                "query_match_vars": expr_params['where_cat_vars']+expr_params['where_cnt_vars'],
                "real_sql":real_expr,
                "syn_sql":np.nan
            }

            queries['query_real'].append(query_real_df)
            queries['query_params'].append(query_params)
            
            print('Generated Filter Query {} '.format(str(k)))
        return queries


    def gen_twin_fltr_queries(self, n_rnd_queries, tbl_syn,agg_fntn=True) -> dict:
        if agg_fntn:
            assert agg_fntn and self.CNT_VARS, "Data shall include at least one continuous variable, or set agg_fntn to False"
        cur = self.CUR
        queries = {'query_real': [], 'query_syn': [], 'query_params': []}
        for k in range(n_rnd_queries):
            this_n_vars = random.randrange(1, len(self.VARS))
            # SMK - Randomly pick a number of WHERE variables for the query
            this_vars = list(np.random.choice(
                self.VARS, size=this_n_vars, replace=False))
            real_expr, syn_expr, expr_params = self._gen_twin_fltr_expr(
                this_vars,tbl_syn, agg_fntn=agg_fntn)

            cur.execute(real_expr)
            query_real = cur.fetchall()
            query_real_headers = [description[0]
                                  for description in cur.description]
            query_real_df = pd.DataFrame(
                query_real, columns=query_real_headers)

            cur.execute(syn_expr)
            query_syn = cur.fetchall()
            query_syn_headers = [description[0]
                                 for description in cur.description]
            query_syn_df = pd.DataFrame(query_syn, columns=query_syn_headers)
            query_params = {
                "query_type":'fltr_{}'.format(str(int(agg_fntn))),
                "real_table_name": self.REAL_TBL_NAME,
                "syn_table_name": tbl_syn,
                "query_tmplt_idx": np.nan,
                "real_query_tmplt": real_expr,
                "syn_query_tmplt": syn_expr,
                "query_cat_vars": expr_params['where_cat_vars'],
                "query_cnt_vars": expr_params['where_cnt_vars'],
                "query_cnt_var": expr_params['agg_cnt_var'],
                "query_agg_op": expr_params['query_agg_op'],
                "real_n_rcrds": len(query_real_df),
                "syn_n_rcrds": len(query_syn_df),
                "query_match_vars": expr_params['where_cat_vars']+expr_params['where_cnt_vars'],
                "real_sql":real_expr,
                "syn_sql":syn_expr
            }

            queries['query_real'].append(query_real_df)
            queries['query_syn'].append(query_syn_df)
            queries['query_params'].append(query_params)
            
            print('Generated Filter Query {} '.format(str(k)))
        return queries

    def _match_agg_queries(self, queries: dict) -> dict:
        real_queries = queries['query_real']
        syn_queries = queries['query_syn']
        query_params = queries['query_params']
        matched_queries = {'query_real': [],
                           'query_syn': [], 'query_params': []}
        for query_real, query_syn, query_params in zip(real_queries, syn_queries, query_params):
            matched_real, matched_syn = self._match_class_records(
                query_params, query_real, query_syn)
            matched_queries['query_real'].append(matched_real)
            matched_queries['query_syn'].append(matched_syn)
            matched_queries['query_params'].append(query_params)
        return matched_queries

    def _make_hlngr_pivot(self, real_df: pd.DataFrame, syn_df: pd.DataFrame) -> pd.DataFrame:
        real_counts = real_df['count'].values
        syn_counts = syn_df['count'].values
        pivot = np.concatenate([real_counts.reshape(
            1, -1), syn_counts.reshape(1, -1)], axis=0)
        pivot = pd.DataFrame(pivot, index=['real', 'syn'])
        return pivot.T

    def _make_ecldn_pivot(self, real_df: pd.DataFrame, syn_df: pd.DataFrame, agg_var_name) -> pd.DataFrame:
        real_vals = real_df[agg_var_name].values
        syn_vals = syn_df[agg_var_name].values
        pivot = np.concatenate(
            [real_vals.reshape(1, -1), syn_vals.reshape(1, -1)], axis=0)
        pivot = pd.DataFrame(pivot, index=['real', 'syn'])
        return pivot.T

    def _calc_hlngr_dist(self, pivot: pd.DataFrame, dropna) -> float:
        if dropna:
            pivot = pivot.dropna()  # drop nan (ie drop non-matching records)
        else:
            pivot = pivot.fillna(0)  # replace nan with 0 (the default)

        p = pivot['real'].values
        p = p/np.sum(p)
        q = pivot['syn'].values
        q = q/np.sum(q)
        z = np.sqrt(p) - np.sqrt(q)
        return np.sqrt(z @ z / 2)

    def _calc_ecldn_dist(self, pivot: pd.DataFrame) -> float:
        pivot = pivot.dropna()
        p = pivot['real'].values
        q = pivot['syn'].values
        scaler = StandardScaler()
        pq_s = scaler.fit_transform((p-q).reshape(-1, 1))
        return np.linalg.norm(pq_s, 2)

    def get_agg_metrics(self, queries: dict, hlngr_dropna=False) -> dict:
        """ The function returns Hillinger distance and Euclidean distance (whenever applicable) for each real-syn query tuple in the input dictionary"""
        matched_queries = self._match_agg_queries(queries)
        matched_queries["hlngr_dist"] = []
        matched_queries["ecldn_dist"] = []
        real_queries = matched_queries['query_real']
        syn_queries = matched_queries['query_syn']
        query_params = matched_queries['query_params']
        for query_real, query_syn, query_params in zip(real_queries, syn_queries, query_params):
            hlngr_pivot = self._make_hlngr_pivot(query_real, query_syn)
            hlngr_dist = self._calc_hlngr_dist(
                hlngr_pivot, dropna=hlngr_dropna)
            matched_queries["hlngr_dist"].append(hlngr_dist)
            # For case1, both hlngr and ecldn pivots and distances will be produced
            if not pd.isnull(query_params['query_agg_op']):
                ecldn_pivot = self._make_ecldn_pivot(
                    query_real, query_syn, query_params['query_cnt_var'])
                ecldn_dist = self._calc_ecldn_dist(ecldn_pivot)
                matched_queries["ecldn_dist"].append(ecldn_dist)
            else:  # For case 0, only hlngr pivots wil be produced
                matched_queries["ecldn_dist"].append(np.nan)

        return matched_queries

    def get_fltr_metrics(self, queries: dict)-> dict:
        hits=[]
        misses=[]
        diffs=[]
        for real, syn, params in zip(queries['query_real'], queries['query_syn'], queries['query_params']):
            if params['query_type']=='fltr_0':
                # unify types of real and syn dataframes
                types_dict=dict(real.dtypes)
                syn=syn.astype(types_dict)         
                #find hits and misses
                in_both=df = real.merge(syn, how = 'inner' ,indicator=False)
                hits.append(len(in_both))
                misses.append(len(real)-len(in_both))
            else:
                diffs.append(np.nan_to_num(np.abs(real-syn).values.ravel()))
                
        if params['query_type']=='fltr_0':
            queries['hits']=hits
            queries['misses']=misses
        else:
            queries['agg_fnctn_diffs']=[diffs[i][0] for i in range(len(diffs))]
            queries['count_diffs']=[diffs[i][1] for i in range(len(diffs))]

        return queries



################################################################################################################################################################S


def extract_fnames(data_dir: Path) -> list:
    """ The function extract file names without teh extension for all the files in the input directory 'data_dir. It returns a list with all file names """
    ds_fn=os.listdir(data_dir) # Obtain a list of dataset file names
    ds_name=[Path(ds_fn_i).stem for ds_fn_i in ds_fn]
    print('Extracted the names of {} real datasets'.format(str(len(ds_name))))
    return ds_name

def find_syn_fnames(syn_data_dir: Path, real_names: list) -> dict:
    syn_dict={}
    for real_name_i in real_names:
        catch_file=[]
        for syn_name_i in os.listdir(syn_data_dir):
            if syn_name_i.startswith(real_name_i+'_'):
                catch_file.append(Path(syn_name_i).stem)
            syn_dict[real_name_i]=catch_file
    print('Extracted the names of all available synthetic datasets corresponding to {} real datasets'.format(str(len(syn_dict))))
    return syn_dict


def load_csv(file_path: Path) -> list:
    df=pd.read_csv(file_path,encoding = "ISO-8859-1") 
    #remove any apostrophe from data
    df=df.replace({"'":""}, regex=True)
    return df

def get_metadata(file_path: Path) -> dict:
    """ The function reareal the input json file and returns a dictionary """
    metafile= open(file_path)
    return json.load(metafile)

def make_table(real_name: list, real: list, db_conn):
    """" The function converts input dataframe into a table using the input database cursor """
    cur=db_conn.cursor()
    cur.execute("SELECT count(name) FROM sqlite_master WHERE type='table' AND name=(?) ",(real_name,)) #sqlite_master holds  the schema of the db including table names
    if cur.fetchone()[0]==0 : # If table does not exist (ie returned count is zero), then import the table into db from pandas
        real.to_sql(real_name, db_conn, index=False)
        print(f'Table {real_name} is created in the database')
    else:
        print (f'Table {real_name} already exists in the database')


def discretize_data( data_org: pd.DataFrame, metadata_org: dict, n_bins=10):
    data=copy.deepcopy(data_org)
    metadata=copy.deepcopy(metadata_org)
    cnt_vars=[key for key,value in metadata.items() if value == 'continuous'] #Get all continuous var names 
    clnd_cnt_vars=[name.replace('`','') for name in cnt_vars]
    data_cnt=data[clnd_cnt_vars]
    discretizer = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='uniform')
    data_binned=discretizer.fit_transform(data_cnt.values)
    discretizer.feature_names_in_=data_cnt.columns
    data[clnd_cnt_vars]=data_binned
    metadata=metadata.fromkeys(metadata,'nominal')
    return data, metadata

def calc_stats(history_arr):
    mean=np.mean(history_arr)
    median=np.median(history_arr)
    stddev=np.sqrt(np.var(history_arr))
    return {'mean':mean, 'median':median, 'stddev':stddev}


    
def print_single_agg_queries(queries: dict, file_writer):
    all_real = queries['query_real']
    all_params = queries['query_params']
    for real,params in zip(all_real,all_params):
        n_real_records=params['real_n_rcrds']
        # get any 5 records to display from both real and syn queries
        a = list(range(len(real)))
        b = random.sample(a, min(5, len(a)))
        real = real.iloc[b]
        real_style = real.style.set_table_attributes("style='display:inline; margin-right: 20px; font-size: 8pt; text-align:center'").set_caption("Data")


        file_writer.write(real_style.to_html())
        file_writer.write('<br><br>')
    
        if not pd.isnull(params['query_agg_op']):
            file_writer.write('<p style="font-size: 8pt; margin-bottom:-10px"><u>SQL:</u></p>')
            expr = params['query_tmplt'].format(*params['query_cat_vars'], params['query_agg_op'], params['query_cnt_var'], params['real_table_name'], *params['query_cat_vars'])
            file_writer.write('<p style="font-size: 8pt">{}</p>'.format(expr))
            
            file_writer.write('<p style="font-size: 8pt; margin-top:-5px"> Resulted in {} records</p>'.format(str(n_real_records)))  

        else:
            file_writer.write('<p style="font-size: 8pt; margin-bottom:-10px"><u>SQL:</u></p>')
            expr = params['query_tmplt'].format(*params['query_cat_vars'], params['real_table_name'], *params['query_cat_vars'])
            file_writer.write('<p style="font-size: 8pt">{}</p>'.format(expr))
            
            file_writer.write('<p style="font-size: 8pt; margin-top:-5px"> Resulted in {} records</p>'.format(str(n_real_records)))
            
        file_writer.write("<p>===========================================</p>")


    return file_writer

def print_twin_agg_queries(queries: dict, file_writer):
    all_real = queries['query_real']
    all_syn = queries['query_syn']
    all_params = queries['query_params']
    all_hlngr = queries['hlngr_dist']
    all_ecldn = queries['ecldn_dist']
    for real, syn, params, hlngr, ecldn in zip(all_real, all_syn, all_params, all_hlngr, all_ecldn):
        n_real_records=params['real_n_rcrds']
        n_syn_records=params['syn_n_rcrds']
        # get any 5 records to display from both real and syn queries
        a = list(range(len(real)))
        b = random.sample(a, min(5, len(a)))
        real = real.iloc[b]
        syn = syn.iloc[b]
        real_style = real.style.set_table_attributes("style='display:inline; margin-right: 20px; font-size: 8pt; text-align:center'").set_caption("Real")
        syn_style = syn.style.set_table_attributes("style='display:inline; font-size: 8pt;text-align:center'").set_caption("Synthetic")

        if ecldn > 100:
            real_style.set_properties(**{'color': 'blue'})
            syn_style.set_properties(**{'color': 'blue'})

        if hlngr > 0.5:
            real_style.set_properties(**{'color': 'red'})
            syn_style.set_properties(**{'color': 'red'})

        file_writer.write(real_style.to_html())
        file_writer.write('<br><br>')
        file_writer.write(syn_style.to_html())
    
        if not pd.isnull(params['query_agg_op']):
            file_writer.write('<p style="font-size: 8pt; margin-bottom:-10px"><u>SQL for Real:</u></p>')
            expr = params['query_tmplt'].format(*params['query_cat_vars'], params['query_agg_op'], params['query_cnt_var'], params['real_table_name'], *params['query_cat_vars'])
            file_writer.write('<p style="font-size: 8pt">{}</p>'.format(expr))
            
            file_writer.write('<p style="font-size: 8pt; margin-top:-5px"> Resulted in {} records</p>'.format(str(n_real_records)))
            
            file_writer.write('<p style="font-size: 8pt;margin-bottom:-10px"><u>SQL for Synthetic:</u></p>')
            expr = params['query_tmplt'].format(*params['query_cat_vars'], params['query_agg_op'], params['query_cnt_var'], params['syn_table_name'], *params['query_cat_vars'])
            file_writer.write('<p style="font-size: 8pt">{}</p>'.format(expr))
            
            file_writer.write('<p style="font-size: 8pt; margin-top:-5px"> Resulted in {} records</p>'.format(str(n_syn_records)))
            
            file_writer.write('<p style="font-size: 8pt"> Normalized Euclidean distance for ({}): {} </p>'.format( params['query_cnt_var'], str(np.round(ecldn, 2))))
        else:
            file_writer.write('<p style="font-size: 8pt; margin-bottom:-10px"><u>SQL for Real:</u></p>')
            expr = params['query_tmplt'].format(*params['query_cat_vars'], params['real_table_name'], *params['query_cat_vars'])
            file_writer.write('<p style="font-size: 8pt">{}</p>'.format(expr))
            
            file_writer.write('<p style="font-size: 8pt; margin-top:-5px"> Resulted in {} records</p>'.format(str(n_real_records)))
            
            file_writer.write('<p style="font-size: 8pt;margin-bottom:-10px"><u>SQL for Synthetic:</u></p>')
            expr = params['query_tmplt'].format(*params['query_cat_vars'], params['syn_table_name'], *params['query_cat_vars'])
            file_writer.write('<p style="font-size: 8pt">{}</p>'.format(expr))
            
            file_writer.write('<p style="font-size: 8pt; margin-top:-5px"> Resulted in {} records</p>'.format(str(n_syn_records)))

        file_writer.write('<p style="font-size: 8pt"> Hellinger Distance: {} </p>'.format(str(np.round(hlngr, 3))))
        file_writer.write("<p>===========================================</p>")

    file_writer.write('<br>')
    hlngr_stats=calc_stats(np.array(all_hlngr))
    file_writer.write('<p style="font-size: 10pt; page-break-before:always"> Hellinger Distance Summary: \n  {} </p>'.format(str(hlngr_stats)))
    if not pd.isnull(params['query_agg_op']):
        ecldn_stats=calc_stats(np.array(all_ecldn))
        file_writer.write('<p style="font-size: 10pt"> Euclidean distance Summary : \n {} </p>'.format(str(ecldn_stats)))
    file_writer.write("<p>===========================================</p>")
    return file_writer

def print_single_fltr_queries(queries: dict, file_writer):
    all_real = queries['query_real']
    all_params = queries['query_params']
    for real, params in zip(all_real, all_params,):
        n_real_records=params['real_n_rcrds']
        real = real.head(5)
        real_style = real.style.set_table_attributes("style='display:inline; margin-right: 20px; font-size: 8pt; text-align:center'").set_caption("Real")


        file_writer.write(real_style.to_html())
        file_writer.write('<br><br>')
    
        # if not pd.isnull(params['query_agg_op']):
        #     file_writer.write('<p style="font-size: 8pt; margin-bottom:-10px"><u>SQL for Input Dataset:</u></p>')
        #     expr = params['real_query_tmplt'].format(*params['query_cat_vars'], params['query_agg_op'], params['query_cnt_var'], params['real_table_name'], *params['query_cat_vars'])
        #     file_writer.write('<p style="font-size: 8pt">{}</p>'.format(expr))
            
        #     file_writer.write('<p style="font-size: 8pt; margin-top:-5px"> Resulted in {} records</p>'.format(str(n_real_records)))
        
        # else:
        file_writer.write('<p style="font-size: 8pt; margin-bottom:-10px"><u>SQL for Real:</u></p>')
        file_writer.write('<p style="font-size: 8pt">{}</p>'.format(params['real_query_tmplt']))
        
        file_writer.write('<p style="font-size: 8pt; margin-top:-5px"> Resulted in {} records</p>'.format(str(n_real_records)))

        file_writer.write("<p>===========================================</p>")

    file_writer.write('<br>')
    file_writer.write("<p>===========================================</p>")
    return file_writer


def print_twin_fltr_queries0(queries: dict, file_writer):
    all_real = queries['query_real']
    all_syn = queries['query_syn']
    all_params = queries['query_params']
    all_hits = queries['hits']
    all_misses = queries['misses']
    for real, syn, params, hits, misses in zip(all_real, all_syn, all_params, all_hits, all_misses):
        n_real_records=params['real_n_rcrds']
        n_syn_records=params['syn_n_rcrds']
        real = real.head(3)
        syn = syn.head(3)
        real_style = real.style.set_table_attributes("style='display:inline; margin-right: 20px; font-size: 8pt; text-align:center'").set_caption("Real")
        syn_style = syn.style.set_table_attributes("style='display:inline; font-size: 8pt;text-align:center'").set_caption("Synthetic")

        if hits > 0:
            real_style.set_properties(**{'color': 'green'})
            syn_style.set_properties(**{'color': 'green'})

        file_writer.write(real_style.to_html())
        file_writer.write('<br><br>')
        file_writer.write(syn_style.to_html())
    
        # if not pd.isnull(params['query_agg_op']):
        #     file_writer.write('<p style="font-size: 8pt; margin-bottom:-10px"><u>SQL for Real:</u></p>')
        #     expr = params['real_query_tmplt'].format(*params['query_cat_vars'], params['query_agg_op'], params['query_cnt_var'], params['real_table_name'], *params['query_cat_vars'])
        #     file_writer.write('<p style="font-size: 8pt">{}</p>'.format(expr))
            
        #     file_writer.write('<p style="font-size: 8pt; margin-top:-5px"> Resulted in {} records</p>'.format(str(n_real_records)))
            
        #     file_writer.write('<p style="font-size: 8pt;margin-bottom:-10px"><u>SQL for Synthetic:</u></p>')
        #     expr = params['syn_query_tmplt'].format(*params['query_cat_vars'], params['query_agg_op'], params['query_cnt_var'], params['syn_table_name'], *params['query_cat_vars'])
        #     file_writer.write('<p style="font-size: 8pt">{}</p>'.format(expr))
            
        #     file_writer.write('<p style="font-size: 8pt; margin-top:-5px"> Resulted in {} records</p>'.format(str(n_syn_records)))
            
        #     file_writer.write('<p style="font-size: 8pt">  Querying synthetic data resulted in ({}) identical matches to real data (HITS)  </p>'.format(  str(hits)))
        #     file_writer.write('<p style="font-size: 8pt"> Querying synthetic data resulted in ({}) mis-matches  to real data (MISSES) </p>'.format( str(misses)))

        # else:
        file_writer.write('<p style="font-size: 8pt; margin-bottom:-10px"><u>SQL for Real:</u></p>')
        file_writer.write('<p style="font-size: 8pt">{}</p>'.format(params['real_query_tmplt']))
        
        file_writer.write('<p style="font-size: 8pt; margin-top:-5px"> Resulted in {} records</p>'.format(str(n_real_records)))
        
        file_writer.write('<p style="font-size: 8pt;margin-bottom:-10px"><u>SQL for Synthetic:</u></p>')
        file_writer.write('<p style="font-size: 8pt">{}</p>'.format(params['syn_query_tmplt']))
        
        file_writer.write('<p style="font-size: 8pt; margin-top:-5px"> Resulted in {} records</p>'.format(str(n_syn_records)))

        file_writer.write('<p style="font-size: 8pt">  Querying synthetic data resulted in ({}) identical matches to real data (HITS)  </p>'.format(  str(hits)))
        file_writer.write('<p style="font-size: 8pt"> Querying synthetic data resulted in ({}) mis-matches  to real data (MISSES) </p>'.format( str(misses)))

        file_writer.write("<p>===========================================</p>")

    file_writer.write('<br>')
    file_writer.write("<p>===========================================</p>")
    return file_writer




def print_twin_fltr_queries1(queries: dict, file_writer):
    all_real = queries['query_real']
    all_syn = queries['query_syn']
    all_params = queries['query_params']
    all_fnctn_diffs = queries['agg_fnctn_diffs']
    all_count_diffs = queries['count_diffs']
    for real, syn, params, fnctn_diff, count_diff in zip(all_real, all_syn, all_params, all_fnctn_diffs, all_count_diffs):
        n_real_records=params['real_n_rcrds']
        n_syn_records=params['syn_n_rcrds']
        real = real.head(3)
        syn = syn.head(3)
        real_style = real.style.set_table_attributes("style='display:inline; margin-right: 20px; font-size: 8pt; text-align:center'").set_caption("Real")
        syn_style = syn.style.set_table_attributes("style='display:inline; font-size: 8pt;text-align:center'").set_caption("Synthetic")

        file_writer.write(real_style.to_html())
        file_writer.write('<br><br>')
        file_writer.write(syn_style.to_html())
    
        # if not pd.isnull(params['query_agg_op']):
        file_writer.write('<p style="font-size: 8pt; margin-bottom:-10px"><u>SQL for Real:</u></p>')
        file_writer.write('<p style="font-size: 8pt">{}</p>'.format(params['real_query_tmplt']))
        
        file_writer.write('<p style="font-size: 8pt; margin-top:-5px"> Resulted in {} records</p>'.format(str(n_real_records)))
        
        file_writer.write('<p style="font-size: 8pt;margin-bottom:-10px"><u>SQL for Synthetic:</u></p>')
        file_writer.write('<p style="font-size: 8pt">{}</p>'.format(params['syn_query_tmplt']))
        
        file_writer.write('<p style="font-size: 8pt; margin-top:-5px"> Resulted in {} records</p>'.format(str(n_syn_records)))
        
        file_writer.write('<p style="font-size: 8pt"> Aggregate value difference between real and synthetic: ({})  </p>'.format(  str(fnctn_diff)))
        file_writer.write('<p style="font-size: 8pt"> Count value difference between real and synthetic: ({})  </p>'.format( str(count_diff)))

        # else:
        #     file_writer.write('<p style="font-size: 8pt; margin-bottom:-10px"><u>SQL for Real:</u></p>')
        #     expr = params['real_query_tmplt'].format(*params['query_cat_vars'], params['real_table_name'], *params['query_cat_vars'])
        #     file_writer.write('<p style="font-size: 8pt">{}</p>'.format(expr))
            
        #     file_writer.write('<p style="font-size: 8pt; margin-top:-5px"> Resulted in {} records</p>'.format(str(n_real_records)))
            
        #     file_writer.write('<p style="font-size: 8pt;margin-bottom:-10px"><u>SQL for Synthetic:</u></p>')
        #     expr = params['syn_query_tmplt'].format(*params['query_cat_vars'], params['syn_table_name'], *params['query_cat_vars'])
        #     file_writer.write('<p style="font-size: 8pt">{}</p>'.format(expr))
            
        #     file_writer.write('<p style="font-size: 8pt; margin-top:-5px"> Resulted in {} records</p>'.format(str(n_syn_records)))

        #     file_writer.write('<p style="font-size: 8pt"> Aggregate value difference between real and synthetic: ({})  </p>'.format(  str(fnctn_diff)))
        #     file_writer.write('<p style="font-size: 8pt"> Count value difference between real and synthetic: ({}) </p>'.format( str(count_diff)))

        file_writer.write("<p>===========================================</p>")

    file_writer.write('<br>')
    file_writer.write("<p>===========================================</p>")
    return file_writer

    
def plot_violin(history: array, xlabel, title, stats_dict):
    fig, ax=plt.subplots(1,1,figsize=(12, 6))
    sns.violinplot(x=history, ax=ax)
    #ax.set_xlim(-0.2,1)
    ax.set_xlabel(xlabel+" ( median: {} , mean: {} , std dev: {} ) ".format(round(stats_dict['median'],2), round(stats_dict['mean'],2),round(stats_dict['stddev'],2)))
    #ax.set_xticks([0,0.2,0.4,0.6,0.8,1.0])
    fig.suptitle(title, fontsize=12)
    return fig



##########################################################################################################################################################################




# def fuzzy_sql(n_queries: int, real_name: str, syn_name='None', query_type= 'single_agg') -> dict:
#     """ The function generates (n_queries) number of randomly generated SELECT queries for the input datasets. The input datasets named (real_name) shall be tabular and saved earlier in csv format in the folder /data/real. The file name shall be identical to the input (real_name). The function also generates random twin queries for both real and twin synthetic datasets. The synthetic dataset shall saved in /data/synthetic. The query_type can be one of the following: 'single_agg', 'single_fltr', 'twin_agg', 'twin_fltr'.
#     The function generates the necessary reports and a dictionary of all generated queries, query parameters and distance scores, if applicable."""
    
#     assert n_queries == int(n_queries), "n_queries must be integer"
#     # Set paths
#     root_dir=Path(__file__).parent.parent
#     os.chdir(root_dir)
#     real_data_dir=os.path.join(root_dir,'data/real') 
#     syn_data_dir=os.path.join(root_dir,'data/synthetic') 
#     metadata_dir=os.path.join(root_dir,'data/metadata')

#     dt = datetime.datetime.now(datetime.timezone.utc)
#     utc_time = dt.replace(tzinfo=datetime.timezone.utc)
#     utc_timestamp = utc_time.timestamp()
#     run_id=int(utc_timestamp)


#     run_id=real_name+'_'+str(run_id)
#     run_dir=os.path.join(root_dir, 'runs', run_id)
#     os.mkdir(run_dir)

#     real_file_path=os.path.join(real_data_dir,real_name+'.csv')
#     if os.path.isfile(real_file_path):
#         real=load_csv(real_file_path)
#         # Create database and load real data into it
#         conn = sqlite3.connect('fuzzy_sql.db')
#         make_table(real_name, real, conn)
#     else:
#         raise Exception('The file {}.csv does not exist in the directory /data/real!'.format(real_name))


#     metafile_path=os.path.join(metadata_dir,real_name+'.json')
#     if os.path.isfile(metafile_path):
#         metadata=get_metadata(metafile_path)

#     else:
#         raise Exception('The file {}.json does not exist in the directory /data/metadata!'.format(real_name))


#     if syn_name != 'None':
#         syn_file_path=os.path.join(syn_data_dir,syn_name+'.csv')
#         if os.path.isfile(syn_file_path):
#             syn=load_csv(syn_file_path)
#             # Load syn data into the database
#             make_table(syn_name, syn, conn)
#         else:
#                 raise Exception('The file {}.csv does not exist in the directory /data/synthetic!'.format(syn_name))

#     else:
#         if query_type!='single_agg' and query_type!='single_fltr':
#             raise Exception("You can not choose query type as 'twin_agg' or 'twin_fltr' unless you provide the file name of the synthetic data. Otherwise, please choose query_type as 'single-agg' or 'single_fltr' ")


#     test_tq=TABULAR_QUERY(conn, real_name, metadata)

#     if query_type=='single_fltr':
#         # Single fltr query
#         output_id="single_fltr"
#         agg_fntn=False
#         queries=test_tq.gen_single_fltr_queries(n_queries, agg_fntn=agg_fntn)
#         with open(run_dir+'/sql_{}.html'.format(output_id), 'w') as file_writer:
#             print_single_fltr_queries(queries, file_writer)
#         pdf.from_file(run_dir+'/sql_{}.html'.format(output_id),run_dir+'/sql_{}.pdf'.format(output_id))
#         print("Generated {} random queries and saved results in: /runs/{}".format(len(queries['query_real']), run_id))
#         return queries

#     elif query_type=='twin_fltr':
#         # Twin fltr query
#         output_id="twin_fltr"
#         agg_fntn=True
#         queries=test_tq.gen_twin_fltr_queries(n_queries, syn_name, agg_fntn=agg_fntn)
#         scored_queries=test_tq.get_fltr_metrics(queries)
#         with open(run_dir+'/sql_{}.html'.format(output_id), 'w') as file_writer:
#             if agg_fntn:
#                 print_twin_fltr_queries1(scored_queries, file_writer)
#             else:
#                 print_twin_fltr_queries0(scored_queries, file_writer)
#         pdf.from_file(run_dir+'/sql_{}.html'.format(output_id),run_dir+'/sql_{}.pdf'.format(output_id))
#         print("Generated {} random twin queries and saved results in: /runs/{}".format(len(scored_queries['query_real']), run_id))
#         return scored_queries


#     elif query_type=='single_agg':
#         # Single Agg Query 
#         output_id="single_agg"
#         agg_fntn=False
#         hlngr_dropna=False
#         queries=test_tq.gen_single_agg_queries(n_queries, agg_fntn=agg_fntn) #returned dictionary of non-matching lists
#         with open(run_dir+'/sql_{}.html'.format(output_id), 'w') as file_writer:
#             print_single_agg_queries(queries, file_writer)
#         pdf.from_file(run_dir+'/sql_{}.html'.format(output_id),run_dir+'/sql_{}.pdf'.format(output_id))
#         print("Generated {} random queries and saved results in: /runs/{}".format(len(queries['query_real']), run_id))
#         return queries


#     elif query_type=='twin_agg':
#         #twin agg query
#         output_id="twin_agg"
#         agg_fntn=True
#         hlngr_dropna=False
#         queries=test_tq.gen_twin_agg_queries(n_queries, syn_name, agg_fntn=agg_fntn) #returned dictionary of non-matching lists
#         scored_queries=test_tq.get_agg_metrics(queries, hlngr_dropna=hlngr_dropna)
#         with open(run_dir+'/sql_{}.html'.format(output_id), 'w') as file_writer:
#             print_twin_agg_queries(scored_queries, file_writer)
#         pdf.from_file(run_dir+'/sql_{}.html'.format(output_id),run_dir+'/sql_{}.pdf'.format(output_id))
#         hlngr_stats=calc_stats(scored_queries['hlngr_dist'])
#         fig=plot_violin(np.array(scored_queries['hlngr_dist']),'Hellinger Dist.','Real-Synthetic Query Comparison for {} Dataset'.format(real_name),hlngr_stats)
#         fig.savefig(run_dir+'/hlngr_{}.png'.format(output_id))
#         if agg_fntn:
#             ecldn_stats=calc_stats(scored_queries['ecldn_dist'])
#             fig=plot_violin(np.array(scored_queries['ecldn_dist']),'Euclidean Dist.','Real-Synthetic Query Comparison for {} Dataset'.format(real_name),ecldn_stats)
#             fig.savefig(run_dir+'/ecldn_{}.png'.format(output_id))    
#         print("Generated {} random twin queries and saved results in: /runs/{}".format(len(scored_queries['query_real']), run_id))
#         return scored_queries



def make_fuzzy_sql(n_queries: int, real_file_path, metadata_file_path, syn_file_path='None', query_type= 'single_agg') -> dict:
    """ The function generates (n_queries) number of randomly generated SELECT queries for the input datasets. The input files shall be tabular and  in csv format in the folder. The function also generates random twin queries for both real and twin synthetic datasets.  The query_type can be one of the following: 'single_agg', 'single_fltr', 'twin_agg', 'twin_fltr'.
    The function generates the necessary reports and a dictionary of all generated queries, query parameters and distance scores, if applicable."""
    
    assert n_queries == int(n_queries), "n_queries must be integer"


    if os.path.isfile(real_file_path):
        real=load_csv(real_file_path)
        real_name=Path(real_file_path).stem
        # Create database and load real data into it
        conn = sqlite3.connect('fuzzy_sql.db')
        make_table(real_name, real, conn)
    else:
        raise Exception('The file {} does not exist !'.format(real_file_path))



    if os.path.isfile(metadata_file_path):
        metadata=get_metadata(metadata_file_path)
    else:
        raise Exception('The file {} does not exist'.format(metadata_file_path))


    if syn_file_path != 'None':
        if os.path.isfile(syn_file_path):
            syn=load_csv(syn_file_path)
            syn_name=Path(syn_file_path).stem
            # Load syn data into the database
            make_table(syn_name, syn, conn)
        else:
                raise Exception('The file {}.csv does not exist!'.format(syn_file_path))

    else:
        if query_type!='single_agg' and query_type!='single_fltr':
            raise Exception("You can not choose query type as 'twin_agg' or 'twin_fltr' unless you provide the file name of the synthetic data. Otherwise, please choose query_type as 'single-agg' or 'single_fltr' ")




    dt = datetime.datetime.now(datetime.timezone.utc)
    utc_time = dt.replace(tzinfo=datetime.timezone.utc)
    utc_timestamp = utc_time.timestamp()
    run_id=int(utc_timestamp)
    run_dir=real_name+'_'+str(run_id)
    os.mkdir(run_dir)
    test_tq=TABULAR_QUERY(conn, real_name, metadata)

    if query_type=='single_fltr':
        # Single fltr query
        output_id="single_fltr"
        agg_fntn=False
        queries=test_tq.gen_single_fltr_queries(n_queries, agg_fntn=agg_fntn)
        with open(run_dir+'/sql_{}.html'.format(output_id), 'w') as file_writer:
            print_single_fltr_queries(queries, file_writer)
        pdf.from_file(run_dir+'/sql_{}.html'.format(output_id),run_dir+'/sql_{}.pdf'.format(output_id))
        print("Generated {} random queries and saved results in: /runs/{}".format(len(queries['query_real']), run_id))
        return queries

    elif query_type=='twin_fltr':
        # Twin fltr query
        output_id="twin_fltr"
        agg_fntn=True
        queries=test_tq.gen_twin_fltr_queries(n_queries, syn_name, agg_fntn=agg_fntn)
        scored_queries=test_tq.get_fltr_metrics(queries)
        with open(run_dir+'/sql_{}.html'.format(output_id), 'w') as file_writer:
            if agg_fntn:
                print_twin_fltr_queries1(scored_queries, file_writer)
            else:
                print_twin_fltr_queries0(scored_queries, file_writer)
        pdf.from_file(run_dir+'/sql_{}.html'.format(output_id),run_dir+'/sql_{}.pdf'.format(output_id))
        print("Generated {} random twin queries and saved results in: /runs/{}".format(len(scored_queries['query_real']), run_id))
        return scored_queries


    elif query_type=='single_agg':
        # Single Agg Query 
        output_id="single_agg"
        agg_fntn=False
        hlngr_dropna=False
        queries=test_tq.gen_single_agg_queries(n_queries, agg_fntn=agg_fntn) #returned dictionary of non-matching lists
        with open(run_dir+'/sql_{}.html'.format(output_id), 'w') as file_writer:
            print_single_agg_queries(queries, file_writer)
        pdf.from_file(run_dir+'/sql_{}.html'.format(output_id),run_dir+'/sql_{}.pdf'.format(output_id))
        print("Generated {} random queries and saved results in: /runs/{}".format(len(queries['query_real']), run_id))
        return queries


    elif query_type=='twin_agg':
        #twin agg query
        output_id="twin_agg"
        agg_fntn=True
        hlngr_dropna=False
        queries=test_tq.gen_twin_agg_queries(n_queries, syn_name, agg_fntn=agg_fntn) #returned dictionary of non-matching lists
        scored_queries=test_tq.get_agg_metrics(queries, hlngr_dropna=hlngr_dropna)
        with open(run_dir+'/sql_{}.html'.format(output_id), 'w') as file_writer:
            print_twin_agg_queries(scored_queries, file_writer)
        pdf.from_file(run_dir+'/sql_{}.html'.format(output_id),run_dir+'/sql_{}.pdf'.format(output_id))
        hlngr_stats=calc_stats(scored_queries['hlngr_dist'])
        fig=plot_violin(np.array(scored_queries['hlngr_dist']),'Hellinger Dist.','Real-Synthetic Query Comparison for {} Dataset'.format(real_name),hlngr_stats)
        fig.savefig(run_dir+'/hlngr_{}.png'.format(output_id))
        if agg_fntn:
            ecldn_stats=calc_stats(scored_queries['ecldn_dist'])
            fig=plot_violin(np.array(scored_queries['ecldn_dist']),'Euclidean Dist.','Real-Synthetic Query Comparison for {} Dataset'.format(real_name),ecldn_stats)
            fig.savefig(run_dir+'/ecldn_{}.png'.format(output_id))    
        print("Generated {} random twin queries and saved results in: /runs/{}".format(len(scored_queries['query_real']), run_id))
        return scored_queries



