Introduction
============

Motivation
----------

Recently, aggregate queries are used as workloads to evaluate the utility of synthetic data :cite:p:`fan2020relational`. The generated query is run on both real and synthetic datasets. The query results from both datasets are compared and the relative error is calculated to serve as a utility measure. However, the current studies assume pre-determined query formulation such as that proposed by Li et al where specific categorical variables are chosen for aggregation :cite:p:`li2018bounded`. This deterministic approach leads to biased results since a synthesizer may learn the underlying distribution of some variables better than the others. To tackle this problem, we are inspired by the randomness introduced by SQL Fuzzing techniques also known as Fuzzers. 

SQL Fuzzers are mainly used to test database management systems (DBMSs) for any bugs or vulnerabilities :cite:p:`noauthor_sqlsmith_0000`. Before executing an SQL query, a DBMS performs two levels of checks. First the SQL statement is checked for any syntactic error such as grammatical errors. Secondly, the query is checked semantically e.g. a call is made to a non-existent table. Once the DBMS performs the necessary checks, the SQL statement is executed according to the best execution plan :cite:p:`zhong2020squirrel`. 
Fuzzers usually generate large amount of queries that do not pass the aforementioned checks. For instance,  American Fuzzy Lop (AFL) :cite:p:`wong2022american`, a widely used fuzzer, has  only 30% out of it generated queries passing the syntax check while only 4% can pass the semantic check :cite:p:`zhong2020squirrel`. While research attempts are made to focus on finding DBMS logic errors rather than semantic and syntactic errors such techniques generate both queries and the test datasets :cite:p:`ghit_sparkfuzz_2020`. Other researchers :cite:p:`rigger_testing_2020` propose an approach to generate queries that ensure fetching a randomly selected row and hence avoid syntactic and semantic error injection. 

To ensure unbiased representation of synthetic data utility, we propose a Fuzzy SQL technique that have the following features:
-	Aggregate queries shall be randomly generated, i.e. grouping may be executed using any combination of the available categorical data.  
-	Aggregation may take place across any of the available continuous variables.
-	A random condition may be imposed on the aggregate queries. In such case, the values used in the WHERE clause shall be randomly sampled from the real data and equally executed on both the real and synthetic data. 
-	Datasets are available in tabular formal and may include categorical, continuous and date variables. 
-	A proper metric shall be established to compare the results from the real and synthetic data.

It is important to pay a special attention to the metric to be used. For instance, Fan et al proposes1 to arrange the data with one of the categorical variables as a dependent variable. Then two classifiers are trained using training examples from the real and synthetic data respectively. Finally the testing examples from the real data are used to test both models using traditional metric such as F1. The F1 scores for both models are compared. Clearly, this approach will highly depend on the selection of the dependent variable especially if the dataset mostly incudes categorical variables.  


Constructs
----------

Fuzzy SQL is developed to enable the comparison between real and synthetic datasets that are generated by any ML technique. Fuzzy SQL will generate semantically and syntactically correct SELECT random queries that are simultaneously applied to both inputs of real and synthetic datasets. The tool returns all query results along with the corresponding query parameters such as the SQL statement. The query results may be further analyzed to measure distances between real and synthetic responses to each query.

The input datasets may be either tabular of longitudinal. 

For tabular data, we define two basic types of SELECT queries, namely, 'filter' queries and 'aggregate' queries. For comparing real and synthetic datasets, usually 'aggregate' queries are used. This will allow the analyst to compare the resulting aggregate values from both datasets. Metrics, such as the Hellinger distance, can be applied to the aggregate query results in the same manner they are applied to the original datasets. On the other hand, an analyst may be interested to combine both filter and aggregate types of queries since filter queries may represent inclusion-exclusion criteria. Accordingly, we define a third type of queries and we call it 'filter-aggregate' query.  

If the input data includes continuous variables, various 'aggregate functions' may be randomly applied in addition to counting the resulting number of records. These functions are limited to AVG, SUM, MIN and MAX. If the input doe snot include any continuous variable, only the COUNT aggregate function is applied. The types of each variable are typically defined by the user and inputted along with the real and synthetic datasets.   

.. _Tabular Data Templates:

Tabular Data Templates
----------------------
Without loss of generality, and to simplify the mathematical constructs, we herein ignore the logical operation 'NOT' and the value comparison operations  BETWEEN, LIKE and IN. We further consider that the same set of value comparison operations is applicable to all types of variables. In practice, a distinction in their applicability is made and all the aforementioned operations are considered. Define:

:math:`\mathcal{T}^r` : Database table for real data.

:math:`\mathcal{T}^s`: Database table for synthetic data

:math:`N`: The number of records in both :math:`\mathcal{T}^r` and :math:`\mathcal{T}^s`.

:math:`\mathbb{A}^n=\{A^n_1,A^n_2, \cdots, A^n_{|\mathbb{A}^n|}\}` is the set of *nominal* variables in both :math:`\mathcal{T}^r` and :math:`\mathcal{T}^s` where :math:`|\mathbb{A}^n|` indicates the number of these variables.


:math:`\mathbb{A}^c=\{A^c_1,A^c_2, \cdots, A^c_{|\mathbb{A}^c|}\}` is the set of *continuous* variables in both :math:`\mathcal{T}^r` and :math:`\mathcal{T}^s`.

:math:`\mathbb{A}^d=\{A^d_1,A^d_2, \cdots, A^d_{|\mathbb{A}^d|}\}` is the set of *date* variables in both :math:`\mathcal{T}^r` and :math:`\mathcal{T}^s`.

For any member :math:`A_j` in the above sets, it may assume a *value* given in the real dataset :math:`\mathcal{T}^r` such that: 

:math:`V(A_j)` is the the set of all values that :math:`A_j` may take. The length of :math:`V(A_j)` is :math:`|V(A_j)|=N`.

We further define:

:math:`LO=\{AND, OR\}` is the set of logical operations.

:math:`CO=\{=, \ne,<,\leq, >,\geq \}` is the set of value comparison operations. 

:math:`AG=\{SUM, AVG, MIN, MAX\}` is the set of aggregate functions.

Random samples are drawn from the above sets to construct the three major queries defined below. The basic sampling functions can be defined as:

:math:`f_s: S_m \rightarrow S_s` where :math:`f_s` is a sampling function that maps any set :math:`S_m` into a single element set :math:`S_s`. For instance, the set :math:`AG` may be mapped by :math:`f_s` into :math:`\{AVG\}`

:math:`f_m: S_{m1} \rightarrow S_{m2}` where :math:`f_m` is a sampling function that maps any set :math:`S_{m1}` into a multiple element set :math:`S_{m2}`. For instance, the set :math:`\mathbb{A}^n` may be mapped by :math:`f_m` into :math:`\{A^n_1, A^n_{|\mathbb{A}^n|}\}`

Aggregate Queries
~~~~~~~~~~~~~~~~~
If :math:`\mathbb{A}^c = \phi`, an aggregate query takes the form:

.. math::
    :nowrap:

    \begin{flalign}
    \nonumber
    \text{SELECT} \quad & f_m(\mathbb{A}^n) \text{, COUNT(*)} &&\\\nonumber
    \text{FROM} \quad & \mathcal{T}^r &&\\\nonumber
    \text{GROUP BY} \quad & f_m(\mathbb{A}^n)
    \end{flalign}

However, if :math:`\mathbb{A}^c \ne \phi`, an aggregate query takes the form:

.. math::
    :nowrap:

    \begin{flalign}
    \nonumber
    \text{SELECT} \quad & f_m(\mathbb{A}^n), f_s(AG)(f_s(\mathbb{A}^c)) \text{, COUNT(*)} &&\\\nonumber
    \text{FROM} \quad & \mathcal{T}^r &&\\\nonumber
    \text{GROUP BY} \quad & f_m(\mathbb{A}^n)
    \end{flalign}

Similar queries are constructed for :math:`\mathcal{T^s}`.

Filter Queries
~~~~~~~~~~~~~~

If :math:`\mathbb{A}^c = \phi`, a filter query takes the form:

.. math::
   :nowrap:

    \begin{flalign}
    \nonumber
    \text{SELECT} \quad  & * &&\\\nonumber
    \text{FROM}   \quad  & \mathcal{T}^r &&\\\nonumber
    \text{WHERE}  \quad  & [f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d) \quad f_s(CO) \quad f_s(V(f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d )))] &&\\\nonumber
                         & [f_s(LO)] &&\\\nonumber
                         & [(f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d) \quad f_s(CO) \quad f_s(V(f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d ))) &&\\\nonumber
                         & f_s(LO) \quad f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d) \quad f_s(CO) \quad f_s(V(f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d ))))] &&\\\nonumber
                         & \cdots
    \end{flalign}

The WHERE clause comprises three basic expressions denoted by :math:`[\quad ]`. The set length of the randomly selected query variables has an impact on these expressions. For instance, if :math:`|f_m(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d)|=2`, the first and second expressions are dropped and the SELECT statement will reduce to:

.. math::
   :nowrap:

    \begin{flalign}
    \nonumber
    \text{SELECT} \quad  & * &&\\\nonumber
    \text{FROM}   \quad  & \mathcal{T}^r &&\\\nonumber
    \text{WHERE}  \quad  & [(f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d) \quad f_s(CO) \quad f_s(V(f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d ))) &&\\\nonumber
                         & f_s(LO) \quad f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d) \quad f_s(CO) \quad f_s(V(f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d ))))]
    \end{flalign}


If :math:`\mathbb{A}^c \ne \phi`, a filter query takes the form:

.. math::
   :nowrap:

    \begin{flalign}
    \nonumber
    \text{SELECT} \quad  & f_s(AG)(f_s(\mathbb{A}^c)) \text{, COUNT(*)} &&\\\nonumber
    \text{FROM}   \quad  & \mathcal{T}^r &&\\\nonumber
    \text{WHERE}  \quad  & [f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d) \quad f_s(CO) \quad f_s(V(f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d )))] &&\\\nonumber
                         & [f_s(LO)] &&\\\nonumber
                         & [(f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d) \quad f_s(CO) \quad f_s(V(f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d ))) &&\\\nonumber
                         & f_s(LO) \quad f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d) \quad f_s(CO) \quad f_s(V(f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d ))))] &&\\\nonumber
                         & \cdots
    \end{flalign}


Filter-Aggregate Queries
~~~~~~~~~~~~~~~~~~~~~~~~
Filter-Aggregate queries are the most important for comparing real and synthetic datasets. The query is constructed by combining the above two forms. Hence, if :math:`\mathbb{A}^c = \phi`, a filter-aggregate query takes the form: 

.. math::
    :nowrap:

    \begin{flalign}
    \nonumber
    \text{SELECT} \quad & f_m(\mathbb{A}^n) \text{, COUNT(*)} &&\\\nonumber
    \text{FROM} \quad & \mathcal{T}^r &&\\\nonumber
    \text{WHERE}  \quad  & [f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d) \quad f_s(CO) \quad f_s(V(f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d )))] &&\\\nonumber
                        & [f_s(LO)] &&\\\nonumber
                        & [(f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d) \quad f_s(CO) \quad f_s(V(f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d ))) &&\\\nonumber
                        & f_s(LO) \quad f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d) \quad f_s(CO) \quad f_s(V(f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d ))))] &&\\\nonumber
                        & \cdots &&\\\nonumber
    \text{GROUP BY} \quad & f_m(\mathbb{A}^n)
    \end{flalign}


and if :math:`\mathbb{A}^c \ne \phi`, a filter-aggregate query takes the form:

.. math::
    :nowrap:

    \begin{flalign}
    \nonumber
    \text{SELECT} \quad & f_m(\mathbb{A}^n), f_s(AG)(f_s(\mathbb{A}^c)) \text{, COUNT(*)} &&\\\nonumber
    \text{FROM}   \quad & \mathcal{T}^r &&\\\nonumber
    \text{WHERE}  \quad  & [f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d) \quad f_s(CO) \quad f_s(V(f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d )))] &&\\\nonumber
                        & [f_s(LO)] &&\\\nonumber
                        & [(f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d) \quad f_s(CO) \quad f_s(V(f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d ))) &&\\\nonumber
                        & f_s(LO) \quad f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d) \quad f_s(CO) \quad f_s(V(f_s(\mathbb{A}^n \cup \mathbb{A}^c \cup \mathbb{A}^d ))))] &&\\\nonumber
                        & \cdots &&\\\nonumber
    \text{GROUP BY} \quad & f_m(\mathbb{A}^n)
    \end{flalign}


Longitudinal Data Templates
---------------------------
Fuzzy SQL supports the generation of valid random queries for joint tables in parent-child relationship. Both single and multiple-child relationships are supported. Further to the definitions given in :ref:`Hellinger Distance for Datasets`, and for simplicity, we will drop the distinction between the real and synthetic tables as the generated random queries are always identical. Define:

Metrics for Tabular Datasets
----------------------------

.. _Hellinger Distance for Datasets:

Hellinger Distance for Datasets
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The Hellinger distance may be used to measure the quality of synthetic data. First we consider the calculation of the Hellinger distance between the real and the synthetic tabular datasets :math:`\mathcal{T}^r` and :math:`\mathcal{T}^s` respectively. Define:

:math:`\mathbb{A}=\{A_1, \cdots,A_i, \cdots, A_{|\mathbb{A}|}\}` is the set of *nominal* variables in both :math:`\mathcal{T}^r` and :math:`\mathcal{T}^s` where :math:`|\mathbb{A}|` indicates the number of these variables.

:math:`o^j_{A_i}` is the number of occurrences (i.e. counts) of the :math:`j^{th}` class for the nominal variable :math:`A_i` in :math:`\mathcal{T}^r`. The discrete probability of the :math:`j^{th}` class can be calculated as:

.. math:: 

    r^j_{A_i}=\frac{o^j_{A_i}}{\sum\limits_{\forall j} o^j_{A_i}}


For instance, consider the *nominal* variable :math:`A_1=\text{"income"}` with two classes '<=50k' and '>50k'. Then the first class may have :math:`o^1_{A_1}=1200` occurrences and the second may have :math:`o^2_{A_1}=2000` occurrences with discrete probabilities of :math:`r^1_{A_1}=0.375` and :math:`r^2_{A_1}=0.625` respectively. 

Similarly, for the synthetic data :math:`\mathcal{T}^s` we can calculate the discrete probabilities :math:`s^j_{A_i}` 

The Hellinger distance for the nominal variable :math:`A_i`  is calculated as:

.. math:: 

    \mathcal{H}^{A_i}=\frac{1}{\sqrt{2}}\left(\sum\limits_{\forall j}\left(\sqrt{r^j_{A_i}}-\sqrt{s^j_{A_i}}\right)^2\right)^{1 / 2}

The Hellinger distance between :math:`\mathcal{T}^r` and :math:`\mathcal{T}^s` can be calculated  by taking the mean across all *nominal* variables:

.. math:: 
    :label: eq_hlngr_T

    \mathcal{H}^{\mathcal{T}}=\frac{1}{|\mathbb{A}|} \sum_{i=1}^{|\mathbb{A}|} \mathcal{H}^{A_i}

.. _Hellinger Distance for Queries:

Hellinger Distance for Queries
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In *aggregate* queries, grouping is done by randomly selected *nominal* variables. In this sense, measuring the Hellinger distance for the  datasets as explained above is just a special case where grouping is done by a single nominal variable at a time. So, for :math:`|\mathbb{A}|` number of *nominal* variables in the original datasets, we may execute :math:`|\mathbb{A}|` number of queries with each query grouped by a single variable. Then by averaging the Hellinger distances of these queries, we reach the same results in :eq:`eq_hlngr_T`

If grouping is done by more than a single variable, it is as we are defining a new nominal variable :math:`A^q` where :math:`A^q` may be any combination of two or more dataset variables :math:`A^i \quad \forall A^i \in \mathbb{A}` as defined in :ref:`hellinger distance for datasets`. The query will result in specific number of classes for :math:`A^q`. Using the superscript :math:`j` to indicate the :math:`j^{th}` class of :math:`A^q`, we calculate the Hellinger distance for the query by:

.. math:: 

    \mathcal{H}^{\mathcal{Q}}=\frac{1}{\sqrt{2}}\left(\sum\limits_{\forall j}\left(\sqrt{r^j_{A^q}}-\sqrt{s^j_{A^q}}\right)^2\right)^{1 / 2}

Both discrete probabilities :math:`r` and :math:`s` were defined earlier in  :ref:`hellinger distance for datasets`.

For instance, consider an aggregate query grouped by the two nominal variables :math:`A_1=\text{"income"}` and :math:`A_2=\text{"marital status"}` with each having two distinct classes. The query will result in the variable :math:`A^q` having four distinct classes with a discrete probability :math:`r_{A^q}^j` for each resulting class :math:`j`.

Euclidean Distance for Queries
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Once the *aggregate* query is executed, the variable :math:`A^q`, as defined in :ref:`Hellinger Distance for Queries`, will result in the classes: :math:`1,2..j..J`.  If the data includes a continuous variable :math:`A^c`, an aggregate function, say AGG, may be applied to that variable. For each class :math:`j`, an aggregation value :math:`[AGG(A^c)]_j` of the continuous variable can be calculated. For instance, let :math:`A^q` be a combination of two nominal variables :math:`A_1=\text{"income"}` and :math:`A_2=\text{"marital status"}`. Let :math:`A^c=\text{"age"}` be a continuous variable, then for each of the four distinct classes, we can calculate the :math:`\text{AVG}(\text{age})`. Define:

:math:`v^r_j` is the aggregate value (e.g. :math:`[\text{AVG}(\text{age})]_j`) corresponding to the :math:`j^{th}` class of an arbitrary continuos variable :math:`A^c` in :math:`\mathcal{T}^r`.

:math:`v^s_j` is the aggregate value corresponding to the :math:`j^{th}` class of the same continuos variable :math:`A^c` in :math:`\mathcal{T}^s` 

From the above components, we can find the difference components:

:math:`d_j=v^r_j-v^s_j \quad \forall j`

We further find the mean and standard deviation across all the classes:

:math:`\mu^d=\frac{1}{J} \sum\limits_{j=1}^J d_j`

:math:`\sigma^d=\sqrt{\frac{1}{J}\sum\limits_{j=1}^J (d_j-\mu^d)^2}`

and we compute the standardized aggregate values:

:math:`z_j =\frac{d_j-\mu^d}{\sigma^d}`

Finally, we compute the norm and normalize it to reflect the normalized Euclidean distance between the real and synthetic queries :

:math:`\mathcal{E}^\mathcal{Q}=\frac{\|z_j\|}{J}`

Normalizing the distance by the number of resulting classes for the random query enables us to average the Euclidean distance across multiple queries since each of them may result in different number of classes. 




.. bibliography:: refs.bib
